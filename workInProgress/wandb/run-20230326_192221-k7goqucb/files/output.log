current loss:  10.004135131835938
current loss:  7.525043487548828
current loss:  7.82453727722168
current loss:  10.761115074157715
current loss:  7.007819652557373
current loss:  3.4406423568725586
current loss:  7.761879920959473
current loss:  6.6551103591918945
current loss:  7.967421054840088
current loss:  6.643827438354492
current loss:  5.559983730316162
current loss:  4.0278778076171875
current loss:  6.304489612579346
current loss:  10.912087440490723
current loss:  7.515082836151123
current loss:  4.1072797775268555
current loss:  6.091829776763916
current loss:  6.226975440979004
current loss:  9.898950576782227
current loss:  7.527417182922363
current loss:  4.352759838104248
current loss:  6.52567720413208
current loss:  6.932170867919922
current loss:  3.976389169692993
current loss:  5.884679317474365
current loss:  5.097414970397949
current loss:  8.38590145111084
current loss:  6.712259769439697
current loss:  6.142003536224365
current loss:  6.830816268920898
current loss:  5.634054183959961
current loss:  6.239956855773926
current loss:  4.186172962188721
current loss:  7.637978553771973
current loss:  3.4863779544830322
current loss:  7.543149948120117
current loss:  6.323227405548096
current loss:  11.30661678314209
current loss:  4.633298397064209
current loss:  7.2044677734375
current loss:  7.0731377601623535
current loss:  7.847842216491699
current loss:  4.333564281463623
current loss:  4.349544525146484
current loss:  5.389430999755859
current loss:  3.140596389770508
current loss:  7.702874660491943
current loss:  8.756521224975586
current loss:  6.0711188316345215
current loss:  6.01776123046875
current loss:  6.397312164306641
current loss:  8.390337944030762
current loss:  5.3175835609436035
current loss:  5.826207160949707
current loss:  9.840591430664062
current loss:  4.469997882843018
current loss:  6.593626022338867
current loss:  5.589526176452637
current loss:  8.088622093200684
current loss:  5.227041244506836
current loss:  5.610250473022461
current loss:  9.05459976196289
current loss:  5.222352981567383
current loss:  9.359429359436035
current loss:  6.6989336013793945
current loss:  5.577699184417725
current loss:  5.512032508850098
current loss:  6.8877997398376465
current loss:  5.622706890106201
current loss:  4.236189842224121
current loss:  7.511755466461182
current loss:  4.956320285797119
current loss:  3.9122049808502197
current loss:  7.848079681396484
current loss:  8.083049774169922
current loss:  6.755487442016602
current loss:  7.003559112548828
current loss:  5.80973482131958
current loss:  6.818496227264404
current loss:  2.444735050201416
current loss:  3.5171327590942383
current loss:  8.701698303222656
current loss:  8.206286430358887
current loss:  7.874332427978516
current loss:  5.445684432983398
current loss:  9.04006290435791
current loss:  7.52174711227417
current loss:  4.588208198547363
current loss:  5.7354559898376465
current loss:  5.051761627197266
current loss:  8.099808692932129
current loss:  3.970073699951172
current loss:  4.885445594787598
current loss:  7.561862468719482
current loss:  6.444100856781006
current loss:  7.098781585693359
current loss:  3.4516701698303223
current loss:  5.232349872589111
current loss:  6.921574592590332
current loss:  4.253280162811279
current loss:  6.750360012054443
current loss:  3.3005149364471436
current loss:  10.083653450012207
current loss:  6.106760025024414
current loss:  6.418032169342041
current loss:  3.0398733615875244
current loss:  6.8827948570251465
current loss:  9.519210815429688
current loss:  5.588108539581299
current loss:  7.193685054779053
current loss:  6.906888484954834
current loss:  9.109532356262207
current loss:  8.01867389678955
current loss:  5.298222541809082
current loss:  3.6732699871063232
current loss:  8.956586837768555
current loss:  4.964885711669922
current loss:  9.666090965270996
current loss:  7.451910018920898
current loss:  7.340564727783203
current loss:  7.62153434753418
current loss:  6.785799980163574
current loss:  7.129138469696045
current loss:  3.652707099914551
current loss:  10.071723937988281
current loss:  11.740534782409668
current loss:  8.041468620300293
current loss:  7.172449588775635
current loss:  4.678625106811523
current loss:  6.924814701080322
current loss:  7.37775993347168
current loss:  8.29499626159668
current loss:  5.045220851898193
current loss:  7.011685848236084
current loss:  8.519000053405762
current loss:  6.086698532104492
current loss:  10.08980941772461
current loss:  7.646056175231934
current loss:  6.331577777862549
current loss:  3.0101723670959473
current loss:  4.859088897705078
current loss:  4.7457709312438965
current loss:  3.715017318725586
current loss:  6.428921222686768
current loss:  8.286491394042969
current loss:  6.349417209625244
current loss:  5.542505264282227
current loss:  5.525380611419678
current loss:  5.811460971832275
current loss:  9.298283576965332
current loss:  6.355626583099365
current loss:  6.288580894470215
current loss:  5.5841450691223145
current loss:  8.304222106933594
current loss:  8.289189338684082
current loss:  3.96148419380188
current loss:  9.197333335876465
current loss:  8.712359428405762
current loss:  5.824714660644531
current loss:  12.906719207763672
current loss:  4.7103271484375
current loss:  5.1433539390563965
current loss:  5.623699188232422
current loss:  7.149292469024658
current loss:  4.924734115600586
current loss:  5.752923488616943
current loss:  6.3018364906311035
current loss:  5.686660289764404
current loss:  4.186468601226807
current loss:  6.252993583679199
current loss:  6.728334903717041
current loss:  6.7033162117004395
current loss:  6.302732467651367
current loss:  4.235812664031982
current loss:  5.8838911056518555
current loss:  5.249797821044922
current loss:  6.72917366027832
current loss:  10.876090049743652
current loss:  5.3835344314575195
current loss:  4.688202381134033
current loss:  11.88431453704834
current loss:  7.07932186126709
current loss:  7.173398494720459
current loss:  6.508978366851807
current loss:  6.9745378494262695
current loss:  5.007020473480225
current loss:  6.378014087677002
current loss:  5.023441314697266
current loss:  6.536691188812256
current loss:  11.019893646240234
current loss:  6.6832499504089355
current loss:  8.608332633972168
current loss:  6.293421268463135
current loss:  7.6498122215271
current loss:  4.695425987243652
current loss:  6.614383697509766
current loss:  3.7158849239349365
current loss:  3.925492286682129
current loss:  5.389931678771973
current loss:  8.005738258361816
current loss:  8.029725074768066
current loss:  4.555212497711182
current loss:  7.364014625549316
current loss:  6.49427604675293
current loss:  3.767469644546509
current loss:  7.85923957824707
current loss:  6.701546669006348
current loss:  4.9903974533081055
current loss:  6.195316314697266
current loss:  4.623807907104492
current loss:  7.298343658447266
current loss:  8.641181945800781
current loss:  8.000669479370117
current loss:  5.9301886558532715
current loss:  4.404906749725342
current loss:  8.60339641571045
current loss:  5.560047149658203
current loss:  6.654809951782227
current loss:  7.773287773132324
current loss:  5.604356288909912
current loss:  5.121077537536621
current loss:  7.656694412231445
current loss:  6.230706691741943
current loss:  5.7401204109191895
current loss:  3.2821927070617676
current loss:  10.656170845031738
current loss:  6.303093433380127
current loss:  8.201399803161621
current loss:  6.861708641052246
current loss:  4.561664581298828
current loss:  8.854793548583984
current loss:  5.411492824554443
current loss:  4.7898054122924805
current loss:  5.41375732421875
current loss:  5.95231294631958
current loss:  5.094325542449951
current loss:  7.107308387756348
current loss:  4.264249324798584
current loss:  3.6778903007507324
current loss:  7.575989723205566
current loss:  6.71697998046875
current loss:  6.053811073303223
current loss:  3.901785135269165
current loss:  7.311702251434326
current loss:  5.241201877593994
current loss:  5.207442283630371
current loss:  8.438924789428711
current loss:  8.393819808959961
current loss:  4.760982990264893
current loss:  7.560261249542236
current loss:  7.623581886291504
current loss:  5.739547252655029
current loss:  7.099813461303711
current loss:  4.235980033874512
current loss:  9.424996376037598
current loss:  5.31886625289917
current loss:  6.965888500213623
current loss:  5.072732448577881
current loss:  6.183725357055664
current loss:  5.653466701507568
current loss:  6.269290924072266
current loss:  5.741011619567871
current loss:  5.190148830413818
current loss:  7.381387710571289
current loss:  4.77213191986084
current loss:  9.48520565032959
current loss:  7.068633556365967
current loss:  4.58724308013916
current loss:  9.772765159606934
current loss:  7.008800506591797
current loss:  5.6255784034729
current loss:  6.697352409362793
current loss:  4.04730224609375
current loss:  4.1152544021606445
current loss:  4.850334644317627
current loss:  7.604058742523193
current loss:  4.982715606689453
current loss:  8.043054580688477
current loss:  6.140915870666504
current loss:  7.640641212463379
current loss:  5.04888916015625
current loss:  3.8708243370056152
current loss:  6.392234802246094
current loss:  4.803305149078369
current loss:  4.2717156410217285
current loss:  4.601051330566406
current loss:  6.9173479080200195
current loss:  7.692976474761963
current loss:  6.046139717102051
current loss:  8.155434608459473
current loss:  9.949904441833496
current loss:  9.48405933380127
current loss:  7.948063373565674
current loss:  7.3395209312438965
current loss:  6.50286865234375
current loss:  9.138869285583496
current loss:  4.598054885864258
current loss:  4.820797920227051
current loss:  7.0444746017456055
current loss:  10.663439750671387
current loss:  7.180717468261719
current loss:  6.117445945739746
current loss:  4.6014885902404785
current loss:  9.237421989440918
current loss:  9.70023250579834
current loss:  5.055999755859375
current loss:  7.718127250671387
current loss:  8.081048965454102
current loss:  3.930041551589966
current loss:  6.46037483215332
current loss:  5.905956745147705
current loss:  8.111523628234863
current loss:  8.013898849487305
current loss:  10.063971519470215
current loss:  8.849352836608887
current loss:  5.3697638511657715
current loss:  7.601919651031494
current loss:  7.973171234130859
current loss:  6.167173385620117
current loss:  4.064696311950684
current loss:  4.219205379486084
current loss:  8.975993156433105
current loss:  7.284430027008057
current loss:  4.978130340576172
current loss:  5.24258279800415
current loss:  5.446045875549316
current loss:  5.1334147453308105
current loss:  3.857957124710083
current loss:  5.325331211090088
current loss:  5.723284721374512
current loss:  6.692475318908691
current loss:  5.497890949249268
current loss:  7.299169063568115
current loss:  7.775089740753174
current loss:  7.04400110244751
current loss:  4.770395278930664
current loss:  7.940723419189453
current loss:  3.830939531326294
current loss:  4.904591083526611
current loss:  8.200624465942383
current loss:  5.60708475112915
current loss:  6.958798408508301
current loss:  7.146450519561768
current loss:  7.008618354797363
current loss:  11.132804870605469
current loss:  6.287989139556885
current loss:  5.851874351501465
current loss:  7.62359619140625
current loss:  8.781848907470703
current loss:  7.501070976257324
current loss:  5.087029933929443
current loss:  10.247796058654785
current loss:  8.457377433776855
current loss:  9.84116268157959
current loss:  8.662127494812012
current loss:  8.883504867553711
current loss:  7.330772876739502
current loss:  5.882131099700928
current loss:  5.881986141204834
current loss:  7.8004937171936035
current loss:  6.685937404632568
current loss:  4.223199367523193
current loss:  8.921804428100586
current loss:  6.105587482452393
current loss:  6.946031093597412
current loss:  4.098944187164307
current loss:  8.540603637695312
current loss:  6.503164768218994
current loss:  4.980908393859863
current loss:  6.2583842277526855
current loss:  6.349151134490967
current loss:  5.388784885406494
current loss:  5.563902854919434
current loss:  4.580679893493652
current loss:  7.001579761505127
current loss:  6.917957782745361
current loss:  5.360616207122803
current loss:  7.229557514190674
current loss:  5.580499649047852
current loss:  9.569381713867188
current loss:  6.687057971954346
current loss:  6.496646881103516
current loss:  7.521358013153076
current loss:  6.715991497039795
current loss:  5.589067459106445
current loss:  7.3355817794799805
current loss:  4.949703216552734
current loss:  4.7698187828063965
current loss:  8.864897727966309
current loss:  3.864696502685547
current loss:  7.122158050537109
current loss:  6.10162353515625
current loss:  9.705985069274902
current loss:  5.810868740081787
current loss:  8.576822280883789
current loss:  4.60666036605835
current loss:  8.218690872192383
current loss:  5.032717227935791
current loss:  6.348105430603027
current loss:  7.576102256774902
current loss:  5.927275657653809
current loss:  6.610567569732666
current loss:  8.732498168945312
current loss:  2.770106077194214
current loss:  5.001544952392578
current loss:  3.569124698638916
current loss:  9.466388702392578
current loss:  10.325793266296387
current loss:  5.895319938659668
current loss:  5.511833190917969
current loss:  4.266170024871826
current loss:  6.4607086181640625
Traceback (most recent call last):
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/tokenizer.py", line 243, in <module>
    trainTokenizer(model, trainLoader, optimizer, criterion, device, 5, pathOrigin, True)
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/tokenizer.py", line 219, in trainTokenizer
    losses[counter] = loss.detach().cpu().item()
KeyboardInterrupt
Traceback (most recent call last):
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/tokenizer.py", line 243, in <module>
    trainTokenizer(model, trainLoader, optimizer, criterion, device, 5, pathOrigin, True)
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/tokenizer.py", line 219, in trainTokenizer
    losses[counter] = loss.detach().cpu().item()
