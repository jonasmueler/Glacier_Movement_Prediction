torch.Size([40, 4, 1000])
torch.Size([40, 40, 4, 1000])
Traceback (most recent call last):
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/completeTrainScriptDebug.py", line 84, in <module>
    functions.trainLoop(dTrain, model, False,"transformerPatches", 0.0001, 0.01, 0, 2, None, 1, True, device)
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/functions.py", line 585, in trainLoop
    forward = model.forward(helper, training = True)
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/pureTransformer.py", line 295, in forward
    l = self.latentSpace(res[0], target, datesDecoder, training)
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/pureTransformer.py", line 193, in latentSpace
    out = self.transformer(flattenedInput, targets, tgt_mask=targetMask)
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 5005, in multi_head_attention_forward
    is_batched = _mha_shape_check(query, key, value, key_padding_mask, attn_mask, num_heads)
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 4881, in _mha_shape_check
    raise AssertionError(
AssertionError: query should be unbatched 2D or batched 3D tensor but received 4-D query tensor
Traceback (most recent call last):
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/completeTrainScriptDebug.py", line 84, in <module>
    functions.trainLoop(dTrain, model, False,"transformerPatches", 0.0001, 0.01, 0, 2, None, 1, True, device)
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/functions.py", line 585, in trainLoop
    forward = model.forward(helper, training = True)
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/pureTransformer.py", line 295, in forward
    l = self.latentSpace(res[0], target, datesDecoder, training)
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/pureTransformer.py", line 193, in latentSpace
    out = self.transformer(flattenedInput, targets, tgt_mask=targetMask)
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 146, in forward
    memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 280, in forward
    output = mod(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 538, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 546, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py", line 1167, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 5005, in multi_head_attention_forward
    is_batched = _mha_shape_check(query, key, value, key_padding_mask, attn_mask, num_heads)
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/nn/functional.py", line 4881, in _mha_shape_check
    raise AssertionError(
AssertionError: query should be unbatched 2D or batched 3D tensor but received 4-D query tensor