
current loss:  0.23349995911121368
current loss:  0.21703672409057617
current loss:  0.19786342978477478
current loss:  0.16564211249351501
current loss:  0.14447680115699768
current loss:  0.1315840780735016
current loss:  0.11464590579271317
current loss:  0.10890300571918488
current loss:  0.10765277594327927
current loss:  0.09485830366611481
current loss:  0.0879836454987526
current loss:  0.09030715376138687
current loss:  0.08616402000188828
current loss:  0.07254020124673843
current loss:  0.07034115493297577
current loss:  0.0684061273932457
current loss:  0.05844825133681297
current loss:  0.06923842430114746
current loss:  0.07101821154356003
current loss:  0.06520207971334457
current loss:  0.054258719086647034
current loss:  0.05205419659614563
current loss:  0.0558687262237072
current loss:  0.05038963258266449
current loss:  0.045977454632520676
current loss:  0.04720110818743706
current loss:  0.049355752766132355
current loss:  0.044572412967681885
current loss:  0.04473601654171944
current loss:  0.04144541174173355
current loss:  0.04647216573357582
current loss:  0.03843510150909424
current loss:  0.0382208451628685
current loss:  0.035795051604509354
current loss:  0.03850278630852699
current loss:  0.04363889619708061
current loss:  0.03577816113829613
current loss:  0.03205350786447525
current loss:  0.03785175457596779
current loss:  0.040017273277044296
current loss:  0.039308782666921616
current loss:  0.03387538716197014
current loss:  0.03308132290840149
current loss:  0.03637106344103813
current loss:  0.03781295195221901
current loss:  0.03073580004274845
current loss:  0.030580298975110054
current loss:  0.03093894198536873
current loss:  0.027551358565688133
current loss:  0.027407249435782433
current loss:  0.033005811274051666
current loss:  0.03346629440784454
current loss:  0.030684377998113632
current loss:  0.030124159529805183
current loss:  0.027572480961680412
current loss:  0.03270607441663742
current loss:  0.02672203816473484
current loss:  0.025616925209760666
Traceback (most recent call last):
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/tokenizer.py", line 106, in <module>
    trainTokenizer(model, trainLoader, optimizer, criterion, device, 5, pathOrigin, True)
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/tokenizer.py", line 82, in trainTokenizer
    for inputs in trainLoader:
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/datasetClasses.py", line 77, in __getitem__
    inpt = functions.openData(self.images[idx])
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/functions.py", line 403, in openData
    with open(name, "rb") as fp:   # Unpickling
KeyboardInterrupt
Traceback (most recent call last):
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/tokenizer.py", line 106, in <module>
    trainTokenizer(model, trainLoader, optimizer, criterion, device, 5, pathOrigin, True)
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/tokenizer.py", line 82, in trainTokenizer
    for inputs in trainLoader:
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 671, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jonas/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/datasetClasses.py", line 77, in __getitem__
    inpt = functions.openData(self.images[idx])
  File "/media/jonas/B41ED7D91ED792AA/Arbeit_und_Studium/Kognitionswissenschaft/Semester_5/masterarbeit#/data_Code/code/functions.py", line 403, in openData
    with open(name, "rb") as fp:   # Unpickling
