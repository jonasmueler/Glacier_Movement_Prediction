{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saHCxtV21_Av",
        "outputId": "8eeea4bb-2712-46d6-fbec-bd4040e68b0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JYq_Q2Hu10Ro"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "# read a file\n",
        "gdrive_path = '/content/gdrive/My Drive/'\n",
        "\n",
        "\n",
        "with open(f'{gdrive_path}trainData', 'rb')  as fp:\n",
        "  data = pickle.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jb71gdqV2m1H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from numpy import linalg as LA\n",
        "from numpy import ma\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.feature_extraction import image\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import sys\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KQC10P1P4hVu"
      },
      "outputs": [],
      "source": [
        "# move data to cuda \n",
        "for i in range(len(data)):\n",
        "  helper = data[i]\n",
        "  helper[0][0] = [x.to(device='cuda').to(torch.float32) for x in helper[0][0]]\n",
        "  helper[0][1] = [x.to(device='cuda').to(torch.float32) for x in helper[0][1]] \n",
        "  helper[0][2] = [x.to(device='cuda').to(torch.float32) for x in helper[0][2]]\n",
        "  helper[1] = [x.to(device='cuda').to(torch.float32) for x in helper[1]]\n",
        "  data[i] = helper\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1bSacIg5YYp",
        "outputId": "a4d6553c-b047-4f74-b6bc-38eb1ce774fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3294, 0.3182, 0.0000,  ..., 0.6981, 0.7055, 0.6477],\n",
              "        [0.0000, 0.3526, 0.4650,  ..., 0.7217, 0.6978, 0.7010],\n",
              "        [0.4380, 0.4390, 0.5213,  ..., 0.6960, 0.7132, 0.7188],\n",
              "        ...,\n",
              "        [0.6764, 0.6825, 0.7110,  ..., 0.7558, 0.6577, 0.7469],\n",
              "        [0.6713, 0.6141, 0.6745,  ..., 0.7575, 0.7194, 0.7203],\n",
              "        [0.6736, 0.6773, 0.7012,  ..., 0.7258, 0.7388, 0.7500]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# check\n",
        "data[0][1][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uowxzuHT3ZwB"
      },
      "outputs": [],
      "source": [
        "# train functions\n",
        "def MSEpixelLoss(predictions, y):\n",
        "    \"\"\"\n",
        "\n",
        "    predictions: tensor\n",
        "        dims = (seqLen, x,y)\n",
        "    y: list of (x,y)\n",
        "\n",
        "    return: float\n",
        "        pixel loss for all images\n",
        "    \"\"\"\n",
        "\n",
        "    #y = torch.stack(y, 0)\n",
        "    #y = y.to(\"cuda\").to(torch.float32)\n",
        "    y = y.to(torch.float32)\n",
        "    loss = torch.nn.MSELoss()(predictions, y)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def saveCheckpoint(state, filename):\n",
        "    torch.save(state, filename)\n",
        "    print(\"model checkpoint saved\")\n",
        "    \n",
        "def loadCheckpoint(checkpoint, model, optimizer):\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "    print(\"loading model complete\")\n",
        "        \n",
        "\n",
        "def trainLoop(data, model, loadModel, modelName, lr, weightDecay, earlyStopping, criterionFunction, maxIter, epochs, testSet):\n",
        "    \"\"\"\n",
        "\n",
        "    data: list of list of input data and dates and targets\n",
        "    model: pytorch nn.class\n",
        "    loadModel: boolean\n",
        "    modelName: string\n",
        "        .pth.tar model name on harddrive\n",
        "    lr: float\n",
        "    weightDecay: float\n",
        "    earlyStopping: float\n",
        "    criterionFunction: nn.lossfunction\n",
        "    maxIter: int\n",
        "    epochs: int\n",
        "\n",
        "    return: nn.class\n",
        "        trained model\n",
        "    \"\"\"\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    runningLoss = 0\n",
        "    stoppingCounter = 0\n",
        "    lastLoss = 0\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weightDecay)\n",
        "    \n",
        "       \n",
        "    for x in range(epochs):\n",
        "      # load model \n",
        "      if loadModel:\n",
        "        loadCheckpoint(torch.load(modelName), model = model, optimizer = optimizer)\n",
        "      model.train()\n",
        "      for i in range(maxIter):\n",
        "        # sample data\n",
        "        idx = np.random.randint(2, size=1)\n",
        "        helper = data[idx[0]]\n",
        "        X = helper[0]\n",
        "        y = helper[1]\n",
        "        y = torch.stack(y, dim = 0)\n",
        "        X = [X,y]\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        forward = model.forward(X)\n",
        "        #predictions = forward[0].to(device='cuda')\n",
        "        predictions = forward[0]\n",
        "        loss = MSEpixelLoss(predictions, y) + forward[1]\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print loss\n",
        "        \n",
        "        runningLoss += loss.item()\n",
        "        if i%1000 == 0 and i != 0:\n",
        "            if testSet != None:\n",
        "                testLoss = [MSEpixelLoss(model.forward(x[0]).to(\"cuda\"), x[1]).item() for x in testSet]\n",
        "                testLoss = sum(testLoss)/len(testLoss)\n",
        "                #idx = np.random.randint(2, size=1)\n",
        "                #helper = testSet[idx[0]]\n",
        "                #X = helper[0]\n",
        "                #y = helper[1]\n",
        "                #predictions = model.forward(X)\n",
        "                #testLoss = MSEpixelLoss(predictions, y).item()\n",
        "                print(\"current test loss: \", testLoss)\n",
        "        print(\"epoch \", x, \", batch \", i, \" current loss = \", runningLoss/(i+1))\n",
        "        \n",
        "        # early stopping\n",
        "        if earlyStopping > 0:\n",
        "            if (lastLoss - loss.item()) < earlyStopping:\n",
        "                stoppingCounter += 1\n",
        "\n",
        "            if stoppingCounter == 10:\n",
        "              print(\"model converged, early stopping\")\n",
        "              checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
        "              saveCheckpoint(checkpoint, modelName)\n",
        "              sys.exit()\n",
        "        lastLoss = loss.item()\n",
        "            \n",
        "      checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
        "      saveCheckpoint(checkpoint, modelName)\n",
        "            \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AE_Transformer(nn.Module):\n",
        "    def __init__(self, encoderIn, hiddenLenc, hiddenLdec, mlpSize, numLayersDateEncoder, sizeDateEncoder,\n",
        "                     attLayers, attentionHeads, Training = True, predictionInterval = None):\n",
        "        super(AE_Transformer, self).__init__()\n",
        "\n",
        "        # global\n",
        "        self.training = Training\n",
        "        self.predictionInterval = predictionInterval\n",
        "\n",
        "        # encoder\n",
        "        self.CLayer1 = nn.Conv2d(1, 10, (3, 3), 1)\n",
        "        self.CLayer2 = nn.Conv2d(10, 20, (3, 3), 1)\n",
        "        self.CLayer3 = nn.Conv2d(20, 40, (3, 3), 1)\n",
        "        self.CLayer4 = nn.Conv2d(40, 60, (3, 3), 1)\n",
        "        self.CLayer5 = nn.Conv2d(60, 80, (3, 3), 1)\n",
        "        self.CLayer6 = nn.Conv2d(80, 100, (3, 3), 1)\n",
        "        self.CLayer7 = nn.Conv2d(100, 10, (3, 3), 1)\n",
        "        self.maxPool = nn.MaxPool2d(3, 1, return_indices=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.flatten = nn.Flatten(start_dim=0, end_dim=-1)\n",
        "\n",
        "        # date encoder\n",
        "        self.hiddenLenc = hiddenLenc\n",
        "        self.sizeDate = sizeDateEncoder\n",
        "        self.numLayersDateEncoder = numLayersDateEncoder\n",
        "        In = nn.Linear(3, self.sizeDate)\n",
        "        Linear = nn.Linear(self.sizeDate, self.sizeDate)\n",
        "        Out = nn.Linear(self.sizeDate, self.hiddenLenc)\n",
        "        r = nn.ReLU()\n",
        "        s = nn.Softmax()\n",
        "        helper = [In]\n",
        "\n",
        "        for i in range(self.numLayersDateEncoder):\n",
        "            helper.append(Linear)\n",
        "            helper.append(r)\n",
        "        helper.append(Out)\n",
        "        helper.append(s)\n",
        "        self.dateEncoderMLPlist = nn.ModuleList(helper)\n",
        "\n",
        "\n",
        "        # MLP Encoder\n",
        "        self.encoderIn = encoderIn\n",
        "        In = nn.Linear(self.encoderIn, self.hiddenLenc)\n",
        "        Linear = nn.Linear(self.hiddenLenc, self.hiddenLenc)\n",
        "        out = nn.Linear(self.hiddenLenc, self.hiddenLenc)\n",
        "        r = nn.ReLU()\n",
        "        helper = [In]\n",
        "\n",
        "        for i in range(mlpSize):\n",
        "            helper.append(Linear)\n",
        "            helper.append(r)\n",
        "        helper.append(out)\n",
        "        self.MLPlistEnc = nn.ModuleList(helper)\n",
        "\n",
        "        # hidden space\n",
        "        self.attentionLayers = attLayers\n",
        "        self.attentionHeads = attentionHeads\n",
        "        self.transformer = nn.Transformer(d_model = self.hiddenLenc, nhead= self.attentionHeads, num_encoder_layers=self.attentionLayers, num_decoder_layers=self.attentionLayers)\n",
        "\n",
        "        # MLP Decoder\n",
        "        self.hiddenLdec = hiddenLdec\n",
        "        In = nn.Linear(self.hiddenLdec, self.hiddenLdec)\n",
        "        Linear = nn.Linear(self.hiddenLdec, self.hiddenLdec)\n",
        "        out = nn.Linear(self.hiddenLdec, self.hiddenLdec)\n",
        "        r = nn.ReLU()\n",
        "        helper = [In]\n",
        "\n",
        "        for i in range(mlpSize):\n",
        "            helper.append(Linear)\n",
        "            helper.append(r)\n",
        "        helper.append(out)\n",
        "        self.MLPlistDec = nn.ModuleList(helper)\n",
        "\n",
        "        # decoder\n",
        "        self.TCLayer1 = nn.ConvTranspose2d(10, 100, (3, 3), 1)\n",
        "        self.TCLayer2 = nn.ConvTranspose2d(100, 80, (3, 3), 1)\n",
        "        self.TCLayer3 = nn.ConvTranspose2d(80, 60, (3, 3), 1)\n",
        "        self.TCLayer4 = nn.ConvTranspose2d(60, 40, (3, 3), 1)\n",
        "        self.TCLayer5 = nn.ConvTranspose2d(40, 20, (3, 3), 1)\n",
        "        self.TCLayer6 = nn.ConvTranspose2d(20, 10, (3, 3), 1)\n",
        "        self.TCLayer7 = nn.ConvTranspose2d(10, 1, (3, 3), 1)\n",
        "        self.maxUnPool = nn.MaxUnpool2d(3, 1)\n",
        "\n",
        "    def dateEncoder(self, dateVec):\n",
        "        \"\"\"\n",
        "        date encoder uses dates as input and projects onto single scalar number with sigmoid activation in last layer\n",
        "        dateVec: tensor\n",
        "            input date as vector [day, month, year]\n",
        "        return: float\n",
        "        \"\"\"\n",
        "\n",
        "        # MLP\n",
        "        s = dateVec.to(\"cuda\")\n",
        "        for layer in self.dateEncoderMLPlist:\n",
        "            s = layer(s)\n",
        "        return s\n",
        "\n",
        "    def encoder(self, x,  encDate):\n",
        "        \"\"\"\n",
        "        downscale channel dimensions then flatten and weight with output of date Encoder\n",
        "\n",
        "        x: tensor\n",
        "            Input image patches (5,50,50)\n",
        "        encDate: 1d tensor\n",
        "            len = output encoder for each input image\n",
        "        return: list of tensor, list of tensor and list of tensor\n",
        "            [flattened image vectors for latent space, skip connections list for each image in input,\n",
        "            list indices for 2dmaxunpool in decoder]\n",
        "        \"\"\"\n",
        "        # init memory; idea: safe maxPool indices and skip connections in list of lists for decoder\n",
        "        result = torch.zeros((len(x), self.hiddenLenc)).to(\"cuda\")\n",
        "        poolingIndices = []\n",
        "        skipConnections = []\n",
        "\n",
        "        for i in range(len(x)):  # add max pooling\n",
        "            helper = []\n",
        "            helper1 = []\n",
        "            image = x[i].to(\"cuda\")\n",
        "            image = image.view(1,50,50)\n",
        "\n",
        "            # start convolutions\n",
        "            s = self.CLayer1(image)\n",
        "            s, indices = self.maxPool(s)\n",
        "            s = self.relu(s)\n",
        "            helper.append(s)\n",
        "            helper1.append(indices)\n",
        "\n",
        "            s = self.CLayer2(s)\n",
        "            s, indices = self.maxPool(s)\n",
        "            s = self.relu(s)\n",
        "            helper.append(s)\n",
        "            helper1.append(indices)\n",
        "\n",
        "            s = self.CLayer3(s)\n",
        "            s, indices = self.maxPool(s)\n",
        "            s = self.relu(s)\n",
        "            helper.append(s)\n",
        "            helper1.append(indices)\n",
        "\n",
        "            s = self.CLayer4(s)\n",
        "            s, indices = self.maxPool(s)\n",
        "            s = self.relu(s)\n",
        "            helper.append(s)\n",
        "            helper1.append(indices)\n",
        "\n",
        "            s = self.CLayer5(s)\n",
        "            s, indices = self.maxPool(s)\n",
        "            s = self.relu(s)\n",
        "            helper.append(s)\n",
        "            helper1.append(indices)\n",
        "\n",
        "            s = self.CLayer6(s)\n",
        "            s, indices = self.maxPool(s)\n",
        "            s = self.relu(s)\n",
        "            helper.append(s)\n",
        "            helper1.append(indices)\n",
        "\n",
        "            s = self.CLayer7(s)\n",
        "            s, indices = self.maxPool(s)\n",
        "            s = self.relu(s)\n",
        "\n",
        "            helper.append(s)\n",
        "            helper1.append(indices)\n",
        "            s = self.flatten(s)\n",
        "\n",
        "            # MLP\n",
        "            for layer in self.MLPlistEnc:\n",
        "                s = layer(s)\n",
        "            result[i, :] = s + self.dateEncoder(encDate[i]) # + encoder temporal embedding\n",
        "\n",
        "            # save lists for decoder\n",
        "            skipConnections.append(helper)\n",
        "            poolingIndices.append(helper1)\n",
        "\n",
        "        return [result, skipConnections, poolingIndices]\n",
        "\n",
        "    def positionalEncodings(self, seqLen):\n",
        "        \"\"\"\n",
        "        creates positional encoding matrix for the transformer model based on vasmari et al\n",
        "\n",
        "        seqLen: int\n",
        "            length of sequence\n",
        "        inputLen:\n",
        "            length of input\n",
        "\n",
        "        returns: 2d tensor\n",
        "            constants added for positional encodings\n",
        "        \"\"\"\n",
        "        # create constant 'pe' matrix with values dependant on pos and i\n",
        "        pe = torch.zeros(seqLen, self.hiddenLenc).to(\"cuda\")\n",
        "        for pos in range(seqLen):\n",
        "            for i in range(0, self.hiddenLenc, 2):\n",
        "                pe[pos, i] = \\\n",
        "                    math.sin(pos / (10000 ** ((2 * i) / self.hiddenLenc)))\n",
        "                pe[pos, i + 1] = \\\n",
        "                    math.cos(pos / (10000 ** ((2 * (i + 1)) / self.hiddenLenc)))\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        # make relatively larger\n",
        "        x = pe * math.sqrt(self.hiddenLenc)\n",
        "        pe = pe + x\n",
        "\n",
        "        return pe\n",
        "\n",
        "    def get_tgt_mask(self, size):\n",
        "        \"\"\"\n",
        "        Generates target mask for decoder in nn.Transformer\n",
        "\n",
        "        size: int\n",
        "            size of embedded images\n",
        "\n",
        "        returns tensor\n",
        "            size =  (size,size)\n",
        "        \"\"\"\n",
        "        mask = torch.tril(torch.ones(size, size) == 1).to(\"cuda\")\n",
        "        mask = mask.float()\n",
        "        mask = mask.masked_fill(mask == 0, float('-inf'))\n",
        "        mask = mask.masked_fill(mask == 1, float(0.0))\n",
        "\n",
        "        return mask\n",
        "\n",
        "\n",
        "\n",
        "    def latentSpace(self, flattenedInput, targets, targetsT):\n",
        "        \"\"\"\n",
        "        gets flattened feature vectors from encoder and feeds them into transformer\n",
        "\n",
        "        flattenedInput: tensor\n",
        "            output of encoder\n",
        "        targets: tensor\n",
        "            if training == True\n",
        "        targetsT: list of tensor\n",
        "            temporal information of images\n",
        "\n",
        "        returns: tensor\n",
        "            output from the transformer, same shape as input\n",
        "\n",
        "        \"\"\"\n",
        "        if self.training: # ~teacher forcing\n",
        "            # add start token to sequences\n",
        "            helper = torch.zeros(1, self.hiddenLenc, dtype=torch.float32).to(\"cuda\")\n",
        "            flattenedInput = torch.vstack([helper, flattenedInput]).to(\"cuda\")\n",
        "            targets = self.encoder(targets, targetsT)[0].to(\"cuda\") # add temporal information\n",
        "            targetsOut = targets.clone().to(\"cuda\") # for latentspace loss\n",
        "            targets = torch.vstack([helper, targets]).to(\"cuda\")\n",
        "\n",
        "            # positional information to input\n",
        "            positionalEmbedding = self.positionalEncodings(flattenedInput.size(0) * 2).to(\"cuda\")\n",
        "\n",
        "            # divide for input and output\n",
        "            idx = int(flattenedInput.size(0))\n",
        "            inputMatrix = positionalEmbedding[:, 0:idx, :]\n",
        "            targetMatrix = positionalEmbedding[:, idx:flattenedInput.size(0)*2, :]\n",
        "\n",
        "            flattenedInput = flattenedInput + inputMatrix\n",
        "            flattenedInput = flattenedInput.squeeze(0)\n",
        "\n",
        "            # add positional information\n",
        "            targets = targets + targetMatrix\n",
        "            targets = targets.squeeze(0)\n",
        "\n",
        "            targetMask = self.get_tgt_mask(targets.size(0))\n",
        "            out = self.transformer(flattenedInput, targets, tgt_mask = targetMask)\n",
        "            out = out[1:, :]\n",
        "\n",
        "            # MSE loss for latent space\n",
        "            loss = nn.MSELoss()(out, targetsOut)\n",
        "\n",
        "            return [out, loss]\n",
        "\n",
        "        if self.training == False: # inference\n",
        "            ### len(targetsT) = self.predictionInterval -> variable prediction length\n",
        "            # add start token to sequences\n",
        "            yInput = torch.zeros(1, self.hiddenLenc, dtype=torch.float32)\n",
        "            helper = torch.zeros(1, self.hiddenLenc, dtype=torch.float32)\n",
        "            flattenedInput = torch.vstack([helper, flattenedInput])\n",
        "\n",
        "            for q in range(self.predictionInterval):\n",
        "                # positional information to input\n",
        "                positionalEmbedding = self.positionalEncodings(flattenedInput.size(0) + (q+1))\n",
        "                positionalEmbedding = positionalEmbedding.squeeze()\n",
        "                flattenedInput = flattenedInput + positionalEmbedding[0:flattenedInput.size(0)]\n",
        "\n",
        "                yInput = yInput + positionalEmbedding[flattenedInput.size(0):]\n",
        "\n",
        "                # get mask\n",
        "                targetMask = self.get_tgt_mask(yInput.size(0))\n",
        "\n",
        "                # forward pass\n",
        "                out = self.transformer(flattenedInput, yInput, tgt_mask=targetMask)\n",
        "                out = out + self.dateEncoder(targetsT[q]) # add temporal information\n",
        "                nextItem = out[-1]\n",
        "                yInput = torch.vstack([yInput, nextItem]).squeeze()\n",
        "\n",
        "            return yInput[1:, :]\n",
        "\n",
        "\n",
        "    def decoder(self, latentOutput, skips, indices):\n",
        "        \"\"\"\n",
        "        transposed convolutions to get the original image shape\n",
        "\n",
        "        latentOutput: tensor\n",
        "            output of latent space\n",
        "        decdate: 1d tensor\n",
        "            dates for predictions\n",
        "        skips: list of tensor\n",
        "            skip connections\n",
        "        indices: list of tensor\n",
        "            indices for maxunpool in recosntruction of the image\n",
        "        return: tensor\n",
        "            output NDSI image snow maks of shape (5, 50,50) # 5 timepoints\n",
        "        \"\"\"\n",
        "\n",
        "        result = torch.zeros((latentOutput.size(0), 50, 50)).to(\"cuda\")\n",
        "        for i in range(latentOutput.size(0)):\n",
        "            image = latentOutput[i, :].clone()\n",
        "\n",
        "            # MLP\n",
        "            s = image.clone().to(\"cuda\")\n",
        "            for layer in self.MLPlistDec:\n",
        "                s = layer(s)\n",
        "\n",
        "            # start deconvolution; image should be (100, 8, 8)\n",
        "            image = torch.reshape(s, (10, 22, 22))\n",
        "\n",
        "            s = image + skips[i][6]\n",
        "            s = self.maxUnPool(image, indices[i][6])\n",
        "            s = self.TCLayer1(s)\n",
        "            s = self.relu(s)\n",
        "\n",
        "            s = s + skips[i][5]\n",
        "            s = self.maxUnPool(s, indices[i][5])\n",
        "            s = self.TCLayer2(s)\n",
        "            s = self.relu(s)\n",
        "\n",
        "            s = s + skips[i][4]\n",
        "            s = self.maxUnPool(s, indices[i][4])\n",
        "            s = self.TCLayer3(s)\n",
        "            s = self.relu(s)\n",
        "\n",
        "            s = s + skips[i][3]\n",
        "            s = self.maxUnPool(s, indices[i][3])\n",
        "            s = self.TCLayer4(s)\n",
        "            s = self.relu(s)\n",
        "\n",
        "            s = s + skips[i][2]\n",
        "            s = self.maxUnPool(s, indices[i][2])\n",
        "            s = self.TCLayer5(s)\n",
        "            s = self.relu(s)\n",
        "\n",
        "            s = s + skips[i][1]\n",
        "            s = self.maxUnPool(s, indices[i][1])\n",
        "            s = self.TCLayer6(s)\n",
        "            s = self.relu(s)\n",
        "\n",
        "            s = s + skips[i][0]\n",
        "            s = self.maxUnPool(s, indices[i][0])\n",
        "            s = self.TCLayer7(s)\n",
        "            s = self.relu(s)\n",
        "\n",
        "            # save in tensor\n",
        "            result[i, :, :] = s\n",
        "\n",
        "        return result\n",
        "\n",
        "    def forward(self, d):\n",
        "        \"\"\"\n",
        "        forward pass\n",
        "        d: list of tensor and encoder and decoder date vectors\n",
        "            input data\n",
        "        returns: list of tensor and int\n",
        "            if training: model predictions and latent space loss\n",
        "            else: model predictions\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # get data\n",
        "        inpt = torch.stack(d[0][0], dim = 0).to(\"cuda\")\n",
        "        s = inpt[:, 9, :, :].float().to(\"cuda\")\n",
        "        datesEncoder = d[0][1]\n",
        "        datesDecoder = d[0][2]\n",
        "        target = d[1].float().to(\"cuda\")\n",
        "\n",
        "        # encoder\n",
        "        res = self.encoder(s, datesEncoder)\n",
        "\n",
        "        # latent space flattenedInput, targets, targetsT, positionalEmbedding\n",
        "        l = self.latentSpace(res[0], target, datesDecoder)\n",
        "\n",
        "        if self.training:\n",
        "            # decoder\n",
        "            s = self.decoder(l[0], res[1], res[2]) # output encoder: [result, skipConnections, poolingIndices]\n",
        "\n",
        "            return [s, l[1]]\n",
        "        elif self.training == False:\n",
        "            # decoder\n",
        "            s = self.decoder(l, res[1], res[2])  # output encoder: [result, skipConnections, poolingIndices]\n",
        "\n",
        "            return s\n",
        "\n"
      ],
      "metadata": {
        "id": "Q1kTjjJQKTON"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W6vN4rg5lTU",
        "outputId": "fae022cd-993e-408c-dd37-71702e44ba58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-39828ed8d21f>:95: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  s = layer(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  0 , batch  0  current loss =  1.1162177324295044\n",
            "epoch  0 , batch  1  current loss =  1.1372985243797302\n",
            "epoch  0 , batch  2  current loss =  1.1387696663538616\n",
            "epoch  0 , batch  3  current loss =  1.121318906545639\n",
            "epoch  0 , batch  4  current loss =  1.109349536895752\n",
            "epoch  0 , batch  5  current loss =  1.1000985503196716\n",
            "epoch  0 , batch  6  current loss =  1.099532621247428\n",
            "epoch  0 , batch  7  current loss =  1.0920673310756683\n",
            "epoch  0 , batch  8  current loss =  1.0853986740112305\n",
            "epoch  0 , batch  9  current loss =  1.078763234615326\n",
            "epoch  0 , batch  10  current loss =  1.0715147961269726\n",
            "epoch  0 , batch  11  current loss =  1.0619187504053116\n",
            "epoch  0 , batch  12  current loss =  1.0431132729236896\n",
            "epoch  0 , batch  13  current loss =  0.9861746621983392\n",
            "epoch  0 , batch  14  current loss =  2.73040766119957\n",
            "epoch  0 , batch  15  current loss =  2.6001441348344088\n",
            "epoch  0 , batch  16  current loss =  2.4942526098559883\n",
            "epoch  0 , batch  17  current loss =  2.4122423314385943\n",
            "epoch  0 , batch  18  current loss =  2.3406908559171775\n",
            "epoch  0 , batch  19  current loss =  2.2722589775919912\n",
            "epoch  0 , batch  20  current loss =  2.207945263101941\n",
            "epoch  0 , batch  21  current loss =  2.13540278646079\n",
            "epoch  0 , batch  22  current loss =  2.0606404374475065\n",
            "epoch  0 , batch  23  current loss =  1.9918171378473442\n",
            "epoch  0 , batch  24  current loss =  1.9276636552810669\n",
            "epoch  0 , batch  25  current loss =  1.8638447385567884\n",
            "epoch  0 , batch  26  current loss =  1.8035214742024739\n",
            "epoch  0 , batch  27  current loss =  1.7528450776423727\n",
            "epoch  0 , batch  28  current loss =  1.7227712612727593\n",
            "epoch  0 , batch  29  current loss =  1.681723486383756\n",
            "epoch  0 , batch  30  current loss =  1.6457234553752407\n",
            "epoch  0 , batch  31  current loss =  1.6118390010669827\n",
            "epoch  0 , batch  32  current loss =  1.5761673486594\n",
            "epoch  0 , batch  33  current loss =  1.5361692160367966\n",
            "epoch  0 , batch  34  current loss =  1.5024328546864645\n",
            "epoch  0 , batch  35  current loss =  1.4676488786935806\n",
            "epoch  0 , batch  36  current loss =  1.4368054617095638\n",
            "epoch  0 , batch  37  current loss =  1.4059721772608005\n",
            "epoch  0 , batch  38  current loss =  1.374733444207754\n",
            "epoch  0 , batch  39  current loss =  1.3453014105558396\n",
            "epoch  0 , batch  40  current loss =  1.3184195124521487\n",
            "epoch  0 , batch  41  current loss =  1.2916248071761358\n",
            "epoch  0 , batch  42  current loss =  1.265384936748549\n",
            "epoch  0 , batch  43  current loss =  1.2408042265610262\n",
            "epoch  0 , batch  44  current loss =  1.2180183596081204\n",
            "epoch  0 , batch  45  current loss =  1.196025894711847\n",
            "epoch  0 , batch  46  current loss =  1.1742555977816278\n",
            "epoch  0 , batch  47  current loss =  1.153371703190108\n",
            "epoch  0 , batch  48  current loss =  1.1329619151597121\n",
            "epoch  0 , batch  49  current loss =  1.1133983901143074\n",
            "epoch  0 , batch  50  current loss =  1.0947453616296543\n",
            "epoch  0 , batch  51  current loss =  1.0763923703477933\n",
            "epoch  0 , batch  52  current loss =  1.0590240561737205\n",
            "epoch  0 , batch  53  current loss =  1.042093416330991\n",
            "epoch  0 , batch  54  current loss =  1.0260017189112576\n",
            "epoch  0 , batch  55  current loss =  1.0103245925690447\n",
            "epoch  0 , batch  56  current loss =  0.9947856531331414\n",
            "epoch  0 , batch  57  current loss =  0.9799030240753601\n",
            "epoch  0 , batch  58  current loss =  0.9655687308917611\n",
            "epoch  0 , batch  59  current loss =  0.9515607471267382\n",
            "epoch  0 , batch  60  current loss =  0.9378026381867831\n",
            "epoch  0 , batch  61  current loss =  0.9245993950434269\n",
            "epoch  0 , batch  62  current loss =  0.9117747905945021\n",
            "epoch  0 , batch  63  current loss =  0.8994206578936428\n",
            "epoch  0 , batch  64  current loss =  0.8873533370403143\n",
            "epoch  0 , batch  65  current loss =  0.8756132572889328\n",
            "epoch  0 , batch  66  current loss =  0.8642251618317703\n",
            "epoch  0 , batch  67  current loss =  0.8530930931515553\n",
            "epoch  0 , batch  68  current loss =  0.8422537383393965\n",
            "epoch  0 , batch  69  current loss =  0.8318364703229495\n",
            "epoch  0 , batch  70  current loss =  0.8216994093127654\n",
            "epoch  0 , batch  71  current loss =  0.8117153326877289\n",
            "epoch  0 , batch  72  current loss =  0.8020419571293543\n",
            "epoch  0 , batch  73  current loss =  0.7927342521379123\n",
            "epoch  0 , batch  74  current loss =  0.7838456490635872\n",
            "epoch  0 , batch  75  current loss =  0.7750050291222962\n",
            "epoch  0 , batch  76  current loss =  0.7663535966308086\n",
            "epoch  0 , batch  77  current loss =  0.7578613478212785\n",
            "epoch  0 , batch  78  current loss =  0.7496426085693927\n",
            "epoch  0 , batch  79  current loss =  0.7415563044138253\n",
            "epoch  0 , batch  80  current loss =  0.7337206251643322\n",
            "epoch  0 , batch  81  current loss =  0.7259787517349895\n",
            "epoch  0 , batch  82  current loss =  0.718436814036714\n",
            "epoch  0 , batch  83  current loss =  0.7112153394236451\n",
            "epoch  0 , batch  84  current loss =  0.703996616601944\n",
            "epoch  0 , batch  85  current loss =  0.6969438409216182\n",
            "epoch  0 , batch  86  current loss =  0.6903731957420536\n",
            "epoch  0 , batch  87  current loss =  0.6836578333750367\n",
            "epoch  0 , batch  88  current loss =  0.6773522751552336\n",
            "epoch  0 , batch  89  current loss =  0.6708811949524615\n",
            "epoch  0 , batch  90  current loss =  0.6644950870137948\n",
            "epoch  0 , batch  91  current loss =  0.6582311963581521\n",
            "epoch  0 , batch  92  current loss =  0.6520693851735002\n",
            "epoch  0 , batch  93  current loss =  0.6464376240334613\n",
            "epoch  0 , batch  94  current loss =  0.6405437563595019\n",
            "epoch  0 , batch  95  current loss =  0.6347817388984064\n",
            "epoch  0 , batch  96  current loss =  0.6295679463553674\n",
            "epoch  0 , batch  97  current loss =  0.6240185306084399\n",
            "epoch  0 , batch  98  current loss =  0.6190009019290558\n",
            "epoch  0 , batch  99  current loss =  0.6136486009508372\n",
            "epoch  0 , batch  100  current loss =  0.6088309949724982\n",
            "epoch  0 , batch  101  current loss =  0.6036990082585344\n",
            "epoch  0 , batch  102  current loss =  0.5986435569605781\n",
            "epoch  0 , batch  103  current loss =  0.5940236380467048\n",
            "epoch  0 , batch  104  current loss =  0.5894761014552343\n",
            "epoch  0 , batch  105  current loss =  0.5847152088470055\n",
            "epoch  0 , batch  106  current loss =  0.5800561533770828\n",
            "epoch  0 , batch  107  current loss =  0.5754423866531363\n",
            "epoch  0 , batch  108  current loss =  0.5709832664066499\n",
            "epoch  0 , batch  109  current loss =  0.5667859057133848\n",
            "epoch  0 , batch  110  current loss =  0.562412394462405\n",
            "epoch  0 , batch  111  current loss =  0.5581018013347473\n",
            "epoch  0 , batch  112  current loss =  0.5541649802991774\n",
            "epoch  0 , batch  113  current loss =  0.5499856692265\n",
            "epoch  0 , batch  114  current loss =  0.5460915717741718\n",
            "epoch  0 , batch  115  current loss =  0.542093610519479\n",
            "epoch  0 , batch  116  current loss =  0.5381314455826058\n",
            "epoch  0 , batch  117  current loss =  0.5342203918528758\n",
            "epoch  0 , batch  118  current loss =  0.5307679783020701\n",
            "epoch  0 , batch  119  current loss =  0.5273470463852088\n",
            "epoch  0 , batch  120  current loss =  0.5239813976790294\n",
            "epoch  0 , batch  121  current loss =  0.5203020671596292\n",
            "epoch  0 , batch  122  current loss =  0.5166920299937086\n",
            "epoch  0 , batch  123  current loss =  0.5134842044884159\n",
            "epoch  0 , batch  124  current loss =  0.5103148710727692\n",
            "epoch  0 , batch  125  current loss =  0.5071696896874716\n",
            "epoch  0 , batch  126  current loss =  0.5038127656292728\n",
            "epoch  0 , batch  127  current loss =  0.5005263548810035\n",
            "epoch  0 , batch  128  current loss =  0.49746899093075314\n",
            "epoch  0 , batch  129  current loss =  0.4942697067100268\n",
            "epoch  0 , batch  130  current loss =  0.4912951990165783\n",
            "epoch  0 , batch  131  current loss =  0.48832889499537874\n",
            "epoch  0 , batch  132  current loss =  0.4852790414614785\n",
            "epoch  0 , batch  133  current loss =  0.4822750429052915\n",
            "epoch  0 , batch  134  current loss =  0.47929104974976294\n",
            "epoch  0 , batch  135  current loss =  0.4764785405029269\n",
            "epoch  0 , batch  136  current loss =  0.4737444655956143\n",
            "epoch  0 , batch  137  current loss =  0.47085998066957446\n",
            "epoch  0 , batch  138  current loss =  0.4680279504052169\n",
            "epoch  0 , batch  139  current loss =  0.46539722084999086\n",
            "epoch  0 , batch  140  current loss =  0.4626302533644311\n",
            "epoch  0 , batch  141  current loss =  0.4600761347568371\n",
            "epoch  0 , batch  142  current loss =  0.45736982037762663\n",
            "epoch  0 , batch  143  current loss =  0.45490343159892493\n",
            "epoch  0 , batch  144  current loss =  0.4524793697328403\n",
            "epoch  0 , batch  145  current loss =  0.45009547364834235\n",
            "epoch  0 , batch  146  current loss =  0.4477253538512048\n",
            "epoch  0 , batch  147  current loss =  0.4452104424504009\n",
            "epoch  0 , batch  148  current loss =  0.4427310313854442\n",
            "epoch  0 , batch  149  current loss =  0.4404548874000708\n",
            "epoch  0 , batch  150  current loss =  0.4381669688205056\n",
            "epoch  0 , batch  151  current loss =  0.4357809264114813\n",
            "epoch  0 , batch  152  current loss =  0.4335457887622266\n",
            "epoch  0 , batch  153  current loss =  0.4313507890449716\n",
            "epoch  0 , batch  154  current loss =  0.4291948808297034\n",
            "epoch  0 , batch  155  current loss =  0.42691748641813415\n",
            "epoch  0 , batch  156  current loss =  0.42469154739645637\n",
            "epoch  0 , batch  157  current loss =  0.4225822542381438\n",
            "epoch  0 , batch  158  current loss =  0.4205073536660686\n",
            "epoch  0 , batch  159  current loss =  0.41832795753143726\n",
            "epoch  0 , batch  160  current loss =  0.41630945465764646\n",
            "epoch  0 , batch  161  current loss =  0.4142203246369774\n",
            "epoch  0 , batch  162  current loss =  0.41212342720638756\n",
            "epoch  0 , batch  163  current loss =  0.41019711579854895\n",
            "epoch  0 , batch  164  current loss =  0.4082943707252994\n",
            "epoch  0 , batch  165  current loss =  0.40626566843634626\n",
            "epoch  0 , batch  166  current loss =  0.40429222155473904\n",
            "epoch  0 , batch  167  current loss =  0.40231369178564774\n",
            "epoch  0 , batch  168  current loss =  0.40051472336935573\n",
            "epoch  0 , batch  169  current loss =  0.39855167856987783\n",
            "epoch  0 , batch  170  current loss =  0.39663076296187283\n",
            "epoch  0 , batch  171  current loss =  0.39489798126525655\n",
            "epoch  0 , batch  172  current loss =  0.3930034901020844\n",
            "epoch  0 , batch  173  current loss =  0.3913328116652609\n",
            "epoch  0 , batch  174  current loss =  0.38967898292200903\n",
            "epoch  0 , batch  175  current loss =  0.3878467395393686\n",
            "epoch  0 , batch  176  current loss =  0.3862713054243454\n",
            "epoch  0 , batch  177  current loss =  0.3844682075334399\n",
            "epoch  0 , batch  178  current loss =  0.3827095691468463\n",
            "epoch  0 , batch  179  current loss =  0.3809531800034973\n",
            "epoch  0 , batch  180  current loss =  0.3794208595848215\n",
            "epoch  0 , batch  181  current loss =  0.37768810827817234\n",
            "epoch  0 , batch  182  current loss =  0.37596186189377895\n",
            "epoch  0 , batch  183  current loss =  0.37425139763028076\n",
            "epoch  0 , batch  184  current loss =  0.37277609272985845\n",
            "epoch  0 , batch  185  current loss =  0.37133035101797635\n",
            "epoch  0 , batch  186  current loss =  0.36966551886124405\n",
            "epoch  0 , batch  187  current loss =  0.3682432057970065\n",
            "epoch  0 , batch  188  current loss =  0.36663446037305725\n",
            "epoch  0 , batch  189  current loss =  0.36522201905517204\n",
            "epoch  0 , batch  190  current loss =  0.3638809032504159\n",
            "epoch  0 , batch  191  current loss =  0.3622926524452244\n",
            "epoch  0 , batch  192  current loss =  0.36089280718657635\n",
            "epoch  0 , batch  193  current loss =  0.35934647675795656\n",
            "epoch  0 , batch  194  current loss =  0.3579922217207077\n",
            "epoch  0 , batch  195  current loss =  0.3564966270434005\n",
            "epoch  0 , batch  196  current loss =  0.354994124718729\n",
            "epoch  0 , batch  197  current loss =  0.3536703364189827\n",
            "epoch  0 , batch  198  current loss =  0.35220408873941433\n",
            "epoch  0 , batch  199  current loss =  0.3507824043929577\n",
            "epoch  0 , batch  200  current loss =  0.3493321856567219\n",
            "epoch  0 , batch  201  current loss =  0.3480952825249717\n",
            "epoch  0 , batch  202  current loss =  0.3466584106787966\n",
            "epoch  0 , batch  203  current loss =  0.34550724768390256\n",
            "epoch  0 , batch  204  current loss =  0.34430313726387374\n",
            "epoch  0 , batch  205  current loss =  0.34310500162825425\n",
            "epoch  0 , batch  206  current loss =  0.34190477695370064\n",
            "epoch  0 , batch  207  current loss =  0.3405545650658986\n",
            "epoch  0 , batch  208  current loss =  0.3392012858112748\n",
            "epoch  0 , batch  209  current loss =  0.33801112790547666\n",
            "epoch  0 , batch  210  current loss =  0.3368290135398578\n",
            "epoch  0 , batch  211  current loss =  0.3355256552052385\n",
            "epoch  0 , batch  212  current loss =  0.33437705235861837\n",
            "epoch  0 , batch  213  current loss =  0.33311100749768946\n",
            "epoch  0 , batch  214  current loss =  0.3318442320754362\n",
            "epoch  0 , batch  215  current loss =  0.33058717298424906\n",
            "epoch  0 , batch  216  current loss =  0.32947626514231554\n",
            "epoch  0 , batch  217  current loss =  0.3282245486086115\n",
            "epoch  0 , batch  218  current loss =  0.3271523940985061\n",
            "epoch  0 , batch  219  current loss =  0.3260834240777926\n",
            "epoch  0 , batch  220  current loss =  0.3250267082884301\n",
            "epoch  0 , batch  221  current loss =  0.32399026942145714\n",
            "epoch  0 , batch  222  current loss =  0.32293720068952964\n",
            "epoch  0 , batch  223  current loss =  0.3217496964082654\n",
            "epoch  0 , batch  224  current loss =  0.3205768013662762\n",
            "epoch  0 , batch  225  current loss =  0.3194086588259819\n",
            "epoch  0 , batch  226  current loss =  0.3184004066930468\n",
            "epoch  0 , batch  227  current loss =  0.31724988662621434\n",
            "epoch  0 , batch  228  current loss =  0.316241199858324\n",
            "epoch  0 , batch  229  current loss =  0.31510999581736066\n",
            "epoch  0 , batch  230  current loss =  0.3140011144019825\n",
            "epoch  0 , batch  231  current loss =  0.3128837495560533\n",
            "epoch  0 , batch  232  current loss =  0.3119279855598452\n",
            "epoch  0 , batch  233  current loss =  0.3108328732415142\n",
            "epoch  0 , batch  234  current loss =  0.309741192548833\n",
            "epoch  0 , batch  235  current loss =  0.3086485771178189\n",
            "epoch  0 , batch  236  current loss =  0.30772365038656485\n",
            "epoch  0 , batch  237  current loss =  0.30665813460006935\n",
            "epoch  0 , batch  238  current loss =  0.30560237975113064\n",
            "epoch  0 , batch  239  current loss =  0.30472059341457985\n",
            "epoch  0 , batch  240  current loss =  0.30384469250240265\n",
            "epoch  0 , batch  241  current loss =  0.3027931889750002\n",
            "epoch  0 , batch  242  current loss =  0.3019341927772932\n",
            "epoch  0 , batch  243  current loss =  0.3009026718066364\n",
            "epoch  0 , batch  244  current loss =  0.30004067609504775\n",
            "epoch  0 , batch  245  current loss =  0.2990233511701832\n",
            "epoch  0 , batch  246  current loss =  0.2980176255800705\n",
            "epoch  0 , batch  247  current loss =  0.29701220765409453\n",
            "epoch  0 , batch  248  current loss =  0.2961847330163042\n",
            "epoch  0 , batch  249  current loss =  0.29519593332707883\n",
            "epoch  0 , batch  250  current loss =  0.2942074857117883\n",
            "epoch  0 , batch  251  current loss =  0.2934063136252382\n",
            "epoch  0 , batch  252  current loss =  0.2926113287598012\n",
            "epoch  0 , batch  253  current loss =  0.2918163899508283\n",
            "epoch  0 , batch  254  current loss =  0.2908601757650282\n",
            "epoch  0 , batch  255  current loss =  0.290070747025311\n",
            "epoch  0 , batch  256  current loss =  0.28927641695343564\n",
            "epoch  0 , batch  257  current loss =  0.28848513120482133\n",
            "epoch  0 , batch  258  current loss =  0.2875669679845392\n",
            "epoch  0 , batch  259  current loss =  0.2867857895934811\n",
            "epoch  0 , batch  260  current loss =  0.28588290963593116\n",
            "epoch  0 , batch  261  current loss =  0.28511475822852766\n",
            "epoch  0 , batch  262  current loss =  0.28422351515791716\n",
            "epoch  0 , batch  263  current loss =  0.2833324501742468\n",
            "epoch  0 , batch  264  current loss =  0.28258321006905357\n",
            "epoch  0 , batch  265  current loss =  0.28169760343275574\n",
            "epoch  0 , batch  266  current loss =  0.2808211698486341\n",
            "epoch  0 , batch  267  current loss =  0.2800940951443653\n",
            "epoch  0 , batch  268  current loss =  0.27937482470528785\n",
            "epoch  0 , batch  269  current loss =  0.2786655596698876\n",
            "epoch  0 , batch  270  current loss =  0.2779583377124419\n",
            "epoch  0 , batch  271  current loss =  0.27724788484492285\n",
            "epoch  0 , batch  272  current loss =  0.27653843711638626\n",
            "epoch  0 , batch  273  current loss =  0.27583311140591643\n",
            "epoch  0 , batch  274  current loss =  0.27514338641004127\n",
            "epoch  0 , batch  275  current loss =  0.2743341914796527\n",
            "epoch  0 , batch  276  current loss =  0.2735313100854628\n",
            "epoch  0 , batch  277  current loss =  0.272828011539021\n",
            "epoch  0 , batch  278  current loss =  0.2721320144084406\n",
            "epoch  0 , batch  279  current loss =  0.27143859510709134\n",
            "epoch  0 , batch  280  current loss =  0.2707453210344306\n",
            "epoch  0 , batch  281  current loss =  0.27005690625531875\n",
            "epoch  0 , batch  282  current loss =  0.2692875811441838\n",
            "epoch  0 , batch  283  current loss =  0.26852380905405315\n",
            "epoch  0 , batch  284  current loss =  0.2678541710110087\n",
            "epoch  0 , batch  285  current loss =  0.2670981786962781\n",
            "epoch  0 , batch  286  current loss =  0.26634373639155345\n",
            "epoch  0 , batch  287  current loss =  0.2655930994854619\n",
            "epoch  0 , batch  288  current loss =  0.26485609701451135\n",
            "epoch  0 , batch  289  current loss =  0.26422114765335775\n",
            "epoch  0 , batch  290  current loss =  0.26348675390596654\n",
            "epoch  0 , batch  291  current loss =  0.26286933486898467\n",
            "epoch  0 , batch  292  current loss =  0.2622518288956974\n",
            "epoch  0 , batch  293  current loss =  0.26163949708447976\n",
            "epoch  0 , batch  294  current loss =  0.2609129054061437\n",
            "epoch  0 , batch  295  current loss =  0.26018820309105356\n",
            "epoch  0 , batch  296  current loss =  0.25946504008087645\n",
            "epoch  0 , batch  297  current loss =  0.2587428722380592\n",
            "epoch  0 , batch  298  current loss =  0.2581612502776061\n",
            "epoch  0 , batch  299  current loss =  0.25758028257638216\n",
            "epoch  0 , batch  300  current loss =  0.25687429485873525\n",
            "epoch  0 , batch  301  current loss =  0.25616490858181423\n",
            "epoch  0 , batch  302  current loss =  0.2555922741199484\n",
            "epoch  0 , batch  303  current loss =  0.25489333333251507\n",
            "epoch  0 , batch  304  current loss =  0.2543322634012973\n",
            "epoch  0 , batch  305  current loss =  0.25363990165341915\n",
            "epoch  0 , batch  306  current loss =  0.2530792892124831\n",
            "epoch  0 , batch  307  current loss =  0.2523922516613618\n",
            "epoch  0 , batch  308  current loss =  0.25171999769544523\n",
            "epoch  0 , batch  309  current loss =  0.25120867217981047\n",
            "epoch  0 , batch  310  current loss =  0.250738386999085\n",
            "epoch  0 , batch  311  current loss =  0.25028435099058044\n",
            "epoch  0 , batch  312  current loss =  0.24994777982084515\n",
            "epoch  0 , batch  313  current loss =  0.24929147919604353\n",
            "epoch  0 , batch  314  current loss =  0.24895152287587288\n",
            "epoch  0 , batch  315  current loss =  0.24839470435311145\n",
            "epoch  0 , batch  316  current loss =  0.2481501078826584\n",
            "epoch  0 , batch  317  current loss =  0.2477226871294233\n",
            "epoch  0 , batch  318  current loss =  0.24711703130724288\n",
            "epoch  0 , batch  319  current loss =  0.24656292365398258\n",
            "epoch  0 , batch  320  current loss =  0.24609202239372277\n",
            "epoch  0 , batch  321  current loss =  0.24547871452125702\n",
            "epoch  0 , batch  322  current loss =  0.2449192436117875\n",
            "epoch  0 , batch  323  current loss =  0.24449822798739246\n",
            "epoch  0 , batch  324  current loss =  0.24388250125142244\n",
            "epoch  0 , batch  325  current loss =  0.2434122784897411\n",
            "epoch  0 , batch  326  current loss =  0.24295506278901655\n",
            "epoch  0 , batch  327  current loss =  0.24247147462035462\n",
            "epoch  0 , batch  328  current loss =  0.24199297078701137\n",
            "epoch  0 , batch  329  current loss =  0.24141765296684972\n",
            "epoch  0 , batch  330  current loss =  0.2409564242824867\n",
            "epoch  0 , batch  331  current loss =  0.24046815199081797\n",
            "epoch  0 , batch  332  current loss =  0.23987295657575308\n",
            "epoch  0 , batch  333  current loss =  0.23928990489440763\n",
            "epoch  0 , batch  334  current loss =  0.23869856360243327\n",
            "epoch  0 , batch  335  current loss =  0.23811066792612628\n",
            "epoch  0 , batch  336  current loss =  0.23754548498094966\n",
            "epoch  0 , batch  337  current loss =  0.23697494658140036\n",
            "epoch  0 , batch  338  current loss =  0.23639354843833102\n",
            "epoch  0 , batch  339  current loss =  0.23580364862128217\n",
            "epoch  0 , batch  340  current loss =  0.2353688444057343\n",
            "epoch  0 , batch  341  current loss =  0.2347901394122351\n",
            "epoch  0 , batch  342  current loss =  0.2342090263376257\n",
            "epoch  0 , batch  343  current loss =  0.23363800271046023\n",
            "epoch  0 , batch  344  current loss =  0.233067223213721\n",
            "epoch  0 , batch  345  current loss =  0.23268031395670308\n",
            "epoch  0 , batch  346  current loss =  0.23211037051952538\n",
            "epoch  0 , batch  347  current loss =  0.2315388197379037\n",
            "epoch  0 , batch  348  current loss =  0.2309707457728065\n",
            "epoch  0 , batch  349  current loss =  0.2304151458718947\n",
            "epoch  0 , batch  350  current loss =  0.22985910767546067\n",
            "epoch  0 , batch  351  current loss =  0.22930459122554483\n",
            "epoch  0 , batch  352  current loss =  0.2289416778505524\n",
            "epoch  0 , batch  353  current loss =  0.2283884257835857\n",
            "epoch  0 , batch  354  current loss =  0.2278378712144536\n",
            "epoch  0 , batch  355  current loss =  0.22729226366062177\n",
            "epoch  0 , batch  356  current loss =  0.22692552744215275\n",
            "epoch  0 , batch  357  current loss =  0.22638584859669209\n",
            "epoch  0 , batch  358  current loss =  0.22600886479933283\n",
            "epoch  0 , batch  359  current loss =  0.22547168790673217\n",
            "epoch  0 , batch  360  current loss =  0.22493835442655635\n",
            "epoch  0 , batch  361  current loss =  0.2245404929519523\n",
            "epoch  0 , batch  362  current loss =  0.22414289459011444\n",
            "epoch  0 , batch  363  current loss =  0.2236245597334026\n",
            "epoch  0 , batch  364  current loss =  0.22332057897766974\n",
            "epoch  0 , batch  365  current loss =  0.22346928685170706\n",
            "epoch  0 , batch  366  current loss =  0.22348527486463984\n",
            "epoch  0 , batch  367  current loss =  0.2231915267386838\n",
            "epoch  0 , batch  368  current loss =  0.22298493769352998\n",
            "epoch  0 , batch  369  current loss =  0.22260260628284634\n",
            "epoch  0 , batch  370  current loss =  0.2223202705865279\n",
            "epoch  0 , batch  371  current loss =  0.22206195960602454\n",
            "epoch  0 , batch  372  current loss =  0.22169077532221101\n",
            "epoch  0 , batch  373  current loss =  0.22144137055956745\n",
            "epoch  0 , batch  374  current loss =  0.22107578629255295\n",
            "epoch  0 , batch  375  current loss =  0.2206614796825229\n",
            "epoch  0 , batch  376  current loss =  0.22037897523818661\n",
            "epoch  0 , batch  377  current loss =  0.22003359252971316\n",
            "epoch  0 , batch  378  current loss =  0.21956643616500504\n",
            "epoch  0 , batch  379  current loss =  0.21920274546075807\n",
            "epoch  0 , batch  380  current loss =  0.21872834428127982\n",
            "epoch  0 , batch  381  current loss =  0.21827976525571022\n",
            "epoch  0 , batch  382  current loss =  0.21781453607949203\n",
            "epoch  0 , batch  383  current loss =  0.21744320022601946\n",
            "epoch  0 , batch  384  current loss =  0.21707812128709508\n",
            "epoch  0 , batch  385  current loss =  0.21660794036877898\n",
            "epoch  0 , batch  386  current loss =  0.21614944991638801\n",
            "epoch  0 , batch  387  current loss =  0.215784723716836\n",
            "epoch  0 , batch  388  current loss =  0.21532510567676746\n",
            "epoch  0 , batch  389  current loss =  0.2149584703338452\n",
            "epoch  0 , batch  390  current loss =  0.21459766254400658\n",
            "epoch  0 , batch  391  current loss =  0.21414230070171916\n",
            "epoch  0 , batch  392  current loss =  0.21378355211656513\n",
            "epoch  0 , batch  393  current loss =  0.21333090919377234\n",
            "epoch  0 , batch  394  current loss =  0.21287678448082525\n",
            "epoch  0 , batch  395  current loss =  0.21252601268240298\n",
            "epoch  0 , batch  396  current loss =  0.2120758335221024\n",
            "epoch  0 , batch  397  current loss =  0.21162800045318939\n",
            "epoch  0 , batch  398  current loss =  0.21128432645011963\n",
            "epoch  0 , batch  399  current loss =  0.21094061037525536\n",
            "epoch  0 , batch  400  current loss =  0.2104947254470459\n",
            "epoch  0 , batch  401  current loss =  0.21015577107223113\n",
            "epoch  0 , batch  402  current loss =  0.209715316908679\n",
            "epoch  0 , batch  403  current loss =  0.20927231198195184\n",
            "epoch  0 , batch  404  current loss =  0.2089481959188426\n",
            "epoch  0 , batch  405  current loss =  0.20853272797035172\n",
            "epoch  0 , batch  406  current loss =  0.20811393114690113\n",
            "epoch  0 , batch  407  current loss =  0.20768367384980416\n",
            "epoch  0 , batch  408  current loss =  0.20725039117183983\n",
            "epoch  0 , batch  409  current loss =  0.2069758180392588\n",
            "epoch  0 , batch  410  current loss =  0.2065430451275151\n",
            "epoch  0 , batch  411  current loss =  0.20611966561833486\n",
            "epoch  0 , batch  412  current loss =  0.20569139736598543\n",
            "epoch  0 , batch  413  current loss =  0.20541660274842366\n",
            "epoch  0 , batch  414  current loss =  0.2049961209072765\n",
            "epoch  0 , batch  415  current loss =  0.20469379403109017\n",
            "epoch  0 , batch  416  current loss =  0.20439414477659215\n",
            "epoch  0 , batch  417  current loss =  0.20408855857657332\n",
            "epoch  0 , batch  418  current loss =  0.20367257027199986\n",
            "epoch  0 , batch  419  current loss =  0.20336523957639224\n",
            "epoch  0 , batch  420  current loss =  0.2029592696081785\n",
            "epoch  0 , batch  421  current loss =  0.2025549079719666\n",
            "epoch  0 , batch  422  current loss =  0.20226792422680284\n",
            "epoch  0 , batch  423  current loss =  0.2020039741380386\n",
            "epoch  0 , batch  424  current loss =  0.20173645358313533\n",
            "epoch  0 , batch  425  current loss =  0.20143737100467016\n",
            "epoch  0 , batch  426  current loss =  0.20115128282099892\n",
            "epoch  0 , batch  427  current loss =  0.2008673893418337\n",
            "epoch  0 , batch  428  current loss =  0.20059287076108245\n",
            "epoch  0 , batch  429  current loss =  0.20028519370961329\n",
            "epoch  0 , batch  430  current loss =  0.20000400762840795\n",
            "epoch  0 , batch  431  current loss =  0.19970778569458397\n",
            "epoch  0 , batch  432  current loss =  0.19943612222462961\n",
            "epoch  0 , batch  433  current loss =  0.19913024869468493\n",
            "epoch  0 , batch  434  current loss =  0.19885927204513687\n",
            "epoch  0 , batch  435  current loss =  0.19851663497216795\n",
            "epoch  0 , batch  436  current loss =  0.19825824389758454\n",
            "epoch  0 , batch  437  current loss =  0.19791963616955907\n",
            "epoch  0 , batch  438  current loss =  0.19757619931665937\n",
            "epoch  0 , batch  439  current loss =  0.19721283958801492\n",
            "epoch  0 , batch  440  current loss =  0.19694173679414656\n",
            "epoch  0 , batch  441  current loss =  0.19657685232192817\n",
            "epoch  0 , batch  442  current loss =  0.19629975000047387\n",
            "epoch  0 , batch  443  current loss =  0.19603456013525525\n",
            "epoch  0 , batch  444  current loss =  0.19566516312404295\n",
            "epoch  0 , batch  445  current loss =  0.19541258392062022\n",
            "epoch  0 , batch  446  current loss =  0.19515129889234467\n",
            "epoch  0 , batch  447  current loss =  0.1948977037308006\n",
            "epoch  0 , batch  448  current loss =  0.19463639109414113\n",
            "epoch  0 , batch  449  current loss =  0.19438144341525104\n",
            "epoch  0 , batch  450  current loss =  0.19401858111393294\n",
            "epoch  0 , batch  451  current loss =  0.19375550453921994\n",
            "epoch  0 , batch  452  current loss =  0.19348907832952655\n",
            "epoch  0 , batch  453  current loss =  0.19313768215789276\n",
            "epoch  0 , batch  454  current loss =  0.1928707084690149\n",
            "epoch  0 , batch  455  current loss =  0.1925224602394002\n",
            "epoch  0 , batch  456  current loss =  0.1922529634104581\n",
            "epoch  0 , batch  457  current loss =  0.19198708163419795\n",
            "epoch  0 , batch  458  current loss =  0.19172036692029382\n",
            "epoch  0 , batch  459  current loss =  0.19138033296507986\n",
            "epoch  0 , batch  460  current loss =  0.1910432060804711\n",
            "epoch  0 , batch  461  current loss =  0.19077839536664934\n",
            "epoch  0 , batch  462  current loss =  0.19044589969383846\n",
            "epoch  0 , batch  463  current loss =  0.19018573010870224\n",
            "epoch  0 , batch  464  current loss =  0.18992658789840436\n",
            "epoch  0 , batch  465  current loss =  0.1896676460217061\n",
            "epoch  0 , batch  466  current loss =  0.18940731130412738\n",
            "epoch  0 , batch  467  current loss =  0.18914627709274745\n",
            "epoch  0 , batch  468  current loss =  0.18882422724655315\n",
            "epoch  0 , batch  469  current loss =  0.18850290062341918\n",
            "epoch  0 , batch  470  current loss =  0.1881835080896783\n",
            "epoch  0 , batch  471  current loss =  0.18792840036942418\n",
            "epoch  0 , batch  472  current loss =  0.18760294955909\n",
            "epoch  0 , batch  473  current loss =  0.18727885866105431\n",
            "epoch  0 , batch  474  current loss =  0.18702809464382497\n",
            "epoch  0 , batch  475  current loss =  0.18678443284486146\n",
            "epoch  0 , batch  476  current loss =  0.18645985102362977\n",
            "epoch  0 , batch  477  current loss =  0.18621866521522965\n",
            "epoch  0 , batch  478  current loss =  0.18589940099026192\n",
            "epoch  0 , batch  479  current loss =  0.18565879178155834\n",
            "epoch  0 , batch  480  current loss =  0.18533849319261103\n",
            "epoch  0 , batch  481  current loss =  0.18510371033504172\n",
            "epoch  0 , batch  482  current loss =  0.18478323889830714\n",
            "epoch  0 , batch  483  current loss =  0.18454987827057312\n",
            "epoch  0 , batch  484  current loss =  0.1843167405652324\n",
            "epoch  0 , batch  485  current loss =  0.18408479083544066\n",
            "epoch  0 , batch  486  current loss =  0.18376757662353208\n",
            "epoch  0 , batch  487  current loss =  0.1834537637626111\n",
            "epoch  0 , batch  488  current loss =  0.183140911897054\n",
            "epoch  0 , batch  489  current loss =  0.18282755878278795\n",
            "epoch  0 , batch  490  current loss =  0.18251680486784327\n",
            "epoch  0 , batch  491  current loss =  0.18220708032736813\n",
            "epoch  0 , batch  492  current loss =  0.18189791594886998\n",
            "epoch  0 , batch  493  current loss =  0.18158671372619115\n",
            "epoch  0 , batch  494  current loss =  0.1812761586761535\n",
            "epoch  0 , batch  495  current loss =  0.1810670726399328\n",
            "epoch  0 , batch  496  current loss =  0.18087761863031737\n",
            "epoch  0 , batch  497  current loss =  0.1805726484728446\n",
            "epoch  0 , batch  498  current loss =  0.18029617928416433\n",
            "epoch  0 , batch  499  current loss =  0.1801164096556604\n",
            "epoch  0 , batch  500  current loss =  0.1799415709216616\n",
            "epoch  0 , batch  501  current loss =  0.17964408420159877\n",
            "epoch  0 , batch  502  current loss =  0.17980407289123795\n",
            "epoch  0 , batch  503  current loss =  0.18002893516631235\n",
            "epoch  0 , batch  504  current loss =  0.18039607371360358\n",
            "epoch  0 , batch  505  current loss =  0.18077377139741607\n",
            "epoch  0 , batch  506  current loss =  0.18114935788573952\n",
            "epoch  0 , batch  507  current loss =  0.18143867385595686\n",
            "epoch  0 , batch  508  current loss =  0.18178142330193917\n",
            "epoch  0 , batch  509  current loss =  0.1820901734097039\n",
            "epoch  0 , batch  510  current loss =  0.18218271869896327\n",
            "epoch  0 , batch  511  current loss =  0.18229407236140105\n",
            "epoch  0 , batch  512  current loss =  0.18251618895076985\n",
            "epoch  0 , batch  513  current loss =  0.18287305494386283\n",
            "epoch  0 , batch  514  current loss =  0.18321114183557266\n",
            "epoch  0 , batch  515  current loss =  0.18344400552743972\n",
            "epoch  0 , batch  516  current loss =  0.18373821114822214\n",
            "epoch  0 , batch  517  current loss =  0.1838763182565685\n",
            "epoch  0 , batch  518  current loss =  0.183891139404134\n",
            "epoch  0 , batch  519  current loss =  0.18396388018288864\n",
            "epoch  0 , batch  520  current loss =  0.1841233876746527\n",
            "epoch  0 , batch  521  current loss =  0.1842504236882845\n",
            "epoch  0 , batch  522  current loss =  0.1841345435510573\n",
            "epoch  0 , batch  523  current loss =  0.18424191051127234\n",
            "epoch  0 , batch  524  current loss =  0.18435168150989784\n",
            "epoch  0 , batch  525  current loss =  0.18460979772653757\n",
            "epoch  0 , batch  526  current loss =  0.18488761865705308\n",
            "epoch  0 , batch  527  current loss =  0.1850927137790925\n",
            "epoch  0 , batch  528  current loss =  0.1852938638003596\n",
            "epoch  0 , batch  529  current loss =  0.185550395423933\n",
            "epoch  0 , batch  530  current loss =  0.18576617354769154\n",
            "epoch  0 , batch  531  current loss =  0.1859087397106328\n",
            "epoch  0 , batch  532  current loss =  0.18594692519902623\n",
            "epoch  0 , batch  533  current loss =  0.1857680563504497\n",
            "epoch  0 , batch  534  current loss =  0.18692694134731716\n",
            "epoch  0 , batch  535  current loss =  0.18720163683990823\n",
            "epoch  0 , batch  536  current loss =  0.1874836723890773\n",
            "epoch  0 , batch  537  current loss =  0.18767636710757105\n",
            "epoch  0 , batch  538  current loss =  0.1879385637433885\n",
            "epoch  0 , batch  539  current loss =  0.18800286298479746\n",
            "epoch  0 , batch  540  current loss =  0.18824654708439123\n",
            "epoch  0 , batch  541  current loss =  0.18804804570766723\n",
            "epoch  0 , batch  542  current loss =  0.18942559327635208\n",
            "epoch  0 , batch  543  current loss =  0.18961516622221097\n",
            "epoch  0 , batch  544  current loss =  0.18983741487043165\n",
            "epoch  0 , batch  545  current loss =  0.1900600446797498\n",
            "epoch  0 , batch  546  current loss =  0.19027790772835887\n",
            "epoch  0 , batch  547  current loss =  0.19053847361424\n",
            "epoch  0 , batch  548  current loss =  0.1907807317391065\n",
            "epoch  0 , batch  549  current loss =  0.19095150971615857\n",
            "epoch  0 , batch  550  current loss =  0.1911730120725889\n",
            "epoch  0 , batch  551  current loss =  0.1913939219582286\n",
            "epoch  0 , batch  552  current loss =  0.19154573911986233\n",
            "epoch  0 , batch  553  current loss =  0.19176268483098555\n",
            "epoch  0 , batch  554  current loss =  0.19189978872534927\n",
            "epoch  0 , batch  555  current loss =  0.19211852617173208\n",
            "epoch  0 , batch  556  current loss =  0.19233855291786378\n",
            "epoch  0 , batch  557  current loss =  0.19246458998917998\n",
            "epoch  0 , batch  558  current loss =  0.19257890066208588\n",
            "epoch  0 , batch  559  current loss =  0.19277865830476262\n",
            "epoch  0 , batch  560  current loss =  0.19288042806248296\n",
            "epoch  0 , batch  561  current loss =  0.19306762221855944\n",
            "epoch  0 , batch  562  current loss =  0.19314008897921436\n",
            "epoch  0 , batch  563  current loss =  0.19327596278781903\n",
            "epoch  0 , batch  564  current loss =  0.19327819689910497\n",
            "epoch  0 , batch  565  current loss =  0.19320637171647048\n",
            "epoch  0 , batch  566  current loss =  0.19310187775398582\n",
            "epoch  0 , batch  567  current loss =  0.19283307971708266\n",
            "epoch  0 , batch  568  current loss =  0.19263748961757796\n",
            "epoch  0 , batch  569  current loss =  0.19235916807920786\n",
            "epoch  0 , batch  570  current loss =  0.19222032106212372\n",
            "epoch  0 , batch  571  current loss =  0.1921253931786787\n",
            "epoch  0 , batch  572  current loss =  0.19203279541568086\n",
            "epoch  0 , batch  573  current loss =  0.1919042054102967\n",
            "epoch  0 , batch  574  current loss =  0.1916447653297497\n",
            "epoch  0 , batch  575  current loss =  0.19136942643348853\n",
            "epoch  0 , batch  576  current loss =  0.19119128202325447\n",
            "epoch  0 , batch  577  current loss =  0.19092051358410128\n",
            "epoch  0 , batch  578  current loss =  0.19072608071635117\n",
            "epoch  0 , batch  579  current loss =  0.19049116329065172\n",
            "epoch  0 , batch  580  current loss =  0.19026234445583698\n",
            "epoch  0 , batch  581  current loss =  0.19009578557960255\n",
            "epoch  0 , batch  582  current loss =  0.18990662181190826\n",
            "epoch  0 , batch  583  current loss =  0.1897084710015979\n",
            "epoch  0 , batch  584  current loss =  0.1895170016007291\n",
            "epoch  0 , batch  585  current loss =  0.1892427319927783\n",
            "epoch  0 , batch  586  current loss =  0.18905140427488587\n",
            "epoch  0 , batch  587  current loss =  0.18880051186587027\n",
            "epoch  0 , batch  588  current loss =  0.18861932036465315\n",
            "epoch  0 , batch  589  current loss =  0.1884249855495863\n",
            "epoch  0 , batch  590  current loss =  0.188227686239958\n",
            "epoch  0 , batch  591  current loss =  0.1879636653088587\n",
            "epoch  0 , batch  592  current loss =  0.18769748583373191\n",
            "epoch  0 , batch  593  current loss =  0.18750532241444093\n",
            "epoch  0 , batch  594  current loss =  0.18725678464006476\n",
            "epoch  0 , batch  595  current loss =  0.18706974524992123\n",
            "epoch  0 , batch  596  current loss =  0.18680516899667893\n",
            "epoch  0 , batch  597  current loss =  0.1865403727787145\n",
            "epoch  0 , batch  598  current loss =  0.18627416056725438\n",
            "epoch  0 , batch  599  current loss =  0.18601111067769427\n",
            "epoch  0 , batch  600  current loss =  0.18575204117611027\n",
            "epoch  0 , batch  601  current loss =  0.18549080909325733\n",
            "epoch  0 , batch  602  current loss =  0.185316462567073\n",
            "epoch  0 , batch  603  current loss =  0.1850491771258611\n",
            "epoch  0 , batch  604  current loss =  0.18478340575209826\n",
            "epoch  0 , batch  605  current loss =  0.18451926606114055\n",
            "epoch  0 , batch  606  current loss =  0.18425782668347512\n",
            "epoch  0 , batch  607  current loss =  0.1840978549505388\n",
            "epoch  0 , batch  608  current loss =  0.1839359537751853\n",
            "epoch  0 , batch  609  current loss =  0.18367204089939107\n",
            "epoch  0 , batch  610  current loss =  0.1834100311448258\n",
            "epoch  0 , batch  611  current loss =  0.18324032183614822\n",
            "epoch  0 , batch  612  current loss =  0.1830687358319079\n",
            "epoch  0 , batch  613  current loss =  0.1828926357316272\n",
            "epoch  0 , batch  614  current loss =  0.1827121552413072\n",
            "epoch  0 , batch  615  current loss =  0.1825284773072639\n",
            "epoch  0 , batch  616  current loss =  0.18234250076247963\n",
            "epoch  0 , batch  617  current loss =  0.18215660971489925\n",
            "epoch  0 , batch  618  current loss =  0.18197106677130082\n",
            "epoch  0 , batch  619  current loss =  0.18173891700083208\n",
            "epoch  0 , batch  620  current loss =  0.18155273063267294\n",
            "epoch  0 , batch  621  current loss =  0.18132337647523145\n",
            "epoch  0 , batch  622  current loss =  0.18109196545272158\n",
            "epoch  0 , batch  623  current loss =  0.1809096080609239\n",
            "epoch  0 , batch  624  current loss =  0.18072630845308305\n",
            "epoch  0 , batch  625  current loss =  0.18054370811810128\n",
            "epoch  0 , batch  626  current loss =  0.18030434719136837\n",
            "epoch  0 , batch  627  current loss =  0.18006444859443008\n",
            "epoch  0 , batch  628  current loss =  0.1798871701527002\n",
            "epoch  0 , batch  629  current loss =  0.17971117902724515\n",
            "epoch  0 , batch  630  current loss =  0.17953653066240474\n",
            "epoch  0 , batch  631  current loss =  0.17929567119012338\n",
            "epoch  0 , batch  632  current loss =  0.17912267757606168\n",
            "epoch  0 , batch  633  current loss =  0.17888208585923496\n",
            "epoch  0 , batch  634  current loss =  0.1787124810989682\n",
            "epoch  0 , batch  635  current loss =  0.17847310619007023\n",
            "epoch  0 , batch  636  current loss =  0.17823472891581862\n",
            "epoch  0 , batch  637  current loss =  0.1779962490928771\n",
            "epoch  0 , batch  638  current loss =  0.17782962603235095\n",
            "epoch  0 , batch  639  current loss =  0.1775921115593519\n",
            "epoch  0 , batch  640  current loss =  0.17742741400268447\n",
            "epoch  0 , batch  641  current loss =  0.17726315413471136\n",
            "epoch  0 , batch  642  current loss =  0.1770988722530253\n",
            "epoch  0 , batch  643  current loss =  0.17686402813028196\n",
            "epoch  0 , batch  644  current loss =  0.1766298486425202\n",
            "epoch  0 , batch  645  current loss =  0.17646465777209022\n",
            "epoch  0 , batch  646  current loss =  0.17629930387658443\n",
            "epoch  0 , batch  647  current loss =  0.17606747645114398\n",
            "epoch  0 , batch  648  current loss =  0.1759019079883633\n",
            "epoch  0 , batch  649  current loss =  0.1756737002816338\n",
            "epoch  0 , batch  650  current loss =  0.17544670870810886\n",
            "epoch  0 , batch  651  current loss =  0.17521908405334033\n",
            "epoch  0 , batch  652  current loss =  0.17499150757665016\n",
            "epoch  0 , batch  653  current loss =  0.17482820760162507\n",
            "epoch  0 , batch  654  current loss =  0.17466606561179834\n",
            "epoch  0 , batch  655  current loss =  0.17443872089554532\n",
            "epoch  0 , batch  656  current loss =  0.1742783507454114\n",
            "epoch  0 , batch  657  current loss =  0.17405184624450548\n",
            "epoch  0 , batch  658  current loss =  0.17389212807637608\n",
            "epoch  0 , batch  659  current loss =  0.17366634460843422\n",
            "epoch  0 , batch  660  current loss =  0.1734410712041761\n",
            "epoch  0 , batch  661  current loss =  0.17328364059914275\n",
            "epoch  0 , batch  662  current loss =  0.17312759799295602\n",
            "epoch  0 , batch  663  current loss =  0.17297168464276447\n",
            "epoch  0 , batch  664  current loss =  0.1727479600452615\n",
            "epoch  0 , batch  665  current loss =  0.1725249927345518\n",
            "epoch  0 , batch  666  current loss =  0.17230240406951625\n",
            "epoch  0 , batch  667  current loss =  0.17208018961423885\n",
            "epoch  0 , batch  668  current loss =  0.17185825684145428\n",
            "epoch  0 , batch  669  current loss =  0.17163625721777998\n",
            "epoch  0 , batch  670  current loss =  0.1714876992086673\n",
            "epoch  0 , batch  671  current loss =  0.17126806518007515\n",
            "epoch  0 , batch  672  current loss =  0.17112228689219852\n",
            "epoch  0 , batch  673  current loss =  0.1709785857804407\n",
            "epoch  0 , batch  674  current loss =  0.1707588332174001\n",
            "epoch  0 , batch  675  current loss =  0.1706138106790432\n",
            "epoch  0 , batch  676  current loss =  0.17039550866166808\n",
            "epoch  0 , batch  677  current loss =  0.1701779050922851\n",
            "epoch  0 , batch  678  current loss =  0.17003262169187305\n",
            "epoch  0 , batch  679  current loss =  0.1698868630453944\n",
            "epoch  0 , batch  680  current loss =  0.16973988807017582\n",
            "epoch  0 , batch  681  current loss =  0.16952481602326777\n",
            "epoch  0 , batch  682  current loss =  0.16931036254868326\n",
            "epoch  0 , batch  683  current loss =  0.16909672658106215\n",
            "epoch  0 , batch  684  current loss =  0.16888338654526394\n",
            "epoch  0 , batch  685  current loss =  0.16866985578144256\n",
            "epoch  0 , batch  686  current loss =  0.1685259746390312\n",
            "epoch  0 , batch  687  current loss =  0.16838232102955497\n",
            "epoch  0 , batch  688  current loss =  0.16817007417667587\n",
            "epoch  0 , batch  689  current loss =  0.16795847960140395\n",
            "epoch  0 , batch  690  current loss =  0.1677465498468983\n",
            "epoch  0 , batch  691  current loss =  0.16760788127952228\n",
            "epoch  0 , batch  692  current loss =  0.1674696614946982\n",
            "epoch  0 , batch  693  current loss =  0.16725951636086622\n",
            "epoch  0 , batch  694  current loss =  0.167050148187567\n",
            "epoch  0 , batch  695  current loss =  0.1669132636121378\n",
            "epoch  0 , batch  696  current loss =  0.1667765187449657\n",
            "epoch  0 , batch  697  current loss =  0.1666400091172887\n",
            "epoch  0 , batch  698  current loss =  0.16643316757056506\n",
            "epoch  0 , batch  699  current loss =  0.16622719733310598\n",
            "epoch  0 , batch  700  current loss =  0.16609037404457444\n",
            "epoch  0 , batch  701  current loss =  0.165952314301646\n",
            "epoch  0 , batch  702  current loss =  0.16574874344900525\n",
            "epoch  0 , batch  703  current loss =  0.165609900675587\n",
            "epoch  0 , batch  704  current loss =  0.16547135193402884\n",
            "epoch  0 , batch  705  current loss =  0.16533263466154718\n",
            "epoch  0 , batch  706  current loss =  0.165194137066687\n",
            "epoch  0 , batch  707  current loss =  0.1649967061176812\n",
            "epoch  0 , batch  708  current loss =  0.16485747001403142\n",
            "epoch  0 , batch  709  current loss =  0.16466296680376563\n",
            "epoch  0 , batch  710  current loss =  0.16452488151238773\n",
            "epoch  0 , batch  711  current loss =  0.1643309739700864\n",
            "epoch  0 , batch  712  current loss =  0.1641363071363947\n",
            "epoch  0 , batch  713  current loss =  0.16400032821541824\n",
            "epoch  0 , batch  714  current loss =  0.16380554747383494\n",
            "epoch  0 , batch  715  current loss =  0.1636102478743099\n",
            "epoch  0 , batch  716  current loss =  0.16341493738817786\n",
            "epoch  0 , batch  717  current loss =  0.16328279865765555\n",
            "epoch  0 , batch  718  current loss =  0.1630869154249718\n",
            "epoch  0 , batch  719  current loss =  0.16289102567308064\n",
            "epoch  0 , batch  720  current loss =  0.1626948190054723\n",
            "epoch  0 , batch  721  current loss =  0.16256997818153074\n",
            "epoch  0 , batch  722  current loss =  0.16244579251098187\n",
            "epoch  0 , batch  723  current loss =  0.1623216399958985\n",
            "epoch  0 , batch  724  current loss =  0.16212642716179634\n",
            "epoch  0 , batch  725  current loss =  0.16200135807576013\n",
            "epoch  0 , batch  726  current loss =  0.16180868256719272\n",
            "epoch  0 , batch  727  current loss =  0.16161598905839109\n",
            "epoch  0 , batch  728  current loss =  0.16142348418796668\n",
            "epoch  0 , batch  729  current loss =  0.1612987440130482\n",
            "epoch  0 , batch  730  current loss =  0.1611734973075615\n",
            "epoch  0 , batch  731  current loss =  0.16098278754039622\n",
            "epoch  0 , batch  732  current loss =  0.16085673348487725\n",
            "epoch  0 , batch  733  current loss =  0.16073107950095017\n",
            "epoch  0 , batch  734  current loss =  0.1605423636405038\n",
            "epoch  0 , batch  735  current loss =  0.1604163855258578\n",
            "epoch  0 , batch  736  current loss =  0.1602893200711811\n",
            "epoch  0 , batch  737  current loss =  0.16010401952446396\n",
            "epoch  0 , batch  738  current loss =  0.15991924586422307\n",
            "epoch  0 , batch  739  current loss =  0.15979275644278607\n",
            "epoch  0 , batch  740  current loss =  0.159608591264981\n",
            "epoch  0 , batch  741  current loss =  0.15942482940220046\n",
            "epoch  0 , batch  742  current loss =  0.15930067379564086\n",
            "epoch  0 , batch  743  current loss =  0.15911673698624376\n",
            "epoch  0 , batch  744  current loss =  0.15893291988028777\n",
            "epoch  0 , batch  745  current loss =  0.15874878962302016\n",
            "epoch  0 , batch  746  current loss =  0.1586281429911394\n",
            "epoch  0 , batch  747  current loss =  0.15850949495592537\n",
            "epoch  0 , batch  748  current loss =  0.15832563289733373\n",
            "epoch  0 , batch  749  current loss =  0.15814203635106483\n",
            "epoch  0 , batch  750  current loss =  0.1580253879002701\n",
            "epoch  0 , batch  751  current loss =  0.15791002446240646\n",
            "epoch  0 , batch  752  current loss =  0.15772774129373776\n",
            "epoch  0 , batch  753  current loss =  0.15754576847550092\n",
            "epoch  0 , batch  754  current loss =  0.15742967987297388\n",
            "epoch  0 , batch  755  current loss =  0.15731423074212023\n",
            "epoch  0 , batch  756  current loss =  0.1571338990877925\n",
            "epoch  0 , batch  757  current loss =  0.15701773320386153\n",
            "epoch  0 , batch  758  current loss =  0.1568384386417462\n",
            "epoch  0 , batch  759  current loss =  0.15672171955290987\n",
            "epoch  0 , batch  760  current loss =  0.15654371136924283\n",
            "epoch  0 , batch  761  current loss =  0.15642686397951888\n",
            "epoch  0 , batch  762  current loss =  0.15625030731936113\n",
            "epoch  0 , batch  763  current loss =  0.15613399102737766\n",
            "epoch  0 , batch  764  current loss =  0.15601701473488527\n",
            "epoch  0 , batch  765  current loss =  0.15589970475738726\n",
            "epoch  0 , batch  766  current loss =  0.15578202913956038\n",
            "epoch  0 , batch  767  current loss =  0.1556095698470017\n",
            "epoch  0 , batch  768  current loss =  0.15543805539452984\n",
            "epoch  0 , batch  769  current loss =  0.15526673248303788\n",
            "epoch  0 , batch  770  current loss =  0.15509504955092834\n",
            "epoch  0 , batch  771  current loss =  0.15492283851825125\n",
            "epoch  0 , batch  772  current loss =  0.154749986302363\n",
            "epoch  0 , batch  773  current loss =  0.15457749847582605\n",
            "epoch  0 , batch  774  current loss =  0.15446722995369666\n",
            "epoch  0 , batch  775  current loss =  0.15435842648820625\n",
            "epoch  0 , batch  776  current loss =  0.1542502970625305\n",
            "epoch  0 , batch  777  current loss =  0.15414273272960383\n",
            "epoch  0 , batch  778  current loss =  0.15403514685867228\n",
            "epoch  0 , batch  779  current loss =  0.1539270908261339\n",
            "epoch  0 , batch  780  current loss =  0.1538183730663243\n",
            "epoch  0 , batch  781  current loss =  0.15364862382507233\n",
            "epoch  0 , batch  782  current loss =  0.15353884634063467\n",
            "epoch  0 , batch  783  current loss =  0.1533702802796829\n",
            "epoch  0 , batch  784  current loss =  0.15320253522627672\n",
            "epoch  0 , batch  785  current loss =  0.15309216465526107\n",
            "epoch  0 , batch  786  current loss =  0.15298181280418\n",
            "epoch  0 , batch  787  current loss =  0.15287167876296995\n",
            "epoch  0 , batch  788  current loss =  0.152707031343713\n",
            "epoch  0 , batch  789  current loss =  0.15254284187538336\n",
            "epoch  0 , batch  790  current loss =  0.1523788775518706\n",
            "epoch  0 , batch  791  current loss =  0.15226938226965792\n",
            "epoch  0 , batch  792  current loss =  0.15210548267332183\n",
            "epoch  0 , batch  793  current loss =  0.15194156490998245\n",
            "epoch  0 , batch  794  current loss =  0.15177770079400554\n",
            "epoch  0 , batch  795  current loss =  0.15167062467048367\n",
            "epoch  0 , batch  796  current loss =  0.15150645954611536\n",
            "epoch  0 , batch  797  current loss =  0.151401216241258\n",
            "epoch  0 , batch  798  current loss =  0.15129667261058233\n",
            "epoch  0 , batch  799  current loss =  0.15119260757928715\n",
            "epoch  0 , batch  800  current loss =  0.15108914562406833\n",
            "epoch  0 , batch  801  current loss =  0.1509854780798058\n",
            "epoch  0 , batch  802  current loss =  0.15082315945183652\n",
            "epoch  0 , batch  803  current loss =  0.15071920025167032\n",
            "epoch  0 , batch  804  current loss =  0.15055826708026554\n",
            "epoch  0 , batch  805  current loss =  0.15039768407846946\n",
            "epoch  0 , batch  806  current loss =  0.15023741681853486\n",
            "epoch  0 , batch  807  current loss =  0.1500774050629375\n",
            "epoch  0 , batch  808  current loss =  0.14997467021049174\n",
            "epoch  0 , batch  809  current loss =  0.14987221832996533\n",
            "epoch  0 , batch  810  current loss =  0.14977072495347032\n",
            "epoch  0 , batch  811  current loss =  0.14966837040566164\n",
            "epoch  0 , batch  812  current loss =  0.14951021772285816\n",
            "epoch  0 , batch  813  current loss =  0.14935245729653343\n",
            "epoch  0 , batch  814  current loss =  0.14925049617886543\n",
            "epoch  0 , batch  815  current loss =  0.14914835205612084\n",
            "epoch  0 , batch  816  current loss =  0.14904653140078122\n",
            "epoch  0 , batch  817  current loss =  0.14894423616963523\n",
            "epoch  0 , batch  818  current loss =  0.1487898357753825\n",
            "epoch  0 , batch  819  current loss =  0.14863577858976473\n",
            "epoch  0 , batch  820  current loss =  0.1484816695532867\n",
            "epoch  0 , batch  821  current loss =  0.1483273654337746\n",
            "epoch  0 , batch  822  current loss =  0.14817276238978705\n",
            "epoch  0 , batch  823  current loss =  0.14807497351475565\n",
            "epoch  0 , batch  824  current loss =  0.14791990913676492\n",
            "epoch  0 , batch  825  current loss =  0.14782374374315901\n",
            "epoch  0 , batch  826  current loss =  0.1477281293609915\n",
            "epoch  0 , batch  827  current loss =  0.14763260937345343\n",
            "epoch  0 , batch  828  current loss =  0.14753658211687792\n",
            "epoch  0 , batch  829  current loss =  0.14744053217750716\n",
            "epoch  0 , batch  830  current loss =  0.1473441029238715\n",
            "epoch  0 , batch  831  current loss =  0.14719162245567602\n",
            "epoch  0 , batch  832  current loss =  0.1470945878546922\n",
            "epoch  0 , batch  833  current loss =  0.14699770708521492\n",
            "epoch  0 , batch  834  current loss =  0.1468476250946165\n",
            "epoch  0 , batch  835  current loss =  0.14675032037296934\n",
            "epoch  0 , batch  836  current loss =  0.14660162449755407\n",
            "epoch  0 , batch  837  current loss =  0.14650458579789624\n",
            "epoch  0 , batch  838  current loss =  0.1464076723339518\n",
            "epoch  0 , batch  839  current loss =  0.1462607742065475\n",
            "epoch  0 , batch  840  current loss =  0.14616444913335985\n",
            "epoch  0 , batch  841  current loss =  0.14606804981155236\n",
            "epoch  0 , batch  842  current loss =  0.14592161799382203\n",
            "epoch  0 , batch  843  current loss =  0.145775495723808\n",
            "epoch  0 , batch  844  current loss =  0.1456801269798589\n",
            "epoch  0 , batch  845  current loss =  0.14558499802265043\n",
            "epoch  0 , batch  846  current loss =  0.14549033735233327\n",
            "epoch  0 , batch  847  current loss =  0.14539601768911728\n",
            "epoch  0 , batch  848  current loss =  0.14530144804744194\n",
            "epoch  0 , batch  849  current loss =  0.14515638001482276\n",
            "epoch  0 , batch  850  current loss =  0.145011644869535\n",
            "epoch  0 , batch  851  current loss =  0.1449176821914532\n",
            "epoch  0 , batch  852  current loss =  0.14482394286408443\n",
            "epoch  0 , batch  853  current loss =  0.1446799432413884\n",
            "epoch  0 , batch  854  current loss =  0.14453607366926838\n",
            "epoch  0 , batch  855  current loss =  0.14444337475165794\n",
            "epoch  0 , batch  856  current loss =  0.14435110793882588\n",
            "epoch  0 , batch  857  current loss =  0.1442076384778067\n",
            "epoch  0 , batch  858  current loss =  0.144115695714673\n",
            "epoch  0 , batch  859  current loss =  0.14402426822587502\n",
            "epoch  0 , batch  860  current loss =  0.14388156647206599\n",
            "epoch  0 , batch  861  current loss =  0.1437390972676486\n",
            "epoch  0 , batch  862  current loss =  0.14364829896663253\n",
            "epoch  0 , batch  863  current loss =  0.14355804175095357\n",
            "epoch  0 , batch  864  current loss =  0.14346787378062748\n",
            "epoch  0 , batch  865  current loss =  0.1433264736783009\n",
            "epoch  0 , batch  866  current loss =  0.14318535734943383\n",
            "epoch  0 , batch  867  current loss =  0.143044296778687\n",
            "epoch  0 , batch  868  current loss =  0.14295532650199597\n",
            "epoch  0 , batch  869  current loss =  0.14286677026157749\n",
            "epoch  0 , batch  870  current loss =  0.14272596927019676\n",
            "epoch  0 , batch  871  current loss =  0.1425852111344217\n",
            "epoch  0 , batch  872  current loss =  0.14249768068017554\n",
            "epoch  0 , batch  873  current loss =  0.14235709621880024\n",
            "epoch  0 , batch  874  current loss =  0.14227051707463606\n",
            "epoch  0 , batch  875  current loss =  0.14213026404066104\n",
            "epoch  0 , batch  876  current loss =  0.14199011551774826\n",
            "epoch  0 , batch  877  current loss =  0.14190471313834394\n",
            "epoch  0 , batch  878  current loss =  0.14181942723064225\n",
            "epoch  0 , batch  879  current loss =  0.14173404967031358\n",
            "epoch  0 , batch  880  current loss =  0.14159500862341734\n",
            "epoch  0 , batch  881  current loss =  0.14150903775629137\n",
            "epoch  0 , batch  882  current loss =  0.14137101445098155\n",
            "epoch  0 , batch  883  current loss =  0.14128486337603757\n",
            "epoch  0 , batch  884  current loss =  0.14114762354368543\n",
            "epoch  0 , batch  885  current loss =  0.14101057417446886\n",
            "epoch  0 , batch  886  current loss =  0.1409253132589405\n",
            "epoch  0 , batch  887  current loss =  0.14084037062963722\n",
            "epoch  0 , batch  888  current loss =  0.1407555491507422\n",
            "epoch  0 , batch  889  current loss =  0.14067073298011268\n",
            "epoch  0 , batch  890  current loss =  0.14053530715757148\n",
            "epoch  0 , batch  891  current loss =  0.1404004080133354\n",
            "epoch  0 , batch  892  current loss =  0.14031642687289006\n",
            "epoch  0 , batch  893  current loss =  0.14023314308275112\n",
            "epoch  0 , batch  894  current loss =  0.14014956567582137\n",
            "epoch  0 , batch  895  current loss =  0.14006602543979949\n",
            "epoch  0 , batch  896  current loss =  0.13993272416858438\n",
            "epoch  0 , batch  897  current loss =  0.13979978964379874\n",
            "epoch  0 , batch  898  current loss =  0.1396667473950528\n",
            "epoch  0 , batch  899  current loss =  0.13953351022882593\n",
            "epoch  0 , batch  900  current loss =  0.13940011749414108\n",
            "epoch  0 , batch  901  current loss =  0.13926652320629676\n",
            "epoch  0 , batch  902  current loss =  0.13913274898811565\n",
            "epoch  0 , batch  903  current loss =  0.1390554679195042\n",
            "epoch  0 , batch  904  current loss =  0.13897927215744776\n",
            "epoch  0 , batch  905  current loss =  0.13890350180745914\n",
            "epoch  0 , batch  906  current loss =  0.13882689504928336\n",
            "epoch  0 , batch  907  current loss =  0.13874931054165185\n",
            "epoch  0 , batch  908  current loss =  0.13861749511789961\n",
            "epoch  0 , batch  909  current loss =  0.13848632674173011\n",
            "epoch  0 , batch  910  current loss =  0.13835542403063383\n",
            "epoch  0 , batch  911  current loss =  0.1382245590967502\n",
            "epoch  0 , batch  912  current loss =  0.13814662575215786\n",
            "epoch  0 , batch  913  current loss =  0.13801574530141097\n",
            "epoch  0 , batch  914  current loss =  0.137938285533522\n",
            "epoch  0 , batch  915  current loss =  0.13780760499709754\n",
            "epoch  0 , batch  916  current loss =  0.13767722928073894\n",
            "epoch  0 , batch  917  current loss =  0.13760034556344378\n",
            "epoch  0 , batch  918  current loss =  0.13747031211861135\n",
            "epoch  0 , batch  919  current loss =  0.13734048820789094\n",
            "epoch  0 , batch  920  current loss =  0.13721084091953942\n",
            "epoch  0 , batch  921  current loss =  0.1371355628041215\n",
            "epoch  0 , batch  922  current loss =  0.1370604223050056\n",
            "epoch  0 , batch  923  current loss =  0.1369852413951512\n",
            "epoch  0 , batch  924  current loss =  0.13690979444900075\n",
            "epoch  0 , batch  925  current loss =  0.13683383839031918\n",
            "epoch  0 , batch  926  current loss =  0.13670609813854662\n",
            "epoch  0 , batch  927  current loss =  0.13662942956956425\n",
            "epoch  0 , batch  928  current loss =  0.13655241465334358\n",
            "epoch  0 , batch  929  current loss =  0.13642666723418942\n",
            "epoch  0 , batch  930  current loss =  0.1363014530462526\n",
            "epoch  0 , batch  931  current loss =  0.13617628530395326\n",
            "epoch  0 , batch  932  current loss =  0.13605093079971475\n",
            "epoch  0 , batch  933  current loss =  0.13597516570343962\n",
            "epoch  0 , batch  934  current loss =  0.13589995677936523\n",
            "epoch  0 , batch  935  current loss =  0.1358251649265488\n",
            "epoch  0 , batch  936  current loss =  0.13575045657895798\n",
            "epoch  0 , batch  937  current loss =  0.13562531597110064\n",
            "epoch  0 , batch  938  current loss =  0.13550045343633657\n",
            "epoch  0 , batch  939  current loss =  0.13542630960174062\n",
            "epoch  0 , batch  940  current loss =  0.13535296673095695\n",
            "epoch  0 , batch  941  current loss =  0.135228720717053\n",
            "epoch  0 , batch  942  current loss =  0.13510471187563552\n",
            "epoch  0 , batch  943  current loss =  0.13498083283824813\n",
            "epoch  0 , batch  944  current loss =  0.13490849920602702\n",
            "epoch  0 , batch  945  current loss =  0.13483632761142345\n",
            "epoch  0 , batch  946  current loss =  0.13471289914113163\n",
            "epoch  0 , batch  947  current loss =  0.1346407394329644\n",
            "epoch  0 , batch  948  current loss =  0.13456838236860655\n",
            "epoch  0 , batch  949  current loss =  0.13449559423092164\n",
            "epoch  0 , batch  950  current loss =  0.13442202934409667\n",
            "epoch  0 , batch  951  current loss =  0.13430074347425722\n",
            "epoch  0 , batch  952  current loss =  0.1341799782200131\n",
            "epoch  0 , batch  953  current loss =  0.1340593859939924\n",
            "epoch  0 , batch  954  current loss =  0.13393866360109513\n",
            "epoch  0 , batch  955  current loss =  0.13381771566385256\n",
            "epoch  0 , batch  956  current loss =  0.13374666329337012\n",
            "epoch  0 , batch  957  current loss =  0.13367599759072002\n",
            "epoch  0 , batch  958  current loss =  0.13355485153334978\n",
            "epoch  0 , batch  959  current loss =  0.13348439428955317\n",
            "epoch  0 , batch  960  current loss =  0.1334143411387514\n",
            "epoch  0 , batch  961  current loss =  0.13334426102606026\n",
            "epoch  0 , batch  962  current loss =  0.13322393324802537\n",
            "epoch  0 , batch  963  current loss =  0.13310389467263864\n",
            "epoch  0 , batch  964  current loss =  0.1330337506656202\n",
            "epoch  0 , batch  965  current loss =  0.1329142201256092\n",
            "epoch  0 , batch  966  current loss =  0.13284428490300768\n",
            "epoch  0 , batch  967  current loss =  0.13272523554619248\n",
            "epoch  0 , batch  968  current loss =  0.13265544232423154\n",
            "epoch  0 , batch  969  current loss =  0.13253686634113188\n",
            "epoch  0 , batch  970  current loss =  0.13246727817098156\n",
            "epoch  0 , batch  971  current loss =  0.1323975548933839\n",
            "epoch  0 , batch  972  current loss =  0.13227979296517825\n",
            "epoch  0 , batch  973  current loss =  0.13216228913362818\n",
            "epoch  0 , batch  974  current loss =  0.132092869933217\n",
            "epoch  0 , batch  975  current loss =  0.13197565117095153\n",
            "epoch  0 , batch  976  current loss =  0.13185849445114178\n",
            "epoch  0 , batch  977  current loss =  0.1317413182117822\n",
            "epoch  0 , batch  978  current loss =  0.13167374144261657\n",
            "epoch  0 , batch  979  current loss =  0.13155655281580225\n",
            "epoch  0 , batch  980  current loss =  0.13143944216058584\n",
            "epoch  0 , batch  981  current loss =  0.13137364894902814\n",
            "epoch  0 , batch  982  current loss =  0.1312566661671001\n",
            "epoch  0 , batch  983  current loss =  0.13119137160692032\n",
            "epoch  0 , batch  984  current loss =  0.13107469335652244\n",
            "epoch  0 , batch  985  current loss =  0.13095818618293587\n",
            "epoch  0 , batch  986  current loss =  0.1308418348386295\n",
            "epoch  0 , batch  987  current loss =  0.13072560481003181\n",
            "epoch  0 , batch  988  current loss =  0.13066196499657945\n",
            "epoch  0 , batch  989  current loss =  0.13054601115861325\n",
            "epoch  0 , batch  990  current loss =  0.13043021858415138\n",
            "epoch  0 , batch  991  current loss =  0.13036688236564759\n",
            "epoch  0 , batch  992  current loss =  0.13025141862096323\n",
            "epoch  0 , batch  993  current loss =  0.1301876981189883\n",
            "epoch  0 , batch  994  current loss =  0.13012372627292745\n",
            "epoch  0 , batch  995  current loss =  0.1300591925237642\n",
            "epoch  0 , batch  996  current loss =  0.12999391558588508\n",
            "epoch  0 , batch  997  current loss =  0.12992771184687804\n",
            "epoch  0 , batch  998  current loss =  0.12986130957809594\n",
            "epoch  0 , batch  999  current loss =  0.12979485300742089\n",
            "epoch  0 , batch  1000  current loss =  0.12968596560205078\n",
            "epoch  0 , batch  1001  current loss =  0.12961942156936654\n",
            "epoch  0 , batch  1002  current loss =  0.12951141402147642\n",
            "epoch  0 , batch  1003  current loss =  0.12940287146999305\n",
            "epoch  0 , batch  1004  current loss =  0.12933687245964412\n",
            "epoch  0 , batch  1005  current loss =  0.12922660851291942\n",
            "epoch  0 , batch  1006  current loss =  0.12916153962719287\n",
            "epoch  0 , batch  1007  current loss =  0.1290501860277136\n",
            "epoch  0 , batch  1008  current loss =  0.12893859431981983\n",
            "epoch  0 , batch  1009  current loss =  0.12882688258691588\n",
            "epoch  0 , batch  1010  current loss =  0.1287150782644454\n",
            "epoch  0 , batch  1011  current loss =  0.12860322667639187\n",
            "epoch  0 , batch  1012  current loss =  0.1284914005838283\n",
            "epoch  0 , batch  1013  current loss =  0.12837960214043656\n",
            "epoch  0 , batch  1014  current loss =  0.12832592300098078\n",
            "epoch  0 , batch  1015  current loss =  0.12821431705676842\n",
            "epoch  0 , batch  1016  current loss =  0.12810289063431404\n",
            "epoch  0 , batch  1017  current loss =  0.1280525102699084\n",
            "epoch  0 , batch  1018  current loss =  0.1280013410935692\n",
            "epoch  0 , batch  1019  current loss =  0.12794882880122055\n",
            "epoch  0 , batch  1020  current loss =  0.1278942709133744\n",
            "epoch  0 , batch  1021  current loss =  0.12778411871332623\n",
            "epoch  0 , batch  1022  current loss =  0.12767448004713886\n",
            "epoch  0 , batch  1023  current loss =  0.12761478427364636\n",
            "epoch  0 , batch  1024  current loss =  0.12750634437018052\n",
            "epoch  0 , batch  1025  current loss =  0.12739854227464653\n",
            "epoch  0 , batch  1026  current loss =  0.12733721358659872\n",
            "epoch  0 , batch  1027  current loss =  0.12727554599711027\n",
            "epoch  0 , batch  1028  current loss =  0.12716953679140877\n",
            "epoch  0 , batch  1029  current loss =  0.12710767202169715\n",
            "epoch  0 , batch  1030  current loss =  0.12700262641449298\n",
            "epoch  0 , batch  1031  current loss =  0.12689774358092787\n",
            "epoch  0 , batch  1032  current loss =  0.12679266200886835\n",
            "epoch  0 , batch  1033  current loss =  0.12673166341362682\n",
            "epoch  0 , batch  1034  current loss =  0.12662599719610912\n",
            "epoch  0 , batch  1035  current loss =  0.12652012696184045\n",
            "epoch  0 , batch  1036  current loss =  0.12646065193714293\n",
            "epoch  0 , batch  1037  current loss =  0.12635445649608223\n",
            "epoch  0 , batch  1038  current loss =  0.1262960760478608\n",
            "epoch  0 , batch  1039  current loss =  0.1262380922311702\n",
            "epoch  0 , batch  1040  current loss =  0.12613197202337093\n",
            "epoch  0 , batch  1041  current loss =  0.1260745430860361\n",
            "epoch  0 , batch  1042  current loss =  0.12601716395231788\n",
            "epoch  0 , batch  1043  current loss =  0.12595971145888368\n",
            "epoch  0 , batch  1044  current loss =  0.12590209861958854\n",
            "epoch  0 , batch  1045  current loss =  0.12579710007045083\n",
            "epoch  0 , batch  1046  current loss =  0.12573894174234032\n",
            "epoch  0 , batch  1047  current loss =  0.12563464148876521\n",
            "epoch  0 , batch  1048  current loss =  0.12553064733853758\n",
            "epoch  0 , batch  1049  current loss =  0.12547234806897384\n",
            "epoch  0 , batch  1050  current loss =  0.12536880130889327\n",
            "epoch  0 , batch  1051  current loss =  0.12526544642160176\n",
            "epoch  0 , batch  1052  current loss =  0.1251621689047781\n",
            "epoch  0 , batch  1053  current loss =  0.12510449539576665\n",
            "epoch  0 , batch  1054  current loss =  0.12504694837441235\n",
            "epoch  0 , batch  1055  current loss =  0.12498949216167217\n",
            "epoch  0 , batch  1056  current loss =  0.12493201526271333\n",
            "epoch  0 , batch  1057  current loss =  0.12487443760371923\n",
            "epoch  0 , batch  1058  current loss =  0.1248167243138012\n",
            "epoch  0 , batch  1059  current loss =  0.12471500837490103\n",
            "epoch  0 , batch  1060  current loss =  0.12461360100951681\n",
            "epoch  0 , batch  1061  current loss =  0.12451227572913195\n",
            "epoch  0 , batch  1062  current loss =  0.12441090518838234\n",
            "epoch  0 , batch  1063  current loss =  0.12435399804568913\n",
            "epoch  0 , batch  1064  current loss =  0.12425241709857339\n",
            "epoch  0 , batch  1065  current loss =  0.12419633705284286\n",
            "epoch  0 , batch  1066  current loss =  0.1240946952901229\n",
            "epoch  0 , batch  1067  current loss =  0.12403935799985594\n",
            "epoch  0 , batch  1068  current loss =  0.1239842118702348\n",
            "epoch  0 , batch  1069  current loss =  0.12392913444733647\n",
            "epoch  0 , batch  1070  current loss =  0.12382798089474495\n",
            "epoch  0 , batch  1071  current loss =  0.12372702249124257\n",
            "epoch  0 , batch  1072  current loss =  0.12367198837249221\n",
            "epoch  0 , batch  1073  current loss =  0.12361692057426471\n",
            "epoch  0 , batch  1074  current loss =  0.12351655491389507\n",
            "epoch  0 , batch  1075  current loss =  0.12346144721819068\n",
            "epoch  0 , batch  1076  current loss =  0.12340621724067569\n",
            "epoch  0 , batch  1077  current loss =  0.1233066699203235\n",
            "epoch  0 , batch  1078  current loss =  0.12325138355276449\n",
            "epoch  0 , batch  1079  current loss =  0.12319609780485431\n",
            "epoch  0 , batch  1080  current loss =  0.1230975063319536\n",
            "epoch  0 , batch  1081  current loss =  0.12304226534747538\n",
            "epoch  0 , batch  1082  current loss =  0.12294410669269765\n",
            "epoch  0 , batch  1083  current loss =  0.12288920124958362\n",
            "epoch  0 , batch  1084  current loss =  0.12279118959736164\n",
            "epoch  0 , batch  1085  current loss =  0.12273669298772544\n",
            "epoch  0 , batch  1086  current loss =  0.12263874180114587\n",
            "epoch  0 , batch  1087  current loss =  0.12258463004015058\n",
            "epoch  0 , batch  1088  current loss =  0.12248674582748155\n",
            "epoch  0 , batch  1089  current loss =  0.1224331331464949\n",
            "epoch  0 , batch  1090  current loss =  0.1223796001651711\n",
            "epoch  0 , batch  1091  current loss =  0.12228196632499114\n",
            "epoch  0 , batch  1092  current loss =  0.1221844480907219\n",
            "epoch  0 , batch  1093  current loss =  0.12208697985912208\n",
            "epoch  0 , batch  1094  current loss =  0.12198950681308089\n",
            "epoch  0 , batch  1095  current loss =  0.121892012524874\n",
            "epoch  0 , batch  1096  current loss =  0.12184057047687397\n",
            "epoch  0 , batch  1097  current loss =  0.12174309338807707\n",
            "epoch  0 , batch  1098  current loss =  0.12169247586280107\n",
            "epoch  0 , batch  1099  current loss =  0.12159515607848086\n",
            "epoch  0 , batch  1100  current loss =  0.12154489388261379\n",
            "epoch  0 , batch  1101  current loss =  0.12149458789704418\n",
            "epoch  0 , batch  1102  current loss =  0.12144398785948564\n",
            "epoch  0 , batch  1103  current loss =  0.12139289739180653\n",
            "epoch  0 , batch  1104  current loss =  0.12134129471857757\n",
            "epoch  0 , batch  1105  current loss =  0.12124556066488568\n",
            "epoch  0 , batch  1106  current loss =  0.12119332916930305\n",
            "epoch  0 , batch  1107  current loss =  0.12109861139036607\n",
            "epoch  0 , batch  1108  current loss =  0.12104626280835908\n",
            "epoch  0 , batch  1109  current loss =  0.12099386670517626\n",
            "epoch  0 , batch  1110  current loss =  0.12090036644106589\n",
            "epoch  0 , batch  1111  current loss =  0.12080694384212948\n",
            "epoch  0 , batch  1112  current loss =  0.12075484867616885\n",
            "epoch  0 , batch  1113  current loss =  0.12066112451934168\n",
            "epoch  0 , batch  1114  current loss =  0.12060960616682544\n",
            "epoch  0 , batch  1115  current loss =  0.12051566327441364\n",
            "epoch  0 , batch  1116  current loss =  0.12046481639350246\n",
            "epoch  0 , batch  1117  current loss =  0.12041426417776026\n",
            "epoch  0 , batch  1118  current loss =  0.12036386086048693\n",
            "epoch  0 , batch  1119  current loss =  0.12031352082017942\n",
            "epoch  0 , batch  1120  current loss =  0.12026309147294374\n",
            "epoch  0 , batch  1121  current loss =  0.12021252471512041\n",
            "epoch  0 , batch  1122  current loss =  0.12011980317542968\n",
            "epoch  0 , batch  1123  current loss =  0.12002737984455644\n",
            "epoch  0 , batch  1124  current loss =  0.11997669305321243\n",
            "epoch  0 , batch  1125  current loss =  0.11988464461103558\n",
            "epoch  0 , batch  1126  current loss =  0.11983414220490626\n",
            "epoch  0 , batch  1127  current loss =  0.1197836552259466\n",
            "epoch  0 , batch  1128  current loss =  0.11969211779491921\n",
            "epoch  0 , batch  1129  current loss =  0.11964180350913542\n",
            "epoch  0 , batch  1130  current loss =  0.1195505532608174\n",
            "epoch  0 , batch  1131  current loss =  0.11950043303638617\n",
            "epoch  0 , batch  1132  current loss =  0.1194504116820492\n",
            "epoch  0 , batch  1133  current loss =  0.11940042724885454\n",
            "epoch  0 , batch  1134  current loss =  0.1193097986617343\n",
            "epoch  0 , batch  1135  current loss =  0.11921928769295616\n",
            "epoch  0 , batch  1136  current loss =  0.11916969298559553\n",
            "epoch  0 , batch  1137  current loss =  0.11907922834410006\n",
            "epoch  0 , batch  1138  current loss =  0.1190300826694656\n",
            "epoch  0 , batch  1139  current loss =  0.11898111922976871\n",
            "epoch  0 , batch  1140  current loss =  0.11893228989740953\n",
            "epoch  0 , batch  1141  current loss =  0.1188421769323718\n",
            "epoch  0 , batch  1142  current loss =  0.11875219157410496\n",
            "epoch  0 , batch  1143  current loss =  0.11866225244825823\n",
            "epoch  0 , batch  1144  current loss =  0.11857228246497145\n",
            "epoch  0 , batch  1145  current loss =  0.11852469444713745\n",
            "epoch  0 , batch  1146  current loss =  0.11843466944992542\n",
            "epoch  0 , batch  1147  current loss =  0.11834466896743517\n",
            "epoch  0 , batch  1148  current loss =  0.11825464534337386\n",
            "epoch  0 , batch  1149  current loss =  0.11820856666516351\n",
            "epoch  0 , batch  1150  current loss =  0.11811857601687584\n",
            "epoch  0 , batch  1151  current loss =  0.11802864889371752\n",
            "epoch  0 , batch  1152  current loss =  0.11798348908893383\n",
            "epoch  0 , batch  1153  current loss =  0.11789369887948371\n",
            "epoch  0 , batch  1154  current loss =  0.11784872666275475\n",
            "epoch  0 , batch  1155  current loss =  0.11775916130410888\n",
            "epoch  0 , batch  1156  current loss =  0.11766972571575987\n",
            "epoch  0 , batch  1157  current loss =  0.1175804335128561\n",
            "epoch  0 , batch  1158  current loss =  0.11753554901910096\n",
            "epoch  0 , batch  1159  current loss =  0.11749041040652784\n",
            "epoch  0 , batch  1160  current loss =  0.1174450356137845\n",
            "epoch  0 , batch  1161  current loss =  0.11739932770701365\n",
            "epoch  0 , batch  1162  current loss =  0.117353255180634\n",
            "epoch  0 , batch  1163  current loss =  0.11730690251818228\n",
            "epoch  0 , batch  1164  current loss =  0.11726034632824009\n",
            "epoch  0 , batch  1165  current loss =  0.11721362979958029\n",
            "epoch  0 , batch  1166  current loss =  0.1171667789138579\n",
            "epoch  0 , batch  1167  current loss =  0.11708323165697798\n",
            "epoch  0 , batch  1168  current loss =  0.11699973179825715\n",
            "epoch  0 , batch  1169  current loss =  0.11695297774182171\n",
            "epoch  0 , batch  1170  current loss =  0.11686828501528904\n",
            "epoch  0 , batch  1171  current loss =  0.11678292534120203\n",
            "epoch  0 , batch  1172  current loss =  0.1167371407109936\n",
            "epoch  0 , batch  1173  current loss =  0.11665081780394333\n",
            "epoch  0 , batch  1174  current loss =  0.11660639425462231\n",
            "epoch  0 , batch  1175  current loss =  0.11651985024079858\n",
            "epoch  0 , batch  1176  current loss =  0.11647670829277755\n",
            "epoch  0 , batch  1177  current loss =  0.11639022639144611\n",
            "epoch  0 , batch  1178  current loss =  0.11634795632342902\n",
            "epoch  0 , batch  1179  current loss =  0.11626168423158638\n",
            "epoch  0 , batch  1180  current loss =  0.1162203066271811\n",
            "epoch  0 , batch  1181  current loss =  0.1161342929322241\n",
            "epoch  0 , batch  1182  current loss =  0.11609269518858657\n",
            "epoch  0 , batch  1183  current loss =  0.11605070101182177\n",
            "epoch  0 , batch  1184  current loss =  0.11596534912580553\n",
            "epoch  0 , batch  1185  current loss =  0.11592248203641221\n",
            "epoch  0 , batch  1186  current loss =  0.11583771222924599\n",
            "epoch  0 , batch  1187  current loss =  0.11579433394837435\n",
            "epoch  0 , batch  1188  current loss =  0.1157101587101792\n",
            "epoch  0 , batch  1189  current loss =  0.11562621536422052\n",
            "epoch  0 , batch  1190  current loss =  0.11554238315058621\n",
            "epoch  0 , batch  1191  current loss =  0.11549907812501785\n",
            "epoch  0 , batch  1192  current loss =  0.11541528372860639\n",
            "epoch  0 , batch  1193  current loss =  0.11537240050698769\n",
            "epoch  0 , batch  1194  current loss =  0.11528866685942502\n",
            "epoch  0 , batch  1195  current loss =  0.11524610181127279\n",
            "epoch  0 , batch  1196  current loss =  0.11516248582611008\n",
            "epoch  0 , batch  1197  current loss =  0.11512029004004941\n",
            "epoch  0 , batch  1198  current loss =  0.11507817243751732\n",
            "epoch  0 , batch  1199  current loss =  0.1150360274904718\n",
            "epoch  0 , batch  1200  current loss =  0.11495291338078088\n",
            "epoch  0 , batch  1201  current loss =  0.1149106210906573\n",
            "epoch  0 , batch  1202  current loss =  0.11482791097390335\n",
            "epoch  0 , batch  1203  current loss =  0.11474535265624944\n",
            "epoch  0 , batch  1204  current loss =  0.11470318473489081\n",
            "epoch  0 , batch  1205  current loss =  0.11466119588301772\n",
            "epoch  0 , batch  1206  current loss =  0.11461913589752327\n",
            "epoch  0 , batch  1207  current loss =  0.1145371316557454\n",
            "epoch  0 , batch  1208  current loss =  0.11445527673738248\n",
            "epoch  0 , batch  1209  current loss =  0.1144133481135484\n",
            "epoch  0 , batch  1210  current loss =  0.11433164264951409\n",
            "epoch  0 , batch  1211  current loss =  0.11424998464231861\n",
            "epoch  0 , batch  1212  current loss =  0.11416830174910536\n",
            "epoch  0 , batch  1213  current loss =  0.11408660262961193\n",
            "epoch  0 , batch  1214  current loss =  0.11404622799099841\n",
            "epoch  0 , batch  1215  current loss =  0.11400613538372502\n",
            "epoch  0 , batch  1216  current loss =  0.11396612433660025\n",
            "epoch  0 , batch  1217  current loss =  0.11388459967369785\n",
            "epoch  0 , batch  1218  current loss =  0.11384455601045276\n",
            "epoch  0 , batch  1219  current loss =  0.11376334568561955\n",
            "epoch  0 , batch  1220  current loss =  0.11368229544899265\n",
            "epoch  0 , batch  1221  current loss =  0.11360135418477235\n",
            "epoch  0 , batch  1222  current loss =  0.11356146911498789\n",
            "epoch  0 , batch  1223  current loss =  0.11352161052134618\n",
            "epoch  0 , batch  1224  current loss =  0.11348166242621992\n",
            "epoch  0 , batch  1225  current loss =  0.11340132672233327\n",
            "epoch  0 , batch  1226  current loss =  0.1133212051456817\n",
            "epoch  0 , batch  1227  current loss =  0.11328121440497255\n",
            "epoch  0 , batch  1228  current loss =  0.11324121731661557\n",
            "epoch  0 , batch  1229  current loss =  0.1131616074819027\n",
            "epoch  0 , batch  1230  current loss =  0.11312163882804875\n",
            "epoch  0 , batch  1231  current loss =  0.11304233122583744\n",
            "epoch  0 , batch  1232  current loss =  0.1129630912466931\n",
            "epoch  0 , batch  1233  current loss =  0.1129236249630513\n",
            "epoch  0 , batch  1234  current loss =  0.11284438844332811\n",
            "epoch  0 , batch  1235  current loss =  0.11276517114767799\n",
            "epoch  0 , batch  1236  current loss =  0.11268595590955588\n",
            "epoch  0 , batch  1237  current loss =  0.11264774360301301\n",
            "epoch  0 , batch  1238  current loss =  0.11260970980695677\n",
            "epoch  0 , batch  1239  current loss =  0.11253066775464123\n",
            "epoch  0 , batch  1240  current loss =  0.11245172866076039\n",
            "epoch  0 , batch  1241  current loss =  0.11241424933972734\n",
            "epoch  0 , batch  1242  current loss =  0.11233550248321443\n",
            "epoch  0 , batch  1243  current loss =  0.11225688080243479\n",
            "epoch  0 , batch  1244  current loss =  0.11221974719555143\n",
            "epoch  0 , batch  1245  current loss =  0.11218252369123444\n",
            "epoch  0 , batch  1246  current loss =  0.1121042968552939\n",
            "epoch  0 , batch  1247  current loss =  0.11202623608346002\n",
            "epoch  0 , batch  1248  current loss =  0.11198889846884436\n",
            "epoch  0 , batch  1249  current loss =  0.11195152420774102\n",
            "epoch  0 , batch  1250  current loss =  0.11191392546783177\n",
            "epoch  0 , batch  1251  current loss =  0.11183668937111577\n",
            "epoch  0 , batch  1252  current loss =  0.1117988897313595\n",
            "epoch  0 , batch  1253  current loss =  0.11172221802870196\n",
            "epoch  0 , batch  1254  current loss =  0.11164572739090578\n",
            "epoch  0 , batch  1255  current loss =  0.11156925665671422\n",
            "epoch  0 , batch  1256  current loss =  0.1115319278956574\n",
            "epoch  0 , batch  1257  current loss =  0.1114947668458846\n",
            "epoch  0 , batch  1258  current loss =  0.11141834568862549\n",
            "epoch  0 , batch  1259  current loss =  0.11134199520484322\n",
            "epoch  0 , batch  1260  current loss =  0.11130545769569233\n",
            "epoch  0 , batch  1261  current loss =  0.11126908934756334\n",
            "epoch  0 , batch  1262  current loss =  0.11123275932924481\n",
            "epoch  0 , batch  1263  current loss =  0.11119631929264133\n",
            "epoch  0 , batch  1264  current loss =  0.11112055558519872\n",
            "epoch  0 , batch  1265  current loss =  0.11108410408746858\n",
            "epoch  0 , batch  1266  current loss =  0.11100877164300728\n",
            "epoch  0 , batch  1267  current loss =  0.11097228520311862\n",
            "epoch  0 , batch  1268  current loss =  0.11089730755498646\n",
            "epoch  0 , batch  1269  current loss =  0.11086081779877266\n",
            "epoch  0 , batch  1270  current loss =  0.11078614528334159\n",
            "epoch  0 , batch  1271  current loss =  0.11071154695888688\n",
            "epoch  0 , batch  1272  current loss =  0.11063699490842113\n",
            "epoch  0 , batch  1273  current loss =  0.11060129131630554\n",
            "epoch  0 , batch  1274  current loss =  0.11056570314747445\n",
            "epoch  0 , batch  1275  current loss =  0.11053025734619613\n",
            "epoch  0 , batch  1276  current loss =  0.11045596997283498\n",
            "epoch  0 , batch  1277  current loss =  0.11038181437281469\n",
            "epoch  0 , batch  1278  current loss =  0.11030774172817803\n",
            "epoch  0 , batch  1279  current loss =  0.11023372845156701\n",
            "epoch  0 , batch  1280  current loss =  0.11015975202239649\n",
            "epoch  0 , batch  1281  current loss =  0.11008580741523395\n",
            "epoch  0 , batch  1282  current loss =  0.11005202763287797\n",
            "epoch  0 , batch  1283  current loss =  0.10997820648472072\n",
            "epoch  0 , batch  1284  current loss =  0.10990446023932923\n",
            "epoch  0 , batch  1285  current loss =  0.10987149945621033\n",
            "epoch  0 , batch  1286  current loss =  0.10983858281991096\n",
            "epoch  0 , batch  1287  current loss =  0.10976516127352087\n",
            "epoch  0 , batch  1288  current loss =  0.10973199441251573\n",
            "epoch  0 , batch  1289  current loss =  0.10965889700320225\n",
            "epoch  0 , batch  1290  current loss =  0.10962540906724844\n",
            "epoch  0 , batch  1291  current loss =  0.10955272275224998\n",
            "epoch  0 , batch  1292  current loss =  0.10951895761675988\n",
            "epoch  0 , batch  1293  current loss =  0.10944677122769275\n",
            "epoch  0 , batch  1294  current loss =  0.1093747628334924\n",
            "epoch  0 , batch  1295  current loss =  0.10934126283757871\n",
            "epoch  0 , batch  1296  current loss =  0.1092694567806542\n",
            "epoch  0 , batch  1297  current loss =  0.10923625796226834\n",
            "epoch  0 , batch  1298  current loss =  0.10920316688042475\n",
            "epoch  0 , batch  1299  current loss =  0.10913166586954433\n",
            "epoch  0 , batch  1300  current loss =  0.10909873723975175\n",
            "epoch  0 , batch  1301  current loss =  0.10906589043594199\n",
            "epoch  0 , batch  1302  current loss =  0.108994842186736\n",
            "epoch  0 , batch  1303  current loss =  0.1089239332980642\n",
            "epoch  0 , batch  1304  current loss =  0.10889144780835087\n",
            "epoch  0 , batch  1305  current loss =  0.10882076954862722\n",
            "epoch  0 , batch  1306  current loss =  0.10878862336337818\n",
            "epoch  0 , batch  1307  current loss =  0.1087565912675705\n",
            "epoch  0 , batch  1308  current loss =  0.10872461585394862\n",
            "epoch  0 , batch  1309  current loss =  0.10865460134943136\n",
            "epoch  0 , batch  1310  current loss =  0.10862255479549403\n",
            "epoch  0 , batch  1311  current loss =  0.10855299171568576\n",
            "epoch  0 , batch  1312  current loss =  0.10852103122217072\n",
            "epoch  0 , batch  1313  current loss =  0.10845187867820104\n",
            "epoch  0 , batch  1314  current loss =  0.10842015568818543\n",
            "epoch  0 , batch  1315  current loss =  0.10838851354249093\n",
            "epoch  0 , batch  1316  current loss =  0.10835692952984581\n",
            "epoch  0 , batch  1317  current loss =  0.10832540739584878\n",
            "epoch  0 , batch  1318  current loss =  0.10829381004803397\n",
            "epoch  0 , batch  1319  current loss =  0.10822629281249123\n",
            "epoch  0 , batch  1320  current loss =  0.10815899675383453\n",
            "epoch  0 , batch  1321  current loss =  0.1081277272261048\n",
            "epoch  0 , batch  1322  current loss =  0.10809662418393524\n",
            "epoch  0 , batch  1323  current loss =  0.1080656611055327\n",
            "epoch  0 , batch  1324  current loss =  0.10799887950901153\n",
            "epoch  0 , batch  1325  current loss =  0.1079682273583748\n",
            "epoch  0 , batch  1326  current loss =  0.10793771742637456\n",
            "epoch  0 , batch  1327  current loss =  0.10790732724196558\n",
            "epoch  0 , batch  1328  current loss =  0.10787697302554562\n",
            "epoch  0 , batch  1329  current loss =  0.10784672642882942\n",
            "epoch  0 , batch  1330  current loss =  0.10781650095940151\n",
            "epoch  0 , batch  1331  current loss =  0.10775165641806214\n",
            "epoch  0 , batch  1332  current loss =  0.10768706493278084\n",
            "epoch  0 , batch  1333  current loss =  0.10765722108937834\n",
            "epoch  0 , batch  1334  current loss =  0.10762765082541141\n",
            "epoch  0 , batch  1335  current loss =  0.10759818860438435\n",
            "epoch  0 , batch  1336  current loss =  0.1075688339275271\n",
            "epoch  0 , batch  1337  current loss =  0.10750512166021138\n",
            "epoch  0 , batch  1338  current loss =  0.10744157085672322\n",
            "epoch  0 , batch  1339  current loss =  0.10737802853265693\n",
            "epoch  0 , batch  1340  current loss =  0.10734951462718886\n",
            "epoch  0 , batch  1341  current loss =  0.10732127723787896\n",
            "epoch  0 , batch  1342  current loss =  0.10729336600378987\n",
            "epoch  0 , batch  1343  current loss =  0.10723011234949809\n",
            "epoch  0 , batch  1344  current loss =  0.10720253291446369\n",
            "epoch  0 , batch  1345  current loss =  0.1071749127187654\n",
            "epoch  0 , batch  1346  current loss =  0.10714744051825739\n",
            "epoch  0 , batch  1347  current loss =  0.10711982590284541\n",
            "epoch  0 , batch  1348  current loss =  0.10709232566263761\n",
            "epoch  0 , batch  1349  current loss =  0.10706481168046594\n",
            "epoch  0 , batch  1350  current loss =  0.10703723664174228\n",
            "epoch  0 , batch  1351  current loss =  0.10700953513667671\n",
            "epoch  0 , batch  1352  current loss =  0.10698192078669756\n",
            "epoch  0 , batch  1353  current loss =  0.10695428272401103\n",
            "epoch  0 , batch  1354  current loss =  0.10689470015150045\n",
            "epoch  0 , batch  1355  current loss =  0.10683518778436589\n",
            "epoch  0 , batch  1356  current loss =  0.10680759178272771\n",
            "epoch  0 , batch  1357  current loss =  0.1067474730352601\n",
            "epoch  0 , batch  1358  current loss =  0.10672021189648342\n",
            "epoch  0 , batch  1359  current loss =  0.10669315221842707\n",
            "epoch  0 , batch  1360  current loss =  0.10663249337680304\n",
            "epoch  0 , batch  1361  current loss =  0.10660589617716693\n",
            "epoch  0 , batch  1362  current loss =  0.10657941338538533\n",
            "epoch  0 , batch  1363  current loss =  0.10655296057028439\n",
            "epoch  0 , batch  1364  current loss =  0.10652650118815703\n",
            "epoch  0 , batch  1365  current loss =  0.1064999778305029\n",
            "epoch  0 , batch  1366  current loss =  0.10643973490175598\n",
            "epoch  0 , batch  1367  current loss =  0.1064130503456898\n",
            "epoch  0 , batch  1368  current loss =  0.10635304412688214\n",
            "epoch  0 , batch  1369  current loss =  0.10632635830650038\n",
            "epoch  0 , batch  1370  current loss =  0.10629958828216939\n",
            "epoch  0 , batch  1371  current loss =  0.10627284552426819\n",
            "epoch  0 , batch  1372  current loss =  0.10621323108263395\n",
            "epoch  0 , batch  1373  current loss =  0.10615366371890755\n",
            "epoch  0 , batch  1374  current loss =  0.10612695443562487\n",
            "epoch  0 , batch  1375  current loss =  0.10610025054382616\n",
            "epoch  0 , batch  1376  current loss =  0.10607346706701065\n",
            "epoch  0 , batch  1377  current loss =  0.1060466807009855\n",
            "epoch  0 , batch  1378  current loss =  0.10598722782709985\n",
            "epoch  0 , batch  1379  current loss =  0.10592779848738101\n",
            "epoch  0 , batch  1380  current loss =  0.10590114060433273\n",
            "epoch  0 , batch  1381  current loss =  0.10584155705254714\n",
            "epoch  0 , batch  1382  current loss =  0.10581504239007798\n",
            "epoch  0 , batch  1383  current loss =  0.10578849506389479\n",
            "epoch  0 , batch  1384  current loss =  0.1057287537267546\n",
            "epoch  0 , batch  1385  current loss =  0.10570224128666228\n",
            "epoch  0 , batch  1386  current loss =  0.10564261629557063\n",
            "epoch  0 , batch  1387  current loss =  0.10558293143794563\n",
            "epoch  0 , batch  1388  current loss =  0.10552317528771551\n",
            "epoch  0 , batch  1389  current loss =  0.10546332750563249\n",
            "epoch  0 , batch  1390  current loss =  0.10540342883767305\n",
            "epoch  0 , batch  1391  current loss =  0.10534349451143958\n",
            "epoch  0 , batch  1392  current loss =  0.10528349160294972\n",
            "epoch  0 , batch  1393  current loss =  0.10522341943269801\n",
            "epoch  0 , batch  1394  current loss =  0.10516329100522409\n",
            "epoch  0 , batch  1395  current loss =  0.10514066393359066\n",
            "epoch  0 , batch  1396  current loss =  0.10511771041723922\n",
            "epoch  0 , batch  1397  current loss =  0.10509418782435667\n",
            "epoch  0 , batch  1398  current loss =  0.1050697799826612\n",
            "epoch  0 , batch  1399  current loss =  0.10500976127106697\n",
            "epoch  0 , batch  1400  current loss =  0.10498434350327944\n",
            "epoch  0 , batch  1401  current loss =  0.10495861652592853\n",
            "epoch  0 , batch  1402  current loss =  0.10489973266750405\n",
            "epoch  0 , batch  1403  current loss =  0.10484117172602724\n",
            "epoch  0 , batch  1404  current loss =  0.10481537552053288\n",
            "epoch  0 , batch  1405  current loss =  0.10478957718275328\n",
            "epoch  0 , batch  1406  current loss =  0.10473105509506635\n",
            "epoch  0 , batch  1407  current loss =  0.10470537149244179\n",
            "epoch  0 , batch  1408  current loss =  0.1046797125755609\n",
            "epoch  0 , batch  1409  current loss =  0.10462086206592672\n",
            "epoch  0 , batch  1410  current loss =  0.10456189127278552\n",
            "epoch  0 , batch  1411  current loss =  0.10453652508791653\n",
            "epoch  0 , batch  1412  current loss =  0.1044772928857468\n",
            "epoch  0 , batch  1413  current loss =  0.10441796804147296\n",
            "epoch  0 , batch  1414  current loss =  0.10439327530918294\n",
            "epoch  0 , batch  1415  current loss =  0.10433380303728147\n",
            "epoch  0 , batch  1416  current loss =  0.10427426596697296\n",
            "epoch  0 , batch  1417  current loss =  0.10421466444552008\n",
            "epoch  0 , batch  1418  current loss =  0.10415497496973532\n",
            "epoch  0 , batch  1419  current loss =  0.10413189630260244\n",
            "epoch  0 , batch  1420  current loss =  0.10410899958028645\n",
            "epoch  0 , batch  1421  current loss =  0.10404923113335432\n",
            "epoch  0 , batch  1422  current loss =  0.10402632221901555\n",
            "epoch  0 , batch  1423  current loss =  0.1039666432509293\n",
            "epoch  0 , batch  1424  current loss =  0.10394328771126375\n",
            "epoch  0 , batch  1425  current loss =  0.10388372604229695\n",
            "epoch  0 , batch  1426  current loss =  0.10382423794827703\n",
            "epoch  0 , batch  1427  current loss =  0.1037648047838381\n",
            "epoch  0 , batch  1428  current loss =  0.10370541992809094\n",
            "epoch  0 , batch  1429  current loss =  0.10368159514480642\n",
            "epoch  0 , batch  1430  current loss =  0.10365771116515729\n",
            "epoch  0 , batch  1431  current loss =  0.10363373542841857\n",
            "epoch  0 , batch  1432  current loss =  0.10360953357429435\n",
            "epoch  0 , batch  1433  current loss =  0.10355056058992132\n",
            "epoch  0 , batch  1434  current loss =  0.10349175733050091\n",
            "epoch  0 , batch  1435  current loss =  0.10343303718775365\n",
            "epoch  0 , batch  1436  current loss =  0.1034085759970832\n",
            "epoch  0 , batch  1437  current loss =  0.10334991973077409\n",
            "epoch  0 , batch  1438  current loss =  0.10332547545580606\n",
            "epoch  0 , batch  1439  current loss =  0.10330106532783248\n",
            "epoch  0 , batch  1440  current loss =  0.10327654855234043\n",
            "epoch  0 , batch  1441  current loss =  0.103218101289888\n",
            "epoch  0 , batch  1442  current loss =  0.10315970193377837\n",
            "epoch  0 , batch  1443  current loss =  0.1031351469984727\n",
            "epoch  0 , batch  1444  current loss =  0.10307675565054776\n",
            "epoch  0 , batch  1445  current loss =  0.10301834402894433\n",
            "epoch  0 , batch  1446  current loss =  0.10299417433478891\n",
            "epoch  0 , batch  1447  current loss =  0.10297004454859239\n",
            "epoch  0 , batch  1448  current loss =  0.10294600747194041\n",
            "epoch  0 , batch  1449  current loss =  0.10292183497663716\n",
            "epoch  0 , batch  1450  current loss =  0.10286358664637697\n",
            "epoch  0 , batch  1451  current loss =  0.10283927048156269\n",
            "epoch  0 , batch  1452  current loss =  0.10278122354534705\n",
            "epoch  0 , batch  1453  current loss =  0.10275678699221232\n",
            "epoch  0 , batch  1454  current loss =  0.10269891819708638\n",
            "epoch  0 , batch  1455  current loss =  0.10267443330971278\n",
            "epoch  0 , batch  1456  current loss =  0.10264993331976127\n",
            "epoch  0 , batch  1457  current loss =  0.10262541318905063\n",
            "epoch  0 , batch  1458  current loss =  0.1025679212968702\n",
            "epoch  0 , batch  1459  current loss =  0.10254333341455929\n",
            "epoch  0 , batch  1460  current loss =  0.10248599437745588\n",
            "epoch  0 , batch  1461  current loss =  0.10246139238034305\n",
            "epoch  0 , batch  1462  current loss =  0.1024040542842129\n",
            "epoch  0 , batch  1463  current loss =  0.10237958028472328\n",
            "epoch  0 , batch  1464  current loss =  0.10232220777841253\n",
            "epoch  0 , batch  1465  current loss =  0.10229791446790953\n",
            "epoch  0 , batch  1466  current loss =  0.10227365944732612\n",
            "epoch  0 , batch  1467  current loss =  0.10221632246539626\n",
            "epoch  0 , batch  1468  current loss =  0.10219211431906144\n",
            "epoch  0 , batch  1469  current loss =  0.10213481968674226\n",
            "epoch  0 , batch  1470  current loss =  0.10207756433286466\n",
            "epoch  0 , batch  1471  current loss =  0.1020202874566641\n",
            "epoch  0 , batch  1472  current loss =  0.10199644938629761\n",
            "epoch  0 , batch  1473  current loss =  0.10193911923242169\n",
            "epoch  0 , batch  1474  current loss =  0.10191548909739417\n",
            "epoch  0 , batch  1475  current loss =  0.1018918781903469\n",
            "epoch  0 , batch  1476  current loss =  0.10186816520481978\n",
            "epoch  0 , batch  1477  current loss =  0.10184427792917186\n",
            "epoch  0 , batch  1478  current loss =  0.10182014586840976\n",
            "epoch  0 , batch  1479  current loss =  0.1017958455196758\n",
            "epoch  0 , batch  1480  current loss =  0.10177136552227682\n",
            "epoch  0 , batch  1481  current loss =  0.10171533168661792\n",
            "epoch  0 , batch  1482  current loss =  0.10165949634622358\n",
            "epoch  0 , batch  1483  current loss =  0.10163491544178173\n",
            "epoch  0 , batch  1484  current loss =  0.10161036506909814\n",
            "epoch  0 , batch  1485  current loss =  0.10158578903147321\n",
            "epoch  0 , batch  1486  current loss =  0.10153001170886009\n",
            "epoch  0 , batch  1487  current loss =  0.10147413458006697\n",
            "epoch  0 , batch  1488  current loss =  0.10141807894708427\n",
            "epoch  0 , batch  1489  current loss =  0.1013939411854434\n",
            "epoch  0 , batch  1490  current loss =  0.10137000733000831\n",
            "epoch  0 , batch  1491  current loss =  0.10131364273364299\n",
            "epoch  0 , batch  1492  current loss =  0.10129006161140522\n",
            "epoch  0 , batch  1493  current loss =  0.10126660184291413\n",
            "epoch  0 , batch  1494  current loss =  0.1012430850833804\n",
            "epoch  0 , batch  1495  current loss =  0.10118684571617367\n",
            "epoch  0 , batch  1496  current loss =  0.10113068785687626\n",
            "epoch  0 , batch  1497  current loss =  0.10107456131941465\n",
            "epoch  0 , batch  1498  current loss =  0.10101842875837823\n",
            "epoch  0 , batch  1499  current loss =  0.10096227297621468\n",
            "epoch  0 , batch  1500  current loss =  0.10093905823832647\n",
            "epoch  0 , batch  1501  current loss =  0.10088284109370627\n",
            "epoch  0 , batch  1502  current loss =  0.10085980919904199\n",
            "epoch  0 , batch  1503  current loss =  0.10083674156030224\n",
            "epoch  0 , batch  1504  current loss =  0.10078058235805197\n",
            "epoch  0 , batch  1505  current loss =  0.10075741445714952\n",
            "epoch  0 , batch  1506  current loss =  0.10073411287634813\n",
            "epoch  0 , batch  1507  current loss =  0.10067822367622362\n",
            "epoch  0 , batch  1508  current loss =  0.10065472251849805\n",
            "epoch  0 , batch  1509  current loss =  0.10059903333555685\n",
            "epoch  0 , batch  1510  current loss =  0.10054341445705951\n",
            "epoch  0 , batch  1511  current loss =  0.10051986097084684\n",
            "epoch  0 , batch  1512  current loss =  0.10046432027254704\n",
            "epoch  0 , batch  1513  current loss =  0.10040878963224895\n",
            "epoch  0 , batch  1514  current loss =  0.10035319875974959\n",
            "epoch  0 , batch  1515  current loss =  0.10032998873006876\n",
            "epoch  0 , batch  1516  current loss =  0.10030687680736862\n",
            "epoch  0 , batch  1517  current loss =  0.10025120923192546\n",
            "epoch  0 , batch  1518  current loss =  0.1002282106849151\n",
            "epoch  0 , batch  1519  current loss =  0.100205245006854\n",
            "epoch  0 , batch  1520  current loss =  0.1001821763667766\n",
            "epoch  0 , batch  1521  current loss =  0.10012670731999264\n",
            "epoch  0 , batch  1522  current loss =  0.1000713343326631\n",
            "epoch  0 , batch  1523  current loss =  0.10004814496212529\n",
            "epoch  0 , batch  1524  current loss =  0.09999287691822306\n",
            "epoch  0 , batch  1525  current loss =  0.09996965601808376\n",
            "epoch  0 , batch  1526  current loss =  0.09991448939141781\n",
            "epoch  0 , batch  1527  current loss =  0.09985933802151535\n",
            "epoch  0 , batch  1528  current loss =  0.09983633251701152\n",
            "epoch  0 , batch  1529  current loss =  0.09978118074169151\n",
            "epoch  0 , batch  1530  current loss =  0.09975833967352404\n",
            "epoch  0 , batch  1531  current loss =  0.09970321854899879\n",
            "epoch  0 , batch  1532  current loss =  0.09964811729312195\n",
            "epoch  0 , batch  1533  current loss =  0.09959301778274397\n",
            "epoch  0 , batch  1534  current loss =  0.0995706779154242\n",
            "epoch  0 , batch  1535  current loss =  0.09951558990420988\n",
            "epoch  0 , batch  1536  current loss =  0.09949338325058767\n",
            "epoch  0 , batch  1537  current loss =  0.09943835847673184\n",
            "epoch  0 , batch  1538  current loss =  0.09941620064585859\n",
            "epoch  0 , batch  1539  current loss =  0.09939388547201532\n",
            "epoch  0 , batch  1540  current loss =  0.099371401314478\n",
            "epoch  0 , batch  1541  current loss =  0.0993486985705561\n",
            "epoch  0 , batch  1542  current loss =  0.09932580179391805\n",
            "epoch  0 , batch  1543  current loss =  0.09930276956199306\n",
            "epoch  0 , batch  1544  current loss =  0.09927959981341289\n",
            "epoch  0 , batch  1545  current loss =  0.09925635554737389\n",
            "epoch  0 , batch  1546  current loss =  0.09923303922013402\n",
            "epoch  0 , batch  1547  current loss =  0.09918096061321865\n",
            "epoch  0 , batch  1548  current loss =  0.09915752157152873\n",
            "epoch  0 , batch  1549  current loss =  0.09910540400793956\n",
            "epoch  0 , batch  1550  current loss =  0.0990529364025368\n",
            "epoch  0 , batch  1551  current loss =  0.0990296611340342\n",
            "epoch  0 , batch  1552  current loss =  0.09897633358723432\n",
            "epoch  0 , batch  1553  current loss =  0.09892270839239735\n",
            "epoch  0 , batch  1554  current loss =  0.09890040271403418\n",
            "epoch  0 , batch  1555  current loss =  0.09887846834193867\n",
            "epoch  0 , batch  1556  current loss =  0.09885677878129402\n",
            "epoch  0 , batch  1557  current loss =  0.09880289183905652\n",
            "epoch  0 , batch  1558  current loss =  0.0987490272421851\n",
            "epoch  0 , batch  1559  current loss =  0.09872770724304689\n",
            "epoch  0 , batch  1560  current loss =  0.09870634209674894\n",
            "epoch  0 , batch  1561  current loss =  0.09865260865389061\n",
            "epoch  0 , batch  1562  current loss =  0.09859894692804844\n",
            "epoch  0 , batch  1563  current loss =  0.09854531999203421\n",
            "epoch  0 , batch  1564  current loss =  0.09849170739955891\n",
            "epoch  0 , batch  1565  current loss =  0.09847006420896294\n",
            "epoch  0 , batch  1566  current loss =  0.0984483717114028\n",
            "epoch  0 , batch  1567  current loss =  0.09842653541970636\n",
            "epoch  0 , batch  1568  current loss =  0.09837307942434054\n",
            "epoch  0 , batch  1569  current loss =  0.09831972926688992\n",
            "epoch  0 , batch  1570  current loss =  0.09829768583648035\n",
            "epoch  0 , batch  1571  current loss =  0.09824445862003126\n",
            "epoch  0 , batch  1572  current loss =  0.0982224106420369\n",
            "epoch  0 , batch  1573  current loss =  0.09820031888577069\n",
            "epoch  0 , batch  1574  current loss =  0.09814731674061881\n",
            "epoch  0 , batch  1575  current loss =  0.09812521205052052\n",
            "epoch  0 , batch  1576  current loss =  0.0981030521386397\n",
            "epoch  0 , batch  1577  current loss =  0.09805030317408125\n",
            "epoch  0 , batch  1578  current loss =  0.09802810114261619\n",
            "epoch  0 , batch  1579  current loss =  0.09797546529812337\n",
            "epoch  0 , batch  1580  current loss =  0.09792282878480743\n",
            "epoch  0 , batch  1581  current loss =  0.09787013071533834\n",
            "epoch  0 , batch  1582  current loss =  0.09784822407592175\n",
            "epoch  0 , batch  1583  current loss =  0.09779540365832302\n",
            "epoch  0 , batch  1584  current loss =  0.09774255102224154\n",
            "epoch  0 , batch  1585  current loss =  0.09768965450957567\n",
            "epoch  0 , batch  1586  current loss =  0.09763672843953405\n",
            "epoch  0 , batch  1587  current loss =  0.09761616794840533\n",
            "epoch  0 , batch  1588  current loss =  0.09756319741135296\n",
            "epoch  0 , batch  1589  current loss =  0.09751023624631219\n",
            "epoch  0 , batch  1590  current loss =  0.097490216080289\n",
            "epoch  0 , batch  1591  current loss =  0.09743728345943306\n",
            "epoch  0 , batch  1592  current loss =  0.09738437834675777\n",
            "epoch  0 , batch  1593  current loss =  0.09733149953013569\n",
            "epoch  0 , batch  1594  current loss =  0.09731147881702383\n",
            "epoch  0 , batch  1595  current loss =  0.0972586473307682\n",
            "epoch  0 , batch  1596  current loss =  0.09720585723019759\n",
            "epoch  0 , batch  1597  current loss =  0.09718564652181574\n",
            "epoch  0 , batch  1598  current loss =  0.09716520481873968\n",
            "epoch  0 , batch  1599  current loss =  0.09711258178693243\n",
            "epoch  0 , batch  1600  current loss =  0.09706004389005013\n",
            "epoch  0 , batch  1601  current loss =  0.09703917795508524\n",
            "epoch  0 , batch  1602  current loss =  0.09701822315303799\n",
            "epoch  0 , batch  1603  current loss =  0.096966033198167\n",
            "epoch  0 , batch  1604  current loss =  0.09691395249763196\n",
            "epoch  0 , batch  1605  current loss =  0.09686189431205373\n",
            "epoch  0 , batch  1606  current loss =  0.09684088431280187\n",
            "epoch  0 , batch  1607  current loss =  0.09678878449193151\n",
            "epoch  0 , batch  1608  current loss =  0.09673666761466866\n",
            "epoch  0 , batch  1609  current loss =  0.09671603470450696\n",
            "epoch  0 , batch  1610  current loss =  0.09666385006594277\n",
            "epoch  0 , batch  1611  current loss =  0.0966434155113616\n",
            "epoch  0 , batch  1612  current loss =  0.09659123718242005\n",
            "epoch  0 , batch  1613  current loss =  0.09657092847200076\n",
            "epoch  0 , batch  1614  current loss =  0.09651881214231253\n",
            "epoch  0 , batch  1615  current loss =  0.09646672424387721\n",
            "epoch  0 , batch  1616  current loss =  0.09641465738222196\n",
            "epoch  0 , batch  1617  current loss =  0.09639472171793173\n",
            "epoch  0 , batch  1618  current loss =  0.09637478109934655\n",
            "epoch  0 , batch  1619  current loss =  0.09635475446228628\n",
            "epoch  0 , batch  1620  current loss =  0.09630286529657926\n",
            "epoch  0 , batch  1621  current loss =  0.09625107832149626\n",
            "epoch  0 , batch  1622  current loss =  0.09619933509601261\n",
            "epoch  0 , batch  1623  current loss =  0.09617908298567837\n",
            "epoch  0 , batch  1624  current loss =  0.09612743657025007\n",
            "epoch  0 , batch  1625  current loss =  0.09607584010935669\n",
            "epoch  0 , batch  1626  current loss =  0.09605568877553548\n",
            "epoch  0 , batch  1627  current loss =  0.0960041257862862\n",
            "epoch  0 , batch  1628  current loss =  0.09598405273463131\n",
            "epoch  0 , batch  1629  current loss =  0.0959639387473784\n",
            "epoch  0 , batch  1630  current loss =  0.09591253729940265\n",
            "epoch  0 , batch  1631  current loss =  0.09586118827756568\n",
            "epoch  0 , batch  1632  current loss =  0.09580986121919209\n",
            "epoch  0 , batch  1633  current loss =  0.09578989852890099\n",
            "epoch  0 , batch  1634  current loss =  0.09576995426543991\n",
            "epoch  0 , batch  1635  current loss =  0.09571870864644501\n",
            "epoch  0 , batch  1636  current loss =  0.09569874122424794\n",
            "epoch  0 , batch  1637  current loss =  0.0956786874788603\n",
            "epoch  0 , batch  1638  current loss =  0.09562764675575215\n",
            "epoch  0 , batch  1639  current loss =  0.09560750512201793\n",
            "epoch  0 , batch  1640  current loss =  0.09555664891008195\n",
            "epoch  0 , batch  1641  current loss =  0.09550585193915721\n",
            "epoch  0 , batch  1642  current loss =  0.09545505500942178\n",
            "epoch  0 , batch  1643  current loss =  0.09543507273077802\n",
            "epoch  0 , batch  1644  current loss =  0.0953842444418955\n",
            "epoch  0 , batch  1645  current loss =  0.09533341464112408\n",
            "epoch  0 , batch  1646  current loss =  0.09531350497837203\n",
            "epoch  0 , batch  1647  current loss =  0.09526319871939158\n",
            "epoch  0 , batch  1648  current loss =  0.09524349002207116\n",
            "epoch  0 , batch  1649  current loss =  0.09519315301638209\n",
            "epoch  0 , batch  1650  current loss =  0.09514278787013926\n",
            "epoch  0 , batch  1651  current loss =  0.09512344977624498\n",
            "epoch  0 , batch  1652  current loss =  0.09510413234398733\n",
            "epoch  0 , batch  1653  current loss =  0.09505377344262336\n",
            "epoch  0 , batch  1654  current loss =  0.0950034481532354\n",
            "epoch  0 , batch  1655  current loss =  0.09495313120904662\n",
            "epoch  0 , batch  1656  current loss =  0.09493397457685882\n",
            "epoch  0 , batch  1657  current loss =  0.094914746662294\n",
            "epoch  0 , batch  1658  current loss =  0.09486445660785406\n",
            "epoch  0 , batch  1659  current loss =  0.09484511326314006\n",
            "epoch  0 , batch  1660  current loss =  0.09482565085016177\n",
            "epoch  0 , batch  1661  current loss =  0.09477561648831972\n",
            "epoch  0 , batch  1662  current loss =  0.09472566806743178\n",
            "epoch  0 , batch  1663  current loss =  0.09470599235366815\n",
            "epoch  0 , batch  1664  current loss =  0.09468627423495501\n",
            "epoch  0 , batch  1665  current loss =  0.09466653307150749\n",
            "epoch  0 , batch  1666  current loss =  0.09461680313501894\n",
            "epoch  0 , batch  1667  current loss =  0.09459695250423496\n",
            "epoch  0 , batch  1668  current loss =  0.09454733448258197\n",
            "epoch  0 , batch  1669  current loss =  0.09449765315937425\n",
            "epoch  0 , batch  1670  current loss =  0.09444786222759725\n",
            "epoch  0 , batch  1671  current loss =  0.09439797358783453\n",
            "epoch  0 , batch  1672  current loss =  0.09434795204396385\n",
            "epoch  0 , batch  1673  current loss =  0.09429779692342685\n",
            "epoch  0 , batch  1674  current loss =  0.09424752720311952\n",
            "epoch  0 , batch  1675  current loss =  0.0941971650559384\n",
            "epoch  0 , batch  1676  current loss =  0.09414668233379872\n",
            "epoch  0 , batch  1677  current loss =  0.0940961846154898\n",
            "epoch  0 , batch  1678  current loss =  0.0940456314948723\n",
            "epoch  0 , batch  1679  current loss =  0.0939950270151409\n",
            "epoch  0 , batch  1680  current loss =  0.09394443741789589\n",
            "epoch  0 , batch  1681  current loss =  0.09393021974360458\n",
            "epoch  0 , batch  1682  current loss =  0.0939153360880234\n",
            "epoch  0 , batch  1683  current loss =  0.09389917176126142\n",
            "epoch  0 , batch  1684  current loss =  0.09388162947096793\n",
            "epoch  0 , batch  1685  current loss =  0.09386295917104766\n",
            "epoch  0 , batch  1686  current loss =  0.0938435876322441\n",
            "epoch  0 , batch  1687  current loss =  0.09379395415346575\n",
            "epoch  0 , batch  1688  current loss =  0.09374490593074253\n",
            "epoch  0 , batch  1689  current loss =  0.09372495277867426\n",
            "epoch  0 , batch  1690  current loss =  0.0936767552593213\n",
            "epoch  0 , batch  1691  current loss =  0.09362850140672327\n",
            "epoch  0 , batch  1692  current loss =  0.09357986923271974\n",
            "epoch  0 , batch  1693  current loss =  0.09356016912162216\n",
            "epoch  0 , batch  1694  current loss =  0.0935110582961841\n",
            "epoch  0 , batch  1695  current loss =  0.09346188174149918\n",
            "epoch  0 , batch  1696  current loss =  0.09344259395802468\n",
            "epoch  0 , batch  1697  current loss =  0.09339323303595326\n",
            "epoch  0 , batch  1698  current loss =  0.09337446922430875\n",
            "epoch  0 , batch  1699  current loss =  0.09332506232073202\n",
            "epoch  0 , batch  1700  current loss =  0.09327562624913832\n",
            "epoch  0 , batch  1701  current loss =  0.09325766046701128\n",
            "epoch  0 , batch  1702  current loss =  0.09320821578456367\n",
            "epoch  0 , batch  1703  current loss =  0.09315877738561779\n",
            "epoch  0 , batch  1704  current loss =  0.0931093182808056\n",
            "epoch  0 , batch  1705  current loss =  0.0930598458026264\n",
            "epoch  0 , batch  1706  current loss =  0.0930103529653854\n",
            "epoch  0 , batch  1707  current loss =  0.09296083441756631\n",
            "epoch  0 , batch  1708  current loss =  0.09294477873468186\n",
            "epoch  0 , batch  1709  current loss =  0.09289524816303399\n",
            "epoch  0 , batch  1710  current loss =  0.09284573738217737\n",
            "epoch  0 , batch  1711  current loss =  0.09279624267402932\n",
            "epoch  0 , batch  1712  current loss =  0.09274677145776002\n",
            "epoch  0 , batch  1713  current loss =  0.09269731387695952\n",
            "epoch  0 , batch  1714  current loss =  0.09268193311620036\n",
            "epoch  0 , batch  1715  current loss =  0.09266624474867588\n",
            "epoch  0 , batch  1716  current loss =  0.09265005840427944\n",
            "epoch  0 , batch  1717  current loss =  0.0926333173818895\n",
            "epoch  0 , batch  1718  current loss =  0.09261600363516335\n",
            "epoch  0 , batch  1719  current loss =  0.09256701022873871\n",
            "epoch  0 , batch  1720  current loss =  0.09254897641097042\n",
            "epoch  0 , batch  1721  current loss =  0.09253075897410235\n",
            "epoch  0 , batch  1722  current loss =  0.09248268386987982\n",
            "epoch  0 , batch  1723  current loss =  0.09246423382856592\n",
            "epoch  0 , batch  1724  current loss =  0.09241690078021392\n",
            "epoch  0 , batch  1725  current loss =  0.0923982170056487\n",
            "epoch  0 , batch  1726  current loss =  0.09237944864903613\n",
            "epoch  0 , batch  1727  current loss =  0.09233245964397038\n",
            "epoch  0 , batch  1728  current loss =  0.09231364569573422\n",
            "epoch  0 , batch  1729  current loss =  0.09229487192391746\n",
            "epoch  0 , batch  1730  current loss =  0.0922476723564198\n",
            "epoch  0 , batch  1731  current loss =  0.09222903703909376\n",
            "epoch  0 , batch  1732  current loss =  0.09218171048227997\n",
            "epoch  0 , batch  1733  current loss =  0.09213431622143384\n",
            "epoch  0 , batch  1734  current loss =  0.0920868484131584\n",
            "epoch  0 , batch  1735  current loss =  0.09206895998513867\n",
            "epoch  0 , batch  1736  current loss =  0.09202136905948595\n",
            "epoch  0 , batch  1737  current loss =  0.09197374747185116\n",
            "epoch  0 , batch  1738  current loss =  0.09195655207200562\n",
            "epoch  0 , batch  1739  current loss =  0.09193948873950318\n",
            "epoch  0 , batch  1740  current loss =  0.09189183853613721\n",
            "epoch  0 , batch  1741  current loss =  0.09184422156742499\n",
            "epoch  0 , batch  1742  current loss =  0.09182733924748462\n",
            "epoch  0 , batch  1743  current loss =  0.09177976277541505\n",
            "epoch  0 , batch  1744  current loss =  0.09176288967722637\n",
            "epoch  0 , batch  1745  current loss =  0.0917153855351537\n",
            "epoch  0 , batch  1746  current loss =  0.09169840544374776\n",
            "epoch  0 , batch  1747  current loss =  0.09168128699897543\n",
            "epoch  0 , batch  1748  current loss =  0.09166392804911012\n",
            "epoch  0 , batch  1749  current loss =  0.09164634144252964\n",
            "epoch  0 , batch  1750  current loss =  0.09159936382728329\n",
            "epoch  0 , batch  1751  current loss =  0.091581543539672\n",
            "epoch  0 , batch  1752  current loss =  0.09156371858364096\n",
            "epoch  0 , batch  1753  current loss =  0.09151730586762966\n",
            "epoch  0 , batch  1754  current loss =  0.09147105758632945\n",
            "epoch  0 , batch  1755  current loss =  0.09142484159605548\n",
            "epoch  0 , batch  1756  current loss =  0.09137857281409446\n",
            "epoch  0 , batch  1757  current loss =  0.09133220997568012\n",
            "epoch  0 , batch  1758  current loss =  0.09131461239593011\n",
            "epoch  0 , batch  1759  current loss =  0.09129714689810167\n",
            "epoch  0 , batch  1760  current loss =  0.09125058875778295\n",
            "epoch  0 , batch  1761  current loss =  0.09120401973909065\n",
            "epoch  0 , batch  1762  current loss =  0.09115742623353809\n",
            "epoch  0 , batch  1763  current loss =  0.09111080031848329\n",
            "epoch  0 , batch  1764  current loss =  0.09106414667766002\n",
            "epoch  0 , batch  1765  current loss =  0.09104787019299741\n",
            "epoch  0 , batch  1766  current loss =  0.09103174210090167\n",
            "epoch  0 , batch  1767  current loss =  0.09101560100337819\n",
            "epoch  0 , batch  1768  current loss =  0.09096898853098642\n",
            "epoch  0 , batch  1769  current loss =  0.09092244660208201\n",
            "epoch  0 , batch  1770  current loss =  0.09090607827303185\n",
            "epoch  0 , batch  1771  current loss =  0.09088953415880034\n",
            "epoch  0 , batch  1772  current loss =  0.0908728131196565\n",
            "epoch  0 , batch  1773  current loss =  0.0908265959885152\n",
            "epoch  0 , batch  1774  current loss =  0.09078050621535996\n",
            "epoch  0 , batch  1775  current loss =  0.09076343492032155\n",
            "epoch  0 , batch  1776  current loss =  0.09071759259738091\n",
            "epoch  0 , batch  1777  current loss =  0.09070046088753606\n",
            "epoch  0 , batch  1778  current loss =  0.0906833355886178\n",
            "epoch  0 , batch  1779  current loss =  0.09066614292488757\n",
            "epoch  0 , batch  1780  current loss =  0.0906207915881815\n",
            "epoch  0 , batch  1781  current loss =  0.09057548770045508\n",
            "epoch  0 , batch  1782  current loss =  0.0905583070683023\n",
            "epoch  0 , batch  1783  current loss =  0.09054117619462997\n",
            "epoch  0 , batch  1784  current loss =  0.09049583250599331\n",
            "epoch  0 , batch  1785  current loss =  0.09047878274698257\n",
            "epoch  0 , batch  1786  current loss =  0.09043344393972919\n",
            "epoch  0 , batch  1787  current loss =  0.09041656779387854\n",
            "epoch  0 , batch  1788  current loss =  0.09039975243192135\n",
            "epoch  0 , batch  1789  current loss =  0.09035451825833021\n",
            "epoch  0 , batch  1790  current loss =  0.0903093246025481\n",
            "epoch  0 , batch  1791  current loss =  0.09026414276065355\n",
            "epoch  0 , batch  1792  current loss =  0.09024763466895241\n",
            "epoch  0 , batch  1793  current loss =  0.09020247171168842\n",
            "epoch  0 , batch  1794  current loss =  0.09015732441035237\n",
            "epoch  0 , batch  1795  current loss =  0.09014110586850724\n",
            "epoch  0 , batch  1796  current loss =  0.0901249481342281\n",
            "epoch  0 , batch  1797  current loss =  0.09010872873917918\n",
            "epoch  0 , batch  1798  current loss =  0.09006372932862364\n",
            "epoch  0 , batch  1799  current loss =  0.09001880412300428\n",
            "epoch  0 , batch  1800  current loss =  0.09000243274065801\n",
            "epoch  0 , batch  1801  current loss =  0.08995762130568066\n",
            "epoch  0 , batch  1802  current loss =  0.08994121177362704\n",
            "epoch  0 , batch  1803  current loss =  0.08989652426770894\n",
            "epoch  0 , batch  1804  current loss =  0.08985188052759936\n",
            "epoch  0 , batch  1805  current loss =  0.08980725274048952\n",
            "epoch  0 , batch  1806  current loss =  0.08976261479152324\n",
            "epoch  0 , batch  1807  current loss =  0.08971793825152964\n",
            "epoch  0 , batch  1808  current loss =  0.08967324288179938\n",
            "epoch  0 , batch  1809  current loss =  0.08965761867501047\n",
            "epoch  0 , batch  1810  current loss =  0.08961289487768856\n",
            "epoch  0 , batch  1811  current loss =  0.08959755459625611\n",
            "epoch  0 , batch  1812  current loss =  0.08955286877456861\n",
            "epoch  0 , batch  1813  current loss =  0.08950820576570016\n",
            "epoch  0 , batch  1814  current loss =  0.08949305345625014\n",
            "epoch  0 , batch  1815  current loss =  0.08944844575609093\n",
            "epoch  0 , batch  1816  current loss =  0.08943325991398385\n",
            "epoch  0 , batch  1817  current loss =  0.08941795873507956\n",
            "epoch  0 , batch  1818  current loss =  0.089373521222628\n",
            "epoch  0 , batch  1819  current loss =  0.08932919230895466\n",
            "epoch  0 , batch  1820  current loss =  0.08928493456991736\n",
            "epoch  0 , batch  1821  current loss =  0.08924072044906661\n",
            "epoch  0 , batch  1822  current loss =  0.08919650735205843\n",
            "epoch  0 , batch  1823  current loss =  0.08915229144877869\n",
            "epoch  0 , batch  1824  current loss =  0.08913714366518471\n",
            "epoch  0 , batch  1825  current loss =  0.08912208076639902\n",
            "epoch  0 , batch  1826  current loss =  0.08910697845708462\n",
            "epoch  0 , batch  1827  current loss =  0.08906288270143634\n",
            "epoch  0 , batch  1828  current loss =  0.08901886344556847\n",
            "epoch  0 , batch  1829  current loss =  0.08900368617277572\n",
            "epoch  0 , batch  1830  current loss =  0.0889597585677067\n",
            "epoch  0 , batch  1831  current loss =  0.08891588689425887\n",
            "epoch  0 , batch  1832  current loss =  0.08890071789293555\n",
            "epoch  0 , batch  1833  current loss =  0.0888855769689984\n",
            "epoch  0 , batch  1834  current loss =  0.08887037055247161\n",
            "epoch  0 , batch  1835  current loss =  0.08885502251989182\n",
            "epoch  0 , batch  1836  current loss =  0.08881157839079638\n",
            "epoch  0 , batch  1837  current loss =  0.08879607424425758\n",
            "epoch  0 , batch  1838  current loss =  0.08878052161571981\n",
            "epoch  0 , batch  1839  current loss =  0.0887375147927188\n",
            "epoch  0 , batch  1840  current loss =  0.08869456699839401\n",
            "epoch  0 , batch  1841  current loss =  0.08865157611178685\n",
            "epoch  0 , batch  1842  current loss =  0.08863617435635365\n",
            "epoch  0 , batch  1843  current loss =  0.08862084678299482\n",
            "epoch  0 , batch  1844  current loss =  0.08860557908066082\n",
            "epoch  0 , batch  1845  current loss =  0.0885625720808115\n",
            "epoch  0 , batch  1846  current loss =  0.08854738656233777\n",
            "epoch  0 , batch  1847  current loss =  0.08850447666625698\n",
            "epoch  0 , batch  1848  current loss =  0.08846159770695937\n",
            "epoch  0 , batch  1849  current loss =  0.08844653566493779\n",
            "epoch  0 , batch  1850  current loss =  0.08843146408603667\n",
            "epoch  0 , batch  1851  current loss =  0.08841641480354571\n",
            "epoch  0 , batch  1852  current loss =  0.08840124965009581\n",
            "epoch  0 , batch  1853  current loss =  0.08838595083775048\n",
            "epoch  0 , batch  1854  current loss =  0.0883705550282591\n",
            "epoch  0 , batch  1855  current loss =  0.08832839816248703\n",
            "epoch  0 , batch  1856  current loss =  0.08831291167566017\n",
            "epoch  0 , batch  1857  current loss =  0.08829735991052794\n",
            "epoch  0 , batch  1858  current loss =  0.08828172026199077\n",
            "epoch  0 , batch  1859  current loss =  0.08824028499794984\n",
            "epoch  0 , batch  1860  current loss =  0.08822459467746266\n",
            "epoch  0 , batch  1861  current loss =  0.08820887299346568\n",
            "epoch  0 , batch  1862  current loss =  0.0881931638961005\n",
            "epoch  0 , batch  1863  current loss =  0.08815209462123527\n",
            "epoch  0 , batch  1864  current loss =  0.08811099210769018\n",
            "epoch  0 , batch  1865  current loss =  0.0880953805553073\n",
            "epoch  0 , batch  1866  current loss =  0.08805408468395153\n",
            "epoch  0 , batch  1867  current loss =  0.08803868590259817\n",
            "epoch  0 , batch  1868  current loss =  0.08799724359914397\n",
            "epoch  0 , batch  1869  current loss =  0.0879821108499751\n",
            "epoch  0 , batch  1870  current loss =  0.0879671500183399\n",
            "epoch  0 , batch  1871  current loss =  0.08795217963474858\n",
            "epoch  0 , batch  1872  current loss =  0.0879371622109908\n",
            "epoch  0 , batch  1873  current loss =  0.08789582880812209\n",
            "epoch  0 , batch  1874  current loss =  0.08788069529632728\n",
            "epoch  0 , batch  1875  current loss =  0.08786550971335852\n",
            "epoch  0 , batch  1876  current loss =  0.08785018727250822\n",
            "epoch  0 , batch  1877  current loss =  0.0878348633303794\n",
            "epoch  0 , batch  1878  current loss =  0.08779412780369435\n",
            "epoch  0 , batch  1879  current loss =  0.08775349857850356\n",
            "epoch  0 , batch  1880  current loss =  0.087712887932033\n",
            "epoch  0 , batch  1881  current loss =  0.08769764916874334\n",
            "epoch  0 , batch  1882  current loss =  0.08768242706390879\n",
            "epoch  0 , batch  1883  current loss =  0.08766722544877456\n",
            "epoch  0 , batch  1884  current loss =  0.08765199844693315\n",
            "epoch  0 , batch  1885  current loss =  0.08763676004984029\n",
            "epoch  0 , batch  1886  current loss =  0.08759624668247465\n",
            "epoch  0 , batch  1887  current loss =  0.08758096591573429\n",
            "epoch  0 , batch  1888  current loss =  0.08756568446428041\n",
            "epoch  0 , batch  1889  current loss =  0.0875504068369982\n",
            "epoch  0 , batch  1890  current loss =  0.08753507192399784\n",
            "epoch  0 , batch  1891  current loss =  0.08749498793437888\n",
            "epoch  0 , batch  1892  current loss =  0.08747967851839712\n",
            "epoch  0 , batch  1893  current loss =  0.08746434879266\n",
            "epoch  0 , batch  1894  current loss =  0.08744900966244983\n",
            "epoch  0 , batch  1895  current loss =  0.08740928095032535\n",
            "epoch  0 , batch  1896  current loss =  0.08739396368934486\n",
            "epoch  0 , batch  1897  current loss =  0.08735428319594286\n",
            "epoch  0 , batch  1898  current loss =  0.08733902486819006\n",
            "epoch  0 , batch  1899  current loss =  0.08732381476089358\n",
            "epoch  0 , batch  1900  current loss =  0.08730863111837327\n",
            "epoch  0 , batch  1901  current loss =  0.08726891802259565\n",
            "epoch  0 , batch  1902  current loss =  0.08722920539919571\n",
            "epoch  0 , batch  1903  current loss =  0.08718941973506653\n",
            "epoch  0 , batch  1904  current loss =  0.087174523737174\n",
            "epoch  0 , batch  1905  current loss =  0.08713458801775092\n",
            "epoch  0 , batch  1906  current loss =  0.0870945741640776\n",
            "epoch  0 , batch  1907  current loss =  0.08705448320641161\n",
            "epoch  0 , batch  1908  current loss =  0.08701431848188777\n",
            "epoch  0 , batch  1909  current loss =  0.08700076633557209\n",
            "epoch  0 , batch  1910  current loss =  0.08696053134572795\n",
            "epoch  0 , batch  1911  current loss =  0.08694718104142259\n",
            "epoch  0 , batch  1912  current loss =  0.08690692278251277\n",
            "epoch  0 , batch  1913  current loss =  0.08686668441758386\n",
            "epoch  0 , batch  1914  current loss =  0.0868529859803831\n",
            "epoch  0 , batch  1915  current loss =  0.08683913260006146\n",
            "epoch  0 , batch  1916  current loss =  0.08682508593503858\n",
            "epoch  0 , batch  1917  current loss =  0.08678501585597509\n",
            "epoch  0 , batch  1918  current loss =  0.08677079450045948\n",
            "epoch  0 , batch  1919  current loss =  0.08675645648909266\n",
            "epoch  0 , batch  1920  current loss =  0.08674210002514951\n",
            "epoch  0 , batch  1921  current loss =  0.08670277353162945\n",
            "epoch  0 , batch  1922  current loss =  0.08666355177775623\n",
            "epoch  0 , batch  1923  current loss =  0.08662421861808678\n",
            "epoch  0 , batch  1924  current loss =  0.08660992155456311\n",
            "epoch  0 , batch  1925  current loss =  0.08657029730597605\n",
            "epoch  0 , batch  1926  current loss =  0.08653057212436298\n",
            "epoch  0 , batch  1927  current loss =  0.08649078681069924\n",
            "epoch  0 , batch  1928  current loss =  0.08647724161501018\n",
            "epoch  0 , batch  1929  current loss =  0.0864639171225458\n",
            "epoch  0 , batch  1930  current loss =  0.08642407482685757\n",
            "epoch  0 , batch  1931  current loss =  0.08638424960911799\n",
            "epoch  0 , batch  1932  current loss =  0.0863444214687715\n",
            "epoch  0 , batch  1933  current loss =  0.08630461121534673\n",
            "epoch  0 , batch  1934  current loss =  0.08626480685734703\n",
            "epoch  0 , batch  1935  current loss =  0.08622499895166637\n",
            "epoch  0 , batch  1936  current loss =  0.086185188024513\n",
            "epoch  0 , batch  1937  current loss =  0.08614538484844077\n",
            "epoch  0 , batch  1938  current loss =  0.08610558074521013\n",
            "epoch  0 , batch  1939  current loss =  0.0860944749158567\n",
            "epoch  0 , batch  1940  current loss =  0.08608321785314574\n",
            "epoch  0 , batch  1941  current loss =  0.08604344521264568\n",
            "epoch  0 , batch  1942  current loss =  0.08600369608820604\n",
            "epoch  0 , batch  1943  current loss =  0.08599148932873145\n",
            "epoch  0 , batch  1944  current loss =  0.08597893076481963\n",
            "epoch  0 , batch  1945  current loss =  0.08593937929600998\n",
            "epoch  0 , batch  1946  current loss =  0.08589995550360047\n",
            "epoch  0 , batch  1947  current loss =  0.08586064807007383\n",
            "epoch  0 , batch  1948  current loss =  0.0858474240192485\n",
            "epoch  0 , batch  1949  current loss =  0.08580829104695183\n",
            "epoch  0 , batch  1950  current loss =  0.08579507471610726\n",
            "epoch  0 , batch  1951  current loss =  0.08578184195822793\n",
            "epoch  0 , batch  1952  current loss =  0.08576861710544663\n",
            "epoch  0 , batch  1953  current loss =  0.08572985719652997\n",
            "epoch  0 , batch  1954  current loss =  0.08569112077993733\n",
            "epoch  0 , batch  1955  current loss =  0.08567790877681553\n",
            "epoch  0 , batch  1956  current loss =  0.0856390604263911\n",
            "epoch  0 , batch  1957  current loss =  0.08562597519536412\n",
            "epoch  0 , batch  1958  current loss =  0.08561296692719914\n",
            "epoch  0 , batch  1959  current loss =  0.08557406416523973\n",
            "epoch  0 , batch  1960  current loss =  0.0855351654211442\n",
            "epoch  0 , batch  1961  current loss =  0.08552244141466239\n",
            "epoch  0 , batch  1962  current loss =  0.08550970942651169\n",
            "epoch  0 , batch  1963  current loss =  0.08547087429260149\n",
            "epoch  0 , batch  1964  current loss =  0.08545817384690653\n",
            "epoch  0 , batch  1965  current loss =  0.08541943148083583\n",
            "epoch  0 , batch  1966  current loss =  0.08538072258679089\n",
            "epoch  0 , batch  1967  current loss =  0.08536809372736474\n",
            "epoch  0 , batch  1968  current loss =  0.08535546378396668\n",
            "epoch  0 , batch  1969  current loss =  0.08534275624229748\n",
            "epoch  0 , batch  1970  current loss =  0.0853299294484525\n",
            "epoch  0 , batch  1971  current loss =  0.08529158148245837\n",
            "epoch  0 , batch  1972  current loss =  0.08525333961814612\n",
            "epoch  0 , batch  1973  current loss =  0.08524036387325074\n",
            "epoch  0 , batch  1974  current loss =  0.08522739959904288\n",
            "epoch  0 , batch  1975  current loss =  0.08521436414113909\n",
            "epoch  0 , batch  1976  current loss =  0.08517645227689377\n",
            "epoch  0 , batch  1977  current loss =  0.08516341069509832\n",
            "epoch  0 , batch  1978  current loss =  0.08512560491172005\n",
            "epoch  0 , batch  1979  current loss =  0.08508778430963632\n",
            "epoch  0 , batch  1980  current loss =  0.08507484745362126\n",
            "epoch  0 , batch  1981  current loss =  0.08506196939295269\n",
            "epoch  0 , batch  1982  current loss =  0.08504914724706206\n",
            "epoch  0 , batch  1983  current loss =  0.08503628446816301\n",
            "epoch  0 , batch  1984  current loss =  0.08502340953121483\n",
            "epoch  0 , batch  1985  current loss =  0.08498577385332363\n",
            "epoch  0 , batch  1986  current loss =  0.08494821125121199\n",
            "epoch  0 , batch  1987  current loss =  0.08491066096151918\n",
            "epoch  0 , batch  1988  current loss =  0.08487306717341198\n",
            "epoch  0 , batch  1989  current loss =  0.0848354069258662\n",
            "epoch  0 , batch  1990  current loss =  0.0848229495454851\n",
            "epoch  0 , batch  1991  current loss =  0.08481066423537487\n",
            "epoch  0 , batch  1992  current loss =  0.08479836775056318\n",
            "epoch  0 , batch  1993  current loss =  0.08476065887921044\n",
            "epoch  0 , batch  1994  current loss =  0.08472297695981232\n",
            "epoch  0 , batch  1995  current loss =  0.08471069366620752\n",
            "epoch  0 , batch  1996  current loss =  0.08467305117250833\n",
            "epoch  0 , batch  1997  current loss =  0.08463543049153965\n",
            "epoch  0 , batch  1998  current loss =  0.08459782131526875\n",
            "epoch  0 , batch  1999  current loss =  0.08456019560527056\n",
            "epoch  0 , batch  2000  current loss =  0.08452255816116505\n",
            "epoch  0 , batch  2001  current loss =  0.08451076202489041\n",
            "epoch  0 , batch  2002  current loss =  0.0844990235385571\n",
            "epoch  0 , batch  2003  current loss =  0.08446139001664882\n",
            "epoch  0 , batch  2004  current loss =  0.08442377911978158\n",
            "epoch  0 , batch  2005  current loss =  0.08441202362520195\n",
            "epoch  0 , batch  2006  current loss =  0.08440019051610725\n",
            "epoch  0 , batch  2007  current loss =  0.08438824503209472\n",
            "epoch  0 , batch  2008  current loss =  0.08437619306519813\n",
            "epoch  0 , batch  2009  current loss =  0.08436401970452856\n",
            "epoch  0 , batch  2010  current loss =  0.0843517088480868\n",
            "epoch  0 , batch  2011  current loss =  0.08433932819307428\n",
            "epoch  0 , batch  2012  current loss =  0.08432685891170956\n",
            "epoch  0 , batch  2013  current loss =  0.08429093537907659\n",
            "epoch  0 , batch  2014  current loss =  0.08427834088310932\n",
            "epoch  0 , batch  2015  current loss =  0.08424260175559625\n",
            "epoch  0 , batch  2016  current loss =  0.0842066741477833\n",
            "epoch  0 , batch  2017  current loss =  0.08417043156000695\n",
            "epoch  0 , batch  2018  current loss =  0.08413384720053912\n",
            "epoch  0 , batch  2019  current loss =  0.08409701340767269\n",
            "epoch  0 , batch  2020  current loss =  0.0840600494941432\n",
            "epoch  0 , batch  2021  current loss =  0.08402300777575177\n",
            "epoch  0 , batch  2022  current loss =  0.08401307327101064\n",
            "epoch  0 , batch  2023  current loss =  0.08400356129507568\n",
            "epoch  0 , batch  2024  current loss =  0.08396645077584702\n",
            "epoch  0 , batch  2025  current loss =  0.08395691695903508\n",
            "epoch  0 , batch  2026  current loss =  0.0839198757524473\n",
            "epoch  0 , batch  2027  current loss =  0.08388288456145711\n",
            "epoch  0 , batch  2028  current loss =  0.08387259741673157\n",
            "epoch  0 , batch  2029  current loss =  0.08386202214900496\n",
            "epoch  0 , batch  2030  current loss =  0.08382522709555795\n",
            "epoch  0 , batch  2031  current loss =  0.08381396045543503\n",
            "epoch  0 , batch  2032  current loss =  0.08377736870041855\n",
            "epoch  0 , batch  2033  current loss =  0.08376571760011971\n",
            "epoch  0 , batch  2034  current loss =  0.08375394452290029\n",
            "epoch  0 , batch  2035  current loss =  0.08371778387916667\n",
            "epoch  0 , batch  2036  current loss =  0.083705935768955\n",
            "epoch  0 , batch  2037  current loss =  0.08369405433202895\n",
            "epoch  0 , batch  2038  current loss =  0.0836584272823201\n",
            "epoch  0 , batch  2039  current loss =  0.08362284091611703\n",
            "epoch  0 , batch  2040  current loss =  0.08361100513690654\n",
            "epoch  0 , batch  2041  current loss =  0.0835752955019423\n",
            "epoch  0 , batch  2042  current loss =  0.08356347656797397\n",
            "epoch  0 , batch  2043  current loss =  0.08352760450573686\n",
            "epoch  0 , batch  2044  current loss =  0.08351596997672815\n",
            "epoch  0 , batch  2045  current loss =  0.08348000135849924\n",
            "epoch  0 , batch  2046  current loss =  0.08346849614385794\n",
            "epoch  0 , batch  2047  current loss =  0.08343249270956221\n",
            "epoch  0 , batch  2048  current loss =  0.08342122963664661\n",
            "epoch  0 , batch  2049  current loss =  0.0833852014849644\n",
            "epoch  0 , batch  2050  current loss =  0.08337412216177965\n",
            "epoch  0 , batch  2051  current loss =  0.08333811133039741\n",
            "epoch  0 , batch  2052  current loss =  0.08332708164236631\n",
            "epoch  0 , batch  2053  current loss =  0.08331607073770352\n",
            "epoch  0 , batch  2054  current loss =  0.08330491682437505\n",
            "epoch  0 , batch  2055  current loss =  0.08326909163511985\n",
            "epoch  0 , batch  2056  current loss =  0.08325776109570618\n",
            "epoch  0 , batch  2057  current loss =  0.08324633151939025\n",
            "epoch  0 , batch  2058  current loss =  0.08321078482023818\n",
            "epoch  0 , batch  2059  current loss =  0.08319922100020193\n",
            "epoch  0 , batch  2060  current loss =  0.08316387647960817\n",
            "epoch  0 , batch  2061  current loss =  0.0831285893590082\n",
            "epoch  0 , batch  2062  current loss =  0.08311706040392237\n",
            "epoch  0 , batch  2063  current loss =  0.08308176933959227\n",
            "epoch  0 , batch  2064  current loss =  0.08304643420678434\n",
            "epoch  0 , batch  2065  current loss =  0.08303509366501119\n",
            "epoch  0 , batch  2066  current loss =  0.08299967259651633\n",
            "epoch  0 , batch  2067  current loss =  0.08296419702681065\n",
            "epoch  0 , batch  2068  current loss =  0.08295317765220878\n",
            "epoch  0 , batch  2069  current loss =  0.0829176369631564\n",
            "epoch  0 , batch  2070  current loss =  0.08290685400391966\n",
            "epoch  0 , batch  2071  current loss =  0.08287130270205424\n",
            "epoch  0 , batch  2072  current loss =  0.08286068291846777\n",
            "epoch  0 , batch  2073  current loss =  0.0828251577662295\n",
            "epoch  0 , batch  2074  current loss =  0.08278965558677194\n",
            "epoch  0 , batch  2075  current loss =  0.08275416926821777\n",
            "epoch  0 , batch  2076  current loss =  0.08274368326088659\n",
            "epoch  0 , batch  2077  current loss =  0.08273317591942438\n",
            "epoch  0 , batch  2078  current loss =  0.08272260320007786\n",
            "epoch  0 , batch  2079  current loss =  0.08268725161816781\n",
            "epoch  0 , batch  2080  current loss =  0.08265196768891878\n",
            "epoch  0 , batch  2081  current loss =  0.08264118293837057\n",
            "epoch  0 , batch  2082  current loss =  0.08263034067388071\n",
            "epoch  0 , batch  2083  current loss =  0.08261940463342402\n",
            "epoch  0 , batch  2084  current loss =  0.08260842016462586\n",
            "epoch  0 , batch  2085  current loss =  0.0825973602082341\n",
            "epoch  0 , batch  2086  current loss =  0.08256291055308398\n",
            "epoch  0 , batch  2087  current loss =  0.08252855034016958\n",
            "epoch  0 , batch  2088  current loss =  0.0825174368843044\n",
            "epoch  0 , batch  2089  current loss =  0.08250633211155828\n",
            "epoch  0 , batch  2090  current loss =  0.08247191320600578\n",
            "epoch  0 , batch  2091  current loss =  0.08246082736955632\n",
            "epoch  0 , batch  2092  current loss =  0.08244977272669636\n",
            "epoch  0 , batch  2093  current loss =  0.08243875360915147\n",
            "epoch  0 , batch  2094  current loss =  0.08242773391519782\n",
            "epoch  0 , batch  2095  current loss =  0.08241666722705034\n",
            "epoch  0 , batch  2096  current loss =  0.08238246252526683\n",
            "epoch  0 , batch  2097  current loss =  0.08237133682168331\n",
            "epoch  0 , batch  2098  current loss =  0.0823372391093808\n",
            "epoch  0 , batch  2099  current loss =  0.08232612211878101\n",
            "epoch  0 , batch  2100  current loss =  0.08231501228688927\n",
            "epoch  0 , batch  2101  current loss =  0.08228098902564238\n",
            "epoch  0 , batch  2102  current loss =  0.08224697044244124\n",
            "epoch  0 , batch  2103  current loss =  0.08221291888818612\n",
            "epoch  0 , batch  2104  current loss =  0.08217879746666713\n",
            "epoch  0 , batch  2105  current loss =  0.0821445820055343\n",
            "epoch  0 , batch  2106  current loss =  0.08213415328726194\n",
            "epoch  0 , batch  2107  current loss =  0.08212390215272186\n",
            "epoch  0 , batch  2108  current loss =  0.08211365412265387\n",
            "epoch  0 , batch  2109  current loss =  0.08210331596681292\n",
            "epoch  0 , batch  2110  current loss =  0.08206907219078334\n",
            "epoch  0 , batch  2111  current loss =  0.08203490006792091\n",
            "epoch  0 , batch  2112  current loss =  0.0820007507768193\n",
            "epoch  0 , batch  2113  current loss =  0.08196661071658008\n",
            "epoch  0 , batch  2114  current loss =  0.08193245068694471\n",
            "epoch  0 , batch  2115  current loss =  0.08189826780650236\n",
            "epoch  0 , batch  2116  current loss =  0.08188806342187148\n",
            "epoch  0 , batch  2117  current loss =  0.08187789061679254\n",
            "epoch  0 , batch  2118  current loss =  0.08184368068720652\n",
            "epoch  0 , batch  2119  current loss =  0.08183354048436191\n",
            "epoch  0 , batch  2120  current loss =  0.08179936676212832\n",
            "epoch  0 , batch  2121  current loss =  0.0817892049982596\n",
            "epoch  0 , batch  2122  current loss =  0.08177899586820288\n",
            "epoch  0 , batch  2123  current loss =  0.08176875921236369\n",
            "epoch  0 , batch  2124  current loss =  0.08173485002535232\n",
            "epoch  0 , batch  2125  current loss =  0.08170103495642683\n",
            "epoch  0 , batch  2126  current loss =  0.08166723949007154\n",
            "epoch  0 , batch  2127  current loss =  0.08165696111360662\n",
            "epoch  0 , batch  2128  current loss =  0.0816466943997349\n",
            "epoch  0 , batch  2129  current loss =  0.08163636892404355\n",
            "epoch  0 , batch  2130  current loss =  0.08160264828910589\n",
            "epoch  0 , batch  2131  current loss =  0.08159236073726352\n",
            "epoch  0 , batch  2132  current loss =  0.08158205154116549\n",
            "epoch  0 , batch  2133  current loss =  0.0815484848295905\n",
            "epoch  0 , batch  2134  current loss =  0.0815381619896068\n",
            "epoch  0 , batch  2135  current loss =  0.08150469278088293\n",
            "epoch  0 , batch  2136  current loss =  0.08147122753696028\n",
            "epoch  0 , batch  2137  current loss =  0.08143771559930467\n",
            "epoch  0 , batch  2138  current loss =  0.08140414968906244\n",
            "epoch  0 , batch  2139  current loss =  0.08137053408590363\n",
            "epoch  0 , batch  2140  current loss =  0.08136089303735634\n",
            "epoch  0 , batch  2141  current loss =  0.0813272220319977\n",
            "epoch  0 , batch  2142  current loss =  0.08129353403855624\n",
            "epoch  0 , batch  2143  current loss =  0.08128444091616713\n",
            "epoch  0 , batch  2144  current loss =  0.08125073347839859\n",
            "epoch  0 , batch  2145  current loss =  0.08121703662939946\n",
            "epoch  0 , batch  2146  current loss =  0.08120810412196681\n",
            "epoch  0 , batch  2147  current loss =  0.08119907227103743\n",
            "epoch  0 , batch  2148  current loss =  0.08116545898318915\n",
            "epoch  0 , batch  2149  current loss =  0.08113189569782725\n",
            "epoch  0 , batch  2150  current loss =  0.08109837580084288\n",
            "epoch  0 , batch  2151  current loss =  0.08108889001125615\n",
            "epoch  0 , batch  2152  current loss =  0.08107937165374637\n",
            "epoch  0 , batch  2153  current loss =  0.0810697147499047\n",
            "epoch  0 , batch  2154  current loss =  0.08103645759788093\n",
            "epoch  0 , batch  2155  current loss =  0.0810266748068125\n",
            "epoch  0 , batch  2156  current loss =  0.08101682209029386\n",
            "epoch  0 , batch  2157  current loss =  0.08098398007070982\n",
            "epoch  0 , batch  2158  current loss =  0.0809511995903247\n",
            "epoch  0 , batch  2159  current loss =  0.08091836344640425\n",
            "epoch  0 , batch  2160  current loss =  0.08088539597353812\n",
            "epoch  0 , batch  2161  current loss =  0.0808523135564732\n",
            "epoch  0 , batch  2162  current loss =  0.08081914033048403\n",
            "epoch  0 , batch  2163  current loss =  0.08081000707243086\n",
            "epoch  0 , batch  2164  current loss =  0.08077674096592166\n",
            "epoch  0 , batch  2165  current loss =  0.08074346397825391\n",
            "epoch  0 , batch  2166  current loss =  0.08071016866058785\n",
            "epoch  0 , batch  2167  current loss =  0.08067686825078256\n",
            "epoch  0 , batch  2168  current loss =  0.08064354973368144\n",
            "epoch  0 , batch  2169  current loss =  0.08061020829573205\n",
            "epoch  0 , batch  2170  current loss =  0.08057686039008533\n",
            "epoch  0 , batch  2171  current loss =  0.08057039772103751\n",
            "epoch  0 , batch  2172  current loss =  0.08056386675149052\n",
            "epoch  0 , batch  2173  current loss =  0.08053054630485634\n",
            "epoch  0 , batch  2174  current loss =  0.08049727079126684\n",
            "epoch  0 , batch  2175  current loss =  0.0804640288479277\n",
            "epoch  0 , batch  2176  current loss =  0.08043082178085632\n",
            "epoch  0 , batch  2177  current loss =  0.08039764763489776\n",
            "epoch  0 , batch  2178  current loss =  0.0803644899484035\n",
            "epoch  0 , batch  2179  current loss =  0.08033135144270682\n",
            "epoch  0 , batch  2180  current loss =  0.08029824005357036\n",
            "epoch  0 , batch  2181  current loss =  0.08026513014557259\n",
            "epoch  0 , batch  2182  current loss =  0.08023201019566743\n",
            "epoch  0 , batch  2183  current loss =  0.08019889828419798\n",
            "epoch  0 , batch  2184  current loss =  0.08019121560381057\n",
            "epoch  0 , batch  2185  current loss =  0.08018351465588042\n",
            "epoch  0 , batch  2186  current loss =  0.08015044558125582\n",
            "epoch  0 , batch  2187  current loss =  0.08014247689006247\n",
            "epoch  0 , batch  2188  current loss =  0.08013435932026913\n",
            "epoch  0 , batch  2189  current loss =  0.08012601678391502\n",
            "epoch  0 , batch  2190  current loss =  0.08009332208203458\n",
            "epoch  0 , batch  2191  current loss =  0.08006076618092624\n",
            "epoch  0 , batch  2192  current loss =  0.08005213322533261\n",
            "epoch  0 , batch  2193  current loss =  0.08004344972665528\n",
            "epoch  0 , batch  2194  current loss =  0.08001120162487098\n",
            "epoch  0 , batch  2195  current loss =  0.08000248142362035\n",
            "epoch  0 , batch  2196  current loss =  0.07997030739510974\n",
            "epoch  0 , batch  2197  current loss =  0.07996162627226215\n",
            "epoch  0 , batch  2198  current loss =  0.07992940264778985\n",
            "epoch  0 , batch  2199  current loss =  0.07992074351080439\n",
            "epoch  0 , batch  2200  current loss =  0.07991212636049581\n",
            "epoch  0 , batch  2201  current loss =  0.07987989620944243\n",
            "epoch  0 , batch  2202  current loss =  0.07984767244520834\n",
            "epoch  0 , batch  2203  current loss =  0.07983912893244743\n",
            "epoch  0 , batch  2204  current loss =  0.07980689234575447\n",
            "epoch  0 , batch  2205  current loss =  0.07977464941650264\n",
            "epoch  0 , batch  2206  current loss =  0.07976639990310391\n",
            "epoch  0 , batch  2207  current loss =  0.07975823335995749\n",
            "epoch  0 , batch  2208  current loss =  0.07972603267283866\n",
            "epoch  0 , batch  2209  current loss =  0.07971779855929012\n",
            "epoch  0 , batch  2210  current loss =  0.0797095044900603\n",
            "epoch  0 , batch  2211  current loss =  0.0796774805205155\n",
            "epoch  0 , batch  2212  current loss =  0.07966905127970061\n",
            "epoch  0 , batch  2213  current loss =  0.07963717281406152\n",
            "epoch  0 , batch  2214  current loss =  0.0796286309877953\n",
            "epoch  0 , batch  2215  current loss =  0.07962007083071039\n",
            "epoch  0 , batch  2216  current loss =  0.0796114059398686\n",
            "epoch  0 , batch  2217  current loss =  0.07960264799558801\n",
            "epoch  0 , batch  2218  current loss =  0.07957135595099218\n",
            "epoch  0 , batch  2219  current loss =  0.07954016202087472\n",
            "epoch  0 , batch  2220  current loss =  0.07953136138289241\n",
            "epoch  0 , batch  2221  current loss =  0.07952255924575158\n",
            "epoch  0 , batch  2222  current loss =  0.07951368149445366\n",
            "epoch  0 , batch  2223  current loss =  0.07948258851416971\n",
            "epoch  0 , batch  2224  current loss =  0.07947377084430014\n",
            "epoch  0 , batch  2225  current loss =  0.07944265175075249\n",
            "epoch  0 , batch  2226  current loss =  0.07943401103868553\n",
            "epoch  0 , batch  2227  current loss =  0.07940283172665234\n",
            "epoch  0 , batch  2228  current loss =  0.07937158447113297\n",
            "epoch  0 , batch  2229  current loss =  0.07936320744346276\n",
            "epoch  0 , batch  2230  current loss =  0.07933183979486828\n",
            "epoch  0 , batch  2231  current loss =  0.07932385890519307\n",
            "epoch  0 , batch  2232  current loss =  0.07931593829866847\n",
            "epoch  0 , batch  2233  current loss =  0.07930779003478994\n",
            "epoch  0 , batch  2234  current loss =  0.07929953870215606\n",
            "epoch  0 , batch  2235  current loss =  0.07929130399821256\n",
            "epoch  0 , batch  2236  current loss =  0.07928287935104748\n",
            "epoch  0 , batch  2237  current loss =  0.07925179626974106\n",
            "epoch  0 , batch  2238  current loss =  0.07924316071228438\n",
            "epoch  0 , batch  2239  current loss =  0.07921291379898321\n",
            "epoch  0 , batch  2240  current loss =  0.0792041279559241\n",
            "epoch  0 , batch  2241  current loss =  0.07917399912030768\n",
            "epoch  0 , batch  2242  current loss =  0.07914391994921427\n",
            "epoch  0 , batch  2243  current loss =  0.07913496529055948\n",
            "epoch  0 , batch  2244  current loss =  0.07910477984945533\n",
            "epoch  0 , batch  2245  current loss =  0.07909609351302178\n",
            "epoch  0 , batch  2246  current loss =  0.07908734276809518\n",
            "epoch  0 , batch  2247  current loss =  0.07907865746435626\n",
            "epoch  0 , batch  2248  current loss =  0.07904837238894284\n",
            "epoch  0 , batch  2249  current loss =  0.0790180896959371\n",
            "epoch  0 , batch  2250  current loss =  0.07898776107130515\n",
            "epoch  0 , batch  2251  current loss =  0.07895736662517128\n",
            "epoch  0 , batch  2252  current loss =  0.07892688293889648\n",
            "epoch  0 , batch  2253  current loss =  0.07889632576003922\n",
            "epoch  0 , batch  2254  current loss =  0.07886566507594944\n",
            "epoch  0 , batch  2255  current loss =  0.07883492736632981\n",
            "epoch  0 , batch  2256  current loss =  0.07880410482536705\n",
            "epoch  0 , batch  2257  current loss =  0.07877321072430923\n",
            "epoch  0 , batch  2258  current loss =  0.07874225136865591\n",
            "epoch  0 , batch  2259  current loss =  0.07871125146697185\n",
            "epoch  0 , batch  2260  current loss =  0.07870637412994032\n",
            "epoch  0 , batch  2261  current loss =  0.07870127150424938\n",
            "epoch  0 , batch  2262  current loss =  0.07869554701262457\n",
            "epoch  0 , batch  2263  current loss =  0.0786645595319964\n",
            "epoch  0 , batch  2264  current loss =  0.07863362716103824\n",
            "epoch  0 , batch  2265  current loss =  0.07860275670197206\n",
            "epoch  0 , batch  2266  current loss =  0.07859528139044614\n",
            "epoch  0 , batch  2267  current loss =  0.07858753161516363\n",
            "epoch  0 , batch  2268  current loss =  0.07857963231705382\n",
            "epoch  0 , batch  2269  current loss =  0.07857148578587411\n",
            "epoch  0 , batch  2270  current loss =  0.07854187887987078\n",
            "epoch  0 , batch  2271  current loss =  0.07853369127703227\n",
            "epoch  0 , batch  2272  current loss =  0.07850442668918833\n",
            "epoch  0 , batch  2273  current loss =  0.07849618414762571\n",
            "epoch  0 , batch  2274  current loss =  0.07848798037394063\n",
            "epoch  0 , batch  2275  current loss =  0.07847974451687613\n",
            "epoch  0 , batch  2276  current loss =  0.0784715129995901\n",
            "epoch  0 , batch  2277  current loss =  0.07846323973756804\n",
            "epoch  0 , batch  2278  current loss =  0.07845495192529392\n",
            "epoch  0 , batch  2279  current loss =  0.07844665458818015\n",
            "epoch  0 , batch  2280  current loss =  0.07841731227096538\n",
            "epoch  0 , batch  2281  current loss =  0.07840900956208212\n",
            "epoch  0 , batch  2282  current loss =  0.07840069694435563\n",
            "epoch  0 , batch  2283  current loss =  0.0783713646090366\n",
            "epoch  0 , batch  2284  current loss =  0.07834195198666476\n",
            "epoch  0 , batch  2285  current loss =  0.07831239856963722\n",
            "epoch  0 , batch  2286  current loss =  0.07828272190099728\n",
            "epoch  0 , batch  2287  current loss =  0.07825293325879318\n",
            "epoch  0 , batch  2288  current loss =  0.0782454217637227\n",
            "epoch  0 , batch  2289  current loss =  0.07821547086492962\n",
            "epoch  0 , batch  2290  current loss =  0.0782083043599333\n",
            "epoch  0 , batch  2291  current loss =  0.07817826534289847\n",
            "epoch  0 , batch  2292  current loss =  0.07817137273978092\n",
            "epoch  0 , batch  2293  current loss =  0.07816450482757263\n",
            "epoch  0 , batch  2294  current loss =  0.0781575146660793\n",
            "epoch  0 , batch  2295  current loss =  0.07812755200151963\n",
            "epoch  0 , batch  2296  current loss =  0.07809764608695396\n",
            "epoch  0 , batch  2297  current loss =  0.07809027135404584\n",
            "epoch  0 , batch  2298  current loss =  0.07806045673998245\n",
            "epoch  0 , batch  2299  current loss =  0.07803065924095395\n",
            "epoch  0 , batch  2300  current loss =  0.07800088078552604\n",
            "epoch  0 , batch  2301  current loss =  0.07799338334103274\n",
            "epoch  0 , batch  2302  current loss =  0.07798590867558136\n",
            "epoch  0 , batch  2303  current loss =  0.07795617100418895\n",
            "epoch  0 , batch  2304  current loss =  0.07792644539561099\n",
            "epoch  0 , batch  2305  current loss =  0.07791902088735443\n",
            "epoch  0 , batch  2306  current loss =  0.07791156028560878\n",
            "epoch  0 , batch  2307  current loss =  0.07788189990644503\n",
            "epoch  0 , batch  2308  current loss =  0.07785226850120626\n",
            "epoch  0 , batch  2309  current loss =  0.07784480523011643\n",
            "epoch  0 , batch  2310  current loss =  0.07783732205558422\n",
            "epoch  0 , batch  2311  current loss =  0.07782981924673987\n",
            "epoch  0 , batch  2312  current loss =  0.07780029902124348\n",
            "epoch  0 , batch  2313  current loss =  0.07779271714469818\n",
            "epoch  0 , batch  2314  current loss =  0.07778510478753636\n",
            "epoch  0 , batch  2315  current loss =  0.07775576664569156\n",
            "epoch  0 , batch  2316  current loss =  0.07772647294291826\n",
            "epoch  0 , batch  2317  current loss =  0.07769715346314006\n",
            "epoch  0 , batch  2318  current loss =  0.07766777028760592\n",
            "epoch  0 , batch  2319  current loss =  0.07766040104626004\n",
            "epoch  0 , batch  2320  current loss =  0.07763091365468497\n",
            "epoch  0 , batch  2321  current loss =  0.0776238417851319\n",
            "epoch  0 , batch  2322  current loss =  0.07759433786023538\n",
            "epoch  0 , batch  2323  current loss =  0.07758730324506183\n",
            "epoch  0 , batch  2324  current loss =  0.07758027328719054\n",
            "epoch  0 , batch  2325  current loss =  0.07755082479284905\n",
            "epoch  0 , batch  2326  current loss =  0.07752141698380051\n",
            "epoch  0 , batch  2327  current loss =  0.07749201240949333\n",
            "epoch  0 , batch  2328  current loss =  0.0774626031029328\n",
            "epoch  0 , batch  2329  current loss =  0.0774331892053137\n",
            "epoch  0 , batch  2330  current loss =  0.07742629806478742\n",
            "epoch  0 , batch  2331  current loss =  0.07739686855637368\n",
            "epoch  0 , batch  2332  current loss =  0.0773674334949094\n",
            "epoch  0 , batch  2333  current loss =  0.07736073672330931\n",
            "epoch  0 , batch  2334  current loss =  0.07735409337620408\n",
            "epoch  0 , batch  2335  current loss =  0.07732473695028752\n",
            "epoch  0 , batch  2336  current loss =  0.0773179218273452\n",
            "epoch  0 , batch  2337  current loss =  0.07731088023900451\n",
            "epoch  0 , batch  2338  current loss =  0.07728171421317666\n",
            "epoch  0 , batch  2339  current loss =  0.0772526289925425\n",
            "epoch  0 , batch  2340  current loss =  0.07722357925567068\n",
            "epoch  0 , batch  2341  current loss =  0.07719452169315809\n",
            "epoch  0 , batch  2342  current loss =  0.07716542332044815\n",
            "epoch  0 , batch  2343  current loss =  0.0771585790632744\n",
            "epoch  0 , batch  2344  current loss =  0.07715172373902188\n",
            "epoch  0 , batch  2345  current loss =  0.077144934981585\n",
            "epoch  0 , batch  2346  current loss =  0.07713813769373555\n",
            "epoch  0 , batch  2347  current loss =  0.07710908890663752\n",
            "epoch  0 , batch  2348  current loss =  0.0771022038827676\n",
            "epoch  0 , batch  2349  current loss =  0.07707326911944658\n",
            "epoch  0 , batch  2350  current loss =  0.07704437073155357\n",
            "epoch  0 , batch  2351  current loss =  0.07703737464145802\n",
            "epoch  0 , batch  2352  current loss =  0.07700855645623819\n",
            "epoch  0 , batch  2353  current loss =  0.07697974838800696\n",
            "epoch  0 , batch  2354  current loss =  0.07697282784762782\n",
            "epoch  0 , batch  2355  current loss =  0.07696591328010469\n",
            "epoch  0 , batch  2356  current loss =  0.07693711193187552\n",
            "epoch  0 , batch  2357  current loss =  0.07693023267980156\n",
            "epoch  0 , batch  2358  current loss =  0.07692336250055501\n",
            "epoch  0 , batch  2359  current loss =  0.0768946822858968\n",
            "epoch  0 , batch  2360  current loss =  0.0768660420472215\n",
            "epoch  0 , batch  2361  current loss =  0.0768374185717391\n",
            "epoch  0 , batch  2362  current loss =  0.07683047749436335\n",
            "epoch  0 , batch  2363  current loss =  0.07680182459696422\n",
            "epoch  0 , batch  2364  current loss =  0.07677311812612143\n",
            "epoch  0 , batch  2365  current loss =  0.07674444778070534\n",
            "epoch  0 , batch  2366  current loss =  0.07673787224068325\n",
            "epoch  0 , batch  2367  current loss =  0.07673128569188742\n",
            "epoch  0 , batch  2368  current loss =  0.07670261611381239\n",
            "epoch  0 , batch  2369  current loss =  0.07667396831746658\n",
            "epoch  0 , batch  2370  current loss =  0.07664532632496678\n",
            "epoch  0 , batch  2371  current loss =  0.07663895097101016\n",
            "epoch  0 , batch  2372  current loss =  0.07663262001400852\n",
            "epoch  0 , batch  2373  current loss =  0.07662602353969741\n",
            "epoch  0 , batch  2374  current loss =  0.07661947672774917\n",
            "epoch  0 , batch  2375  current loss =  0.07659092798644068\n",
            "epoch  0 , batch  2376  current loss =  0.07656233699629487\n",
            "epoch  0 , batch  2377  current loss =  0.07655557715964541\n",
            "epoch  0 , batch  2378  current loss =  0.07652724806075276\n",
            "epoch  0 , batch  2379  current loss =  0.07649873084889552\n",
            "epoch  0 , batch  2380  current loss =  0.07649204909139662\n",
            "epoch  0 , batch  2381  current loss =  0.07646357383005052\n",
            "epoch  0 , batch  2382  current loss =  0.07643504996959509\n",
            "epoch  0 , batch  2383  current loss =  0.07642847391575162\n",
            "epoch  0 , batch  2384  current loss =  0.07640005998875735\n",
            "epoch  0 , batch  2385  current loss =  0.07637143430119725\n",
            "epoch  0 , batch  2386  current loss =  0.0763428061950841\n",
            "epoch  0 , batch  2387  current loss =  0.0763365944638424\n",
            "epoch  0 , batch  2388  current loss =  0.07633041207943315\n",
            "epoch  0 , batch  2389  current loss =  0.07632406924122546\n",
            "epoch  0 , batch  2390  current loss =  0.07629564064404908\n",
            "epoch  0 , batch  2391  current loss =  0.07628915255249206\n",
            "epoch  0 , batch  2392  current loss =  0.0762826599997211\n",
            "epoch  0 , batch  2393  current loss =  0.07627605040944373\n",
            "epoch  0 , batch  2394  current loss =  0.0762692118475762\n",
            "epoch  0 , batch  2395  current loss =  0.07624163961532418\n",
            "epoch  0 , batch  2396  current loss =  0.07621419874886746\n",
            "epoch  0 , batch  2397  current loss =  0.07618675429181346\n",
            "epoch  0 , batch  2398  current loss =  0.07617995605919325\n",
            "epoch  0 , batch  2399  current loss =  0.0761730862975431\n",
            "epoch  0 , batch  2400  current loss =  0.07616627345661454\n",
            "epoch  0 , batch  2401  current loss =  0.07613878591229625\n",
            "epoch  0 , batch  2402  current loss =  0.07613205917170283\n",
            "epoch  0 , batch  2403  current loss =  0.0761253405672292\n",
            "epoch  0 , batch  2404  current loss =  0.07609790339330191\n",
            "epoch  0 , batch  2405  current loss =  0.07609118248435885\n",
            "epoch  0 , batch  2406  current loss =  0.07606379061977572\n",
            "epoch  0 , batch  2407  current loss =  0.07603637816382888\n",
            "epoch  0 , batch  2408  current loss =  0.0760296701672829\n",
            "epoch  0 , batch  2409  current loss =  0.07600232858782735\n",
            "epoch  0 , batch  2410  current loss =  0.07599575557231854\n",
            "epoch  0 , batch  2411  current loss =  0.07598919206596973\n",
            "epoch  0 , batch  2412  current loss =  0.07596181468923113\n",
            "epoch  0 , batch  2413  current loss =  0.07593443744847522\n",
            "epoch  0 , batch  2414  current loss =  0.07590703064456243\n",
            "epoch  0 , batch  2415  current loss =  0.07587955773704753\n",
            "epoch  0 , batch  2416  current loss =  0.07585201309674046\n",
            "epoch  0 , batch  2417  current loss =  0.07582438418586224\n",
            "epoch  0 , batch  2418  current loss =  0.07579667048752863\n",
            "epoch  0 , batch  2419  current loss =  0.07576888826991285\n",
            "epoch  0 , batch  2420  current loss =  0.07576364542148739\n",
            "epoch  0 , batch  2421  current loss =  0.07573584002318841\n",
            "epoch  0 , batch  2422  current loss =  0.07573072058450411\n",
            "epoch  0 , batch  2423  current loss =  0.07570289988063042\n",
            "epoch  0 , batch  2424  current loss =  0.07567508580796804\n",
            "epoch  0 , batch  2425  current loss =  0.07566984714970902\n",
            "epoch  0 , batch  2426  current loss =  0.07566443876508004\n",
            "epoch  0 , batch  2427  current loss =  0.07565880714013522\n",
            "epoch  0 , batch  2428  current loss =  0.07565296795633275\n",
            "epoch  0 , batch  2429  current loss =  0.07564693313789526\n",
            "epoch  0 , batch  2430  current loss =  0.07564073949722792\n",
            "epoch  0 , batch  2431  current loss =  0.07561389152090812\n",
            "epoch  0 , batch  2432  current loss =  0.0755872477031249\n",
            "epoch  0 , batch  2433  current loss =  0.0755605415315593\n",
            "epoch  0 , batch  2434  current loss =  0.07555421483138809\n",
            "epoch  0 , batch  2435  current loss =  0.07554787755729737\n",
            "epoch  0 , batch  2436  current loss =  0.07552080380221676\n",
            "epoch  0 , batch  2437  current loss =  0.07551455833254668\n",
            "epoch  0 , batch  2438  current loss =  0.07550839790154146\n",
            "epoch  0 , batch  2439  current loss =  0.07550223964976421\n",
            "epoch  0 , batch  2440  current loss =  0.07549609148906164\n",
            "epoch  0 , batch  2441  current loss =  0.07548984038978387\n",
            "epoch  0 , batch  2442  current loss =  0.07546292115963547\n",
            "epoch  0 , batch  2443  current loss =  0.0754360757873328\n",
            "epoch  0 , batch  2444  current loss =  0.07540924611686137\n",
            "epoch  0 , batch  2445  current loss =  0.07540294840644043\n",
            "epoch  0 , batch  2446  current loss =  0.07539664511197762\n",
            "epoch  0 , batch  2447  current loss =  0.07539038549997581\n",
            "epoch  0 , batch  2448  current loss =  0.0753840470265197\n",
            "epoch  0 , batch  2449  current loss =  0.07535744837048103\n",
            "epoch  0 , batch  2450  current loss =  0.07535099026282337\n",
            "epoch  0 , batch  2451  current loss =  0.07532452512646419\n",
            "epoch  0 , batch  2452  current loss =  0.07531809546182497\n",
            "epoch  0 , batch  2453  current loss =  0.07531163595979631\n",
            "epoch  0 , batch  2454  current loss =  0.07528530179111328\n",
            "epoch  0 , batch  2455  current loss =  0.07525897889924373\n",
            "epoch  0 , batch  2456  current loss =  0.07523260096684674\n",
            "epoch  0 , batch  2457  current loss =  0.07520619079173581\n",
            "epoch  0 , batch  2458  current loss =  0.07519997235186074\n",
            "epoch  0 , batch  2459  current loss =  0.07519382495675388\n",
            "epoch  0 , batch  2460  current loss =  0.07518773432707505\n",
            "epoch  0 , batch  2461  current loss =  0.07516115314079785\n",
            "epoch  0 , batch  2462  current loss =  0.07513456657291415\n",
            "epoch  0 , batch  2463  current loss =  0.07512853988680637\n",
            "epoch  0 , batch  2464  current loss =  0.0751225235900307\n",
            "epoch  0 , batch  2465  current loss =  0.07511645645040653\n",
            "epoch  0 , batch  2466  current loss =  0.0751103345507829\n",
            "epoch  0 , batch  2467  current loss =  0.07508391669854775\n",
            "epoch  0 , batch  2468  current loss =  0.07507761110770057\n",
            "epoch  0 , batch  2469  current loss =  0.07505133793300946\n",
            "epoch  0 , batch  2470  current loss =  0.07504498870543554\n",
            "epoch  0 , batch  2471  current loss =  0.07501881455130044\n",
            "epoch  0 , batch  2472  current loss =  0.07501249190109598\n",
            "epoch  0 , batch  2473  current loss =  0.07500618369045246\n",
            "epoch  0 , batch  2474  current loss =  0.0749998582828075\n",
            "epoch  0 , batch  2475  current loss =  0.07497380211797387\n",
            "epoch  0 , batch  2476  current loss =  0.07494773265601504\n",
            "epoch  0 , batch  2477  current loss =  0.0749216352009137\n",
            "epoch  0 , batch  2478  current loss =  0.074895439029323\n",
            "epoch  0 , batch  2479  current loss =  0.07486916165047836\n",
            "epoch  0 , batch  2480  current loss =  0.07484279449951055\n",
            "epoch  0 , batch  2481  current loss =  0.07483730073395357\n",
            "epoch  0 , batch  2482  current loss =  0.07481081183006566\n",
            "epoch  0 , batch  2483  current loss =  0.07478428615524094\n",
            "epoch  0 , batch  2484  current loss =  0.07477946713776655\n",
            "epoch  0 , batch  2485  current loss =  0.0747529258288455\n",
            "epoch  0 , batch  2486  current loss =  0.07472639773370549\n",
            "epoch  0 , batch  2487  current loss =  0.07469985957243974\n",
            "epoch  0 , batch  2488  current loss =  0.07469527135154494\n",
            "epoch  0 , batch  2489  current loss =  0.07466872701810366\n",
            "epoch  0 , batch  2490  current loss =  0.07466389186977922\n",
            "epoch  0 , batch  2491  current loss =  0.07463738543166813\n",
            "epoch  0 , batch  2492  current loss =  0.07461088268004874\n",
            "epoch  0 , batch  2493  current loss =  0.07458440943993777\n",
            "epoch  0 , batch  2494  current loss =  0.07457904683310307\n",
            "epoch  0 , batch  2495  current loss =  0.07457366951469642\n",
            "epoch  0 , batch  2496  current loss =  0.07456819087484741\n",
            "epoch  0 , batch  2497  current loss =  0.07456253965521713\n",
            "epoch  0 , batch  2498  current loss =  0.07455684122319768\n",
            "epoch  0 , batch  2499  current loss =  0.07453102230913937\n",
            "epoch  0 , batch  2500  current loss =  0.07450526438486643\n",
            "epoch  0 , batch  2501  current loss =  0.07447947537173613\n",
            "epoch  0 , batch  2502  current loss =  0.07447371369021634\n",
            "epoch  0 , batch  2503  current loss =  0.0744477676238103\n",
            "epoch  0 , batch  2504  current loss =  0.07444200735769704\n",
            "epoch  0 , batch  2505  current loss =  0.07441603330893819\n",
            "epoch  0 , batch  2506  current loss =  0.07439002849118533\n",
            "epoch  0 , batch  2507  current loss =  0.07438458045283584\n",
            "epoch  0 , batch  2508  current loss =  0.0743585401272194\n",
            "epoch  0 , batch  2509  current loss =  0.07435330405712602\n",
            "epoch  0 , batch  2510  current loss =  0.07434810461696759\n",
            "epoch  0 , batch  2511  current loss =  0.07434284565733022\n",
            "epoch  0 , batch  2512  current loss =  0.07431691089979311\n",
            "epoch  0 , batch  2513  current loss =  0.07431145942071267\n",
            "epoch  0 , batch  2514  current loss =  0.07428563445376947\n",
            "epoch  0 , batch  2515  current loss =  0.07428005439657215\n",
            "epoch  0 , batch  2516  current loss =  0.0742543620487729\n",
            "epoch  0 , batch  2517  current loss =  0.07424869037782914\n",
            "epoch  0 , batch  2518  current loss =  0.07424296848121002\n",
            "epoch  0 , batch  2519  current loss =  0.07421748231032065\n",
            "epoch  0 , batch  2520  current loss =  0.07421179474706406\n",
            "epoch  0 , batch  2521  current loss =  0.07420607513107778\n",
            "epoch  0 , batch  2522  current loss =  0.0742003042568326\n",
            "epoch  0 , batch  2523  current loss =  0.0741750133296153\n",
            "epoch  0 , batch  2524  current loss =  0.07414973245620138\n",
            "epoch  0 , batch  2525  current loss =  0.07412437818316199\n",
            "epoch  0 , batch  2526  current loss =  0.07411865004108718\n",
            "epoch  0 , batch  2527  current loss =  0.07411295460180461\n",
            "epoch  0 , batch  2528  current loss =  0.07408745308395971\n",
            "epoch  0 , batch  2529  current loss =  0.07408189395214376\n",
            "epoch  0 , batch  2530  current loss =  0.0740763479045249\n",
            "epoch  0 , batch  2531  current loss =  0.07405086278423996\n",
            "epoch  0 , batch  2532  current loss =  0.0740452975503868\n",
            "epoch  0 , batch  2533  current loss =  0.07401985633933084\n",
            "epoch  0 , batch  2534  current loss =  0.07399443023244776\n",
            "epoch  0 , batch  2535  current loss =  0.07396899344625792\n",
            "epoch  0 , batch  2536  current loss =  0.07396359007275499\n",
            "epoch  0 , batch  2537  current loss =  0.07393812386787271\n",
            "epoch  0 , batch  2538  current loss =  0.07391263059163983\n",
            "epoch  0 , batch  2539  current loss =  0.07390737312361892\n",
            "epoch  0 , batch  2540  current loss =  0.0738818548130079\n",
            "epoch  0 , batch  2541  current loss =  0.07385632620734565\n",
            "epoch  0 , batch  2542  current loss =  0.07385125665328855\n",
            "epoch  0 , batch  2543  current loss =  0.07384617138052148\n",
            "epoch  0 , batch  2544  current loss =  0.073820661273666\n",
            "epoch  0 , batch  2545  current loss =  0.07379517025765667\n",
            "epoch  0 , batch  2546  current loss =  0.07379003815736122\n",
            "epoch  0 , batch  2547  current loss =  0.07376458829457416\n",
            "epoch  0 , batch  2548  current loss =  0.0737391565551871\n",
            "epoch  0 , batch  2549  current loss =  0.07373402735912332\n",
            "epoch  0 , batch  2550  current loss =  0.07372887526036057\n",
            "epoch  0 , batch  2551  current loss =  0.07370352621852978\n",
            "epoch  0 , batch  2552  current loss =  0.07367820886561638\n",
            "epoch  0 , batch  2553  current loss =  0.07367305896597197\n",
            "epoch  0 , batch  2554  current loss =  0.07366791066117657\n",
            "epoch  0 , batch  2555  current loss =  0.07366269417158117\n",
            "epoch  0 , batch  2556  current loss =  0.07365744616282688\n",
            "epoch  0 , batch  2557  current loss =  0.0736323745129011\n",
            "epoch  0 , batch  2558  current loss =  0.07360735524485078\n",
            "epoch  0 , batch  2559  current loss =  0.07358233864324575\n",
            "epoch  0 , batch  2560  current loss =  0.07357709086618297\n",
            "epoch  0 , batch  2561  current loss =  0.07357188457823784\n",
            "epoch  0 , batch  2562  current loss =  0.07354678706619547\n",
            "epoch  0 , batch  2563  current loss =  0.07354160176819646\n",
            "epoch  0 , batch  2564  current loss =  0.07353643531862059\n",
            "epoch  0 , batch  2565  current loss =  0.07351140117865064\n",
            "epoch  0 , batch  2566  current loss =  0.07350624073804714\n",
            "epoch  0 , batch  2567  current loss =  0.07348124980397024\n",
            "epoch  0 , batch  2568  current loss =  0.0734760380477299\n",
            "epoch  0 , batch  2569  current loss =  0.07345111478982559\n",
            "epoch  0 , batch  2570  current loss =  0.07344591372745284\n",
            "epoch  0 , batch  2571  current loss =  0.07342103223858074\n",
            "epoch  0 , batch  2572  current loss =  0.07339615648553742\n",
            "epoch  0 , batch  2573  current loss =  0.0733910336646902\n",
            "epoch  0 , batch  2574  current loss =  0.07338591426140764\n",
            "epoch  0 , batch  2575  current loss =  0.07336107384585573\n",
            "epoch  0 , batch  2576  current loss =  0.07333623563352543\n",
            "epoch  0 , batch  2577  current loss =  0.0733311678256906\n",
            "epoch  0 , batch  2578  current loss =  0.07332610102141433\n",
            "epoch  0 , batch  2579  current loss =  0.07330131330310778\n",
            "epoch  0 , batch  2580  current loss =  0.0732961995714784\n",
            "epoch  0 , batch  2581  current loss =  0.07327145158142244\n",
            "epoch  0 , batch  2582  current loss =  0.07326636215916356\n",
            "epoch  0 , batch  2583  current loss =  0.0732416736341194\n",
            "epoch  0 , batch  2584  current loss =  0.07321698018016448\n",
            "epoch  0 , batch  2585  current loss =  0.0731922531819543\n",
            "epoch  0 , batch  2586  current loss =  0.073187295288772\n",
            "epoch  0 , batch  2587  current loss =  0.07316254112557141\n",
            "epoch  0 , batch  2588  current loss =  0.07315771370318956\n",
            "epoch  0 , batch  2589  current loss =  0.0731329525885636\n",
            "epoch  0 , batch  2590  current loss =  0.07310817393016707\n",
            "epoch  0 , batch  2591  current loss =  0.07310346651133898\n",
            "epoch  0 , batch  2592  current loss =  0.07309876546454772\n",
            "epoch  0 , batch  2593  current loss =  0.07309400999872624\n",
            "epoch  0 , batch  2594  current loss =  0.0730693115025529\n",
            "epoch  0 , batch  2595  current loss =  0.07306442720649078\n",
            "epoch  0 , batch  2596  current loss =  0.07303987579326252\n",
            "epoch  0 , batch  2597  current loss =  0.07303485896522961\n",
            "epoch  0 , batch  2598  current loss =  0.07302984733510047\n",
            "epoch  0 , batch  2599  current loss =  0.07300551287937336\n",
            "epoch  0 , batch  2600  current loss =  0.07300045861268573\n",
            "epoch  0 , batch  2601  current loss =  0.07299538264638078\n",
            "epoch  0 , batch  2602  current loss =  0.07299026275104427\n",
            "epoch  0 , batch  2603  current loss =  0.0729850838114629\n",
            "epoch  0 , batch  2604  current loss =  0.07296114875336183\n",
            "epoch  0 , batch  2605  current loss =  0.07293722944166897\n",
            "epoch  0 , batch  2606  current loss =  0.07293204876255226\n",
            "epoch  0 , batch  2607  current loss =  0.07292690296711662\n",
            "epoch  0 , batch  2608  current loss =  0.07292177282336595\n",
            "epoch  0 , batch  2609  current loss =  0.07291663082609118\n",
            "epoch  0 , batch  2610  current loss =  0.0728926895199146\n",
            "epoch  0 , batch  2611  current loss =  0.07288754491633229\n",
            "epoch  0 , batch  2612  current loss =  0.07286365232204073\n",
            "epoch  0 , batch  2613  current loss =  0.07283974337080164\n",
            "epoch  0 , batch  2614  current loss =  0.07281577078835687\n",
            "epoch  0 , batch  2615  current loss =  0.07279170880454452\n",
            "epoch  0 , batch  2616  current loss =  0.0727675587357366\n",
            "epoch  0 , batch  2617  current loss =  0.07274333575087322\n",
            "epoch  0 , batch  2618  current loss =  0.07273922818021243\n",
            "epoch  0 , batch  2619  current loss =  0.0727352298049697\n",
            "epoch  0 , batch  2620  current loss =  0.07273115120964599\n",
            "epoch  0 , batch  2621  current loss =  0.07270686246858218\n",
            "epoch  0 , batch  2622  current loss =  0.07268259186067576\n",
            "epoch  0 , batch  2623  current loss =  0.07265834566652946\n",
            "epoch  0 , batch  2624  current loss =  0.07263410877933105\n",
            "epoch  0 , batch  2625  current loss =  0.07260986899862014\n",
            "epoch  0 , batch  2626  current loss =  0.07258561108832833\n",
            "epoch  0 , batch  2627  current loss =  0.07258134955665042\n",
            "epoch  0 , batch  2628  current loss =  0.07255707717702195\n",
            "epoch  0 , batch  2629  current loss =  0.07255284066768823\n",
            "epoch  0 , batch  2630  current loss =  0.07252856742920576\n",
            "epoch  0 , batch  2631  current loss =  0.07250430168567004\n",
            "epoch  0 , batch  2632  current loss =  0.07250002547504329\n",
            "epoch  0 , batch  2633  current loss =  0.07247579661809649\n",
            "epoch  0 , batch  2634  current loss =  0.0724515841369017\n",
            "epoch  0 , batch  2635  current loss =  0.07244731476622293\n",
            "epoch  0 , batch  2636  current loss =  0.0724430318888606\n",
            "epoch  0 , batch  2637  current loss =  0.07243871983385011\n",
            "epoch  0 , batch  2638  current loss =  0.07243432340576719\n",
            "epoch  0 , batch  2639  current loss =  0.07242979013015319\n",
            "epoch  0 , batch  2640  current loss =  0.07240600925854371\n",
            "epoch  0 , batch  2641  current loss =  0.07238229147576636\n",
            "epoch  0 , batch  2642  current loss =  0.07235856540536355\n",
            "epoch  0 , batch  2643  current loss =  0.0723347543769075\n",
            "epoch  0 , batch  2644  current loss =  0.07231082801719413\n",
            "epoch  0 , batch  2645  current loss =  0.0722867975413422\n",
            "epoch  0 , batch  2646  current loss =  0.07228274131457638\n",
            "epoch  0 , batch  2647  current loss =  0.07225862227829055\n",
            "epoch  0 , batch  2648  current loss =  0.07225494822202459\n",
            "epoch  0 , batch  2649  current loss =  0.07223082142653611\n",
            "epoch  0 , batch  2650  current loss =  0.07222709870854725\n",
            "epoch  0 , batch  2651  current loss =  0.07220313301609146\n",
            "epoch  0 , batch  2652  current loss =  0.07219936036007374\n",
            "epoch  0 , batch  2653  current loss =  0.07219539688389184\n",
            "epoch  0 , batch  2654  current loss =  0.07219127161768589\n",
            "epoch  0 , batch  2655  current loss =  0.07216753259003836\n",
            "epoch  0 , batch  2656  current loss =  0.07216306819973424\n",
            "epoch  0 , batch  2657  current loss =  0.07215850416254153\n",
            "epoch  0 , batch  2658  current loss =  0.07215393908761775\n",
            "epoch  0 , batch  2659  current loss =  0.07213083527828182\n",
            "epoch  0 , batch  2660  current loss =  0.07210783559649801\n",
            "epoch  0 , batch  2661  current loss =  0.07208479221127956\n",
            "epoch  0 , batch  2662  current loss =  0.07206160258788544\n",
            "epoch  0 , batch  2663  current loss =  0.07203825693137038\n",
            "epoch  0 , batch  2664  current loss =  0.07203385360420142\n",
            "epoch  0 , batch  2665  current loss =  0.07201030119744933\n",
            "epoch  0 , batch  2666  current loss =  0.07198668225592594\n",
            "epoch  0 , batch  2667  current loss =  0.0719629845196574\n",
            "epoch  0 , batch  2668  current loss =  0.07193922582816971\n",
            "epoch  0 , batch  2669  current loss =  0.07193598076701165\n",
            "epoch  0 , batch  2670  current loss =  0.07193284207283446\n",
            "epoch  0 , batch  2671  current loss =  0.07190900361534866\n",
            "epoch  0 , batch  2672  current loss =  0.07190570947733313\n",
            "epoch  0 , batch  2673  current loss =  0.07188191334699562\n",
            "epoch  0 , batch  2674  current loss =  0.07185812559640296\n",
            "epoch  0 , batch  2675  current loss =  0.07183435849667219\n",
            "epoch  0 , batch  2676  current loss =  0.07183076947270643\n",
            "epoch  0 , batch  2677  current loss =  0.07182712172581644\n",
            "epoch  0 , batch  2678  current loss =  0.07180343906298842\n",
            "epoch  0 , batch  2679  current loss =  0.07179958855163361\n",
            "epoch  0 , batch  2680  current loss =  0.0717760094346639\n",
            "epoch  0 , batch  2681  current loss =  0.07177203705730188\n",
            "epoch  0 , batch  2682  current loss =  0.0717486148277326\n",
            "epoch  0 , batch  2683  current loss =  0.07172524291659732\n",
            "epoch  0 , batch  2684  current loss =  0.07172114923006719\n",
            "epoch  0 , batch  2685  current loss =  0.07171704549216183\n",
            "epoch  0 , batch  2686  current loss =  0.07171291281730159\n",
            "epoch  0 , batch  2687  current loss =  0.07170884661519224\n",
            "epoch  0 , batch  2688  current loss =  0.07168562816093683\n",
            "epoch  0 , batch  2689  current loss =  0.07168143503194793\n",
            "epoch  0 , batch  2690  current loss =  0.07167720951767038\n",
            "epoch  0 , batch  2691  current loss =  0.07165427618199215\n",
            "epoch  0 , batch  2692  current loss =  0.07163132056199648\n",
            "epoch  0 , batch  2693  current loss =  0.07162721202699793\n",
            "epoch  0 , batch  2694  current loss =  0.07162314923877564\n",
            "epoch  0 , batch  2695  current loss =  0.07160003782175371\n",
            "epoch  0 , batch  2696  current loss =  0.07159599674672916\n",
            "epoch  0 , batch  2697  current loss =  0.07159193552025298\n",
            "epoch  0 , batch  2698  current loss =  0.07156888105833738\n",
            "epoch  0 , batch  2699  current loss =  0.07156478149885381\n",
            "epoch  0 , batch  2700  current loss =  0.07156063425252941\n",
            "epoch  0 , batch  2701  current loss =  0.07153773852703275\n",
            "epoch  0 , batch  2702  current loss =  0.07151490601852586\n",
            "epoch  0 , batch  2703  current loss =  0.0715106831244937\n",
            "epoch  0 , batch  2704  current loss =  0.07150642296399184\n",
            "epoch  0 , batch  2705  current loss =  0.07150218309869016\n",
            "epoch  0 , batch  2706  current loss =  0.07147955763768535\n",
            "epoch  0 , batch  2707  current loss =  0.07147525470226486\n",
            "epoch  0 , batch  2708  current loss =  0.0714709020510932\n",
            "epoch  0 , batch  2709  current loss =  0.0714665246642851\n",
            "epoch  0 , batch  2710  current loss =  0.07146207131795813\n",
            "epoch  0 , batch  2711  current loss =  0.07143986420630365\n",
            "epoch  0 , batch  2712  current loss =  0.07141770952141926\n",
            "epoch  0 , batch  2713  current loss =  0.07139550534769476\n",
            "epoch  0 , batch  2714  current loss =  0.0713910830219175\n",
            "epoch  0 , batch  2715  current loss =  0.07136869469701432\n",
            "epoch  0 , batch  2716  current loss =  0.0713462353981195\n",
            "epoch  0 , batch  2717  current loss =  0.07134213567059693\n",
            "epoch  0 , batch  2718  current loss =  0.07133811121068706\n",
            "epoch  0 , batch  2719  current loss =  0.07131551060695475\n",
            "epoch  0 , batch  2720  current loss =  0.07129289283396971\n",
            "epoch  0 , batch  2721  current loss =  0.07128908794371905\n",
            "epoch  0 , batch  2722  current loss =  0.0712853000446979\n",
            "epoch  0 , batch  2723  current loss =  0.07126266906132289\n",
            "epoch  0 , batch  2724  current loss =  0.0712587739510137\n",
            "epoch  0 , batch  2725  current loss =  0.07125478573874601\n",
            "epoch  0 , batch  2726  current loss =  0.07123228909224436\n",
            "epoch  0 , batch  2727  current loss =  0.07120984421955569\n",
            "epoch  0 , batch  2728  current loss =  0.07118742058914293\n",
            "epoch  0 , batch  2729  current loss =  0.07118334377239094\n",
            "epoch  0 , batch  2730  current loss =  0.07116091284281613\n",
            "epoch  0 , batch  2731  current loss =  0.07115680764369274\n",
            "epoch  0 , batch  2732  current loss =  0.07115271941891933\n",
            "epoch  0 , batch  2733  current loss =  0.07114859562927221\n",
            "epoch  0 , batch  2734  current loss =  0.07112625647724438\n",
            "epoch  0 , batch  2735  current loss =  0.07110393548259043\n",
            "epoch  0 , batch  2736  current loss =  0.07109988938675425\n",
            "epoch  0 , batch  2737  current loss =  0.07109583737811657\n",
            "epoch  0 , batch  2738  current loss =  0.07107353120853199\n",
            "epoch  0 , batch  2739  current loss =  0.07105121916996138\n",
            "epoch  0 , batch  2740  current loss =  0.0710288618179225\n",
            "epoch  0 , batch  2741  current loss =  0.07102498157088455\n",
            "epoch  0 , batch  2742  current loss =  0.07100254791200357\n",
            "epoch  0 , batch  2743  current loss =  0.0709800741400396\n",
            "epoch  0 , batch  2744  current loss =  0.0709575630259617\n",
            "epoch  0 , batch  2745  current loss =  0.07095420665636072\n",
            "epoch  0 , batch  2746  current loss =  0.0709316533623032\n",
            "epoch  0 , batch  2747  current loss =  0.0709090918049032\n",
            "epoch  0 , batch  2748  current loss =  0.0708865149145849\n",
            "epoch  0 , batch  2749  current loss =  0.07088355327092788\n",
            "epoch  0 , batch  2750  current loss =  0.0708805370926234\n",
            "epoch  0 , batch  2751  current loss =  0.07087733368369004\n",
            "epoch  0 , batch  2752  current loss =  0.07087383425263083\n",
            "epoch  0 , batch  2753  current loss =  0.07087013269108419\n",
            "epoch  0 , batch  2754  current loss =  0.0708662399853125\n",
            "epoch  0 , batch  2755  current loss =  0.07084436595564267\n",
            "epoch  0 , batch  2756  current loss =  0.0708226458708991\n",
            "epoch  0 , batch  2757  current loss =  0.07081867530408428\n",
            "epoch  0 , batch  2758  current loss =  0.07079700982294661\n",
            "epoch  0 , batch  2759  current loss =  0.07079302168289281\n",
            "epoch  0 , batch  2760  current loss =  0.07077120136157924\n",
            "epoch  0 , batch  2761  current loss =  0.0707672022129318\n",
            "epoch  0 , batch  2762  current loss =  0.07076321642170381\n",
            "epoch  0 , batch  2763  current loss =  0.0707592500317114\n",
            "epoch  0 , batch  2764  current loss =  0.07073723638319085\n",
            "epoch  0 , batch  2765  current loss =  0.07071522693806317\n",
            "epoch  0 , batch  2766  current loss =  0.07069317919155364\n",
            "epoch  0 , batch  2767  current loss =  0.07067108858845095\n",
            "epoch  0 , batch  2768  current loss =  0.07066760484617554\n",
            "epoch  0 , batch  2769  current loss =  0.07064544011633642\n",
            "epoch  0 , batch  2770  current loss =  0.07064215017826128\n",
            "epoch  0 , batch  2771  current loss =  0.07061997822702232\n",
            "epoch  0 , batch  2772  current loss =  0.07061673180370437\n",
            "epoch  0 , batch  2773  current loss =  0.07061340437064562\n",
            "epoch  0 , batch  2774  current loss =  0.07059129021826896\n",
            "epoch  0 , batch  2775  current loss =  0.07056922618177604\n",
            "epoch  0 , batch  2776  current loss =  0.07054718172792741\n",
            "epoch  0 , batch  2777  current loss =  0.07052513649868206\n",
            "epoch  0 , batch  2778  current loss =  0.07052158798047882\n",
            "epoch  0 , batch  2779  current loss =  0.070518014564601\n",
            "epoch  0 , batch  2780  current loss =  0.07051437541357543\n",
            "epoch  0 , batch  2781  current loss =  0.07049245189635671\n",
            "epoch  0 , batch  2782  current loss =  0.07047058536095174\n",
            "epoch  0 , batch  2783  current loss =  0.07044872234578127\n",
            "epoch  0 , batch  2784  current loss =  0.0704450735772159\n",
            "epoch  0 , batch  2785  current loss =  0.07044144049059528\n",
            "epoch  0 , batch  2786  current loss =  0.07043777197361484\n",
            "epoch  0 , batch  2787  current loss =  0.07041595345483277\n",
            "epoch  0 , batch  2788  current loss =  0.07041225863127094\n",
            "epoch  0 , batch  2789  current loss =  0.07039048044064405\n",
            "epoch  0 , batch  2790  current loss =  0.07038676732899478\n",
            "epoch  0 , batch  2791  current loss =  0.07036500301793816\n",
            "epoch  0 , batch  2792  current loss =  0.07034322163346865\n",
            "epoch  0 , batch  2793  current loss =  0.07033964215245155\n",
            "epoch  0 , batch  2794  current loss =  0.07033608939452013\n",
            "epoch  0 , batch  2795  current loss =  0.07033252362121904\n",
            "epoch  0 , batch  2796  current loss =  0.07031075790601732\n",
            "epoch  0 , batch  2797  current loss =  0.07028902991387921\n",
            "epoch  0 , batch  2798  current loss =  0.07028544893992048\n",
            "epoch  0 , batch  2799  current loss =  0.07026373713975773\n",
            "epoch  0 , batch  2800  current loss =  0.07024203688777406\n",
            "epoch  0 , batch  2801  current loss =  0.07023850721749161\n",
            "epoch  0 , batch  2802  current loss =  0.07023500584370264\n",
            "epoch  0 , batch  2803  current loss =  0.07023145919752051\n",
            "epoch  0 , batch  2804  current loss =  0.07022780889675101\n",
            "epoch  0 , batch  2805  current loss =  0.07022410186395282\n",
            "epoch  0 , batch  2806  current loss =  0.07022031858439999\n",
            "epoch  0 , batch  2807  current loss =  0.07021649118925463\n",
            "epoch  0 , batch  2808  current loss =  0.07021262673724107\n",
            "epoch  0 , batch  2809  current loss =  0.07020867634332636\n",
            "epoch  0 , batch  2810  current loss =  0.07018818491549678\n",
            "epoch  0 , batch  2811  current loss =  0.07018416426687701\n",
            "epoch  0 , batch  2812  current loss =  0.070180088076032\n",
            "epoch  0 , batch  2813  current loss =  0.07017599536151001\n",
            "epoch  0 , batch  2814  current loss =  0.07015576506526496\n",
            "epoch  0 , batch  2815  current loss =  0.07015162754198007\n",
            "epoch  0 , batch  2816  current loss =  0.07013125570717753\n",
            "epoch  0 , batch  2817  current loss =  0.0701107182487121\n",
            "epoch  0 , batch  2818  current loss =  0.07010678201418273\n",
            "epoch  0 , batch  2819  current loss =  0.07010297438704428\n",
            "epoch  0 , batch  2820  current loss =  0.0700992260280784\n",
            "epoch  0 , batch  2821  current loss =  0.07009549420241143\n",
            "epoch  0 , batch  2822  current loss =  0.07007463993006487\n",
            "epoch  0 , batch  2823  current loss =  0.07007089047165055\n",
            "epoch  0 , batch  2824  current loss =  0.07005007212569492\n",
            "epoch  0 , batch  2825  current loss =  0.07002924941348337\n",
            "epoch  0 , batch  2826  current loss =  0.07000837119037255\n",
            "epoch  0 , batch  2827  current loss =  0.07000475928689256\n",
            "epoch  0 , batch  2828  current loss =  0.06998377066953637\n",
            "epoch  0 , batch  2829  current loss =  0.06998024853341307\n",
            "epoch  0 , batch  2830  current loss =  0.06995919050931067\n",
            "epoch  0 , batch  2831  current loss =  0.06995569767317297\n",
            "epoch  0 , batch  2832  current loss =  0.06995216384858809\n",
            "epoch  0 , batch  2833  current loss =  0.06993111473953137\n",
            "epoch  0 , batch  2834  current loss =  0.06991009003527107\n",
            "epoch  0 , batch  2835  current loss =  0.06988904825825512\n",
            "epoch  0 , batch  2836  current loss =  0.06986796710269895\n",
            "epoch  0 , batch  2837  current loss =  0.06986452413820009\n",
            "epoch  0 , batch  2838  current loss =  0.06986110589187165\n",
            "epoch  0 , batch  2839  current loss =  0.06983994782089033\n",
            "epoch  0 , batch  2840  current loss =  0.06981878592188522\n",
            "epoch  0 , batch  2841  current loss =  0.06979759380432406\n",
            "epoch  0 , batch  2842  current loss =  0.06979437118590748\n",
            "epoch  0 , batch  2843  current loss =  0.06979116936588893\n",
            "epoch  0 , batch  2844  current loss =  0.06978795506577343\n",
            "epoch  0 , batch  2845  current loss =  0.06978467782011658\n",
            "epoch  0 , batch  2846  current loss =  0.06976357999139651\n",
            "epoch  0 , batch  2847  current loss =  0.06976012068341507\n",
            "epoch  0 , batch  2848  current loss =  0.06975656734513384\n",
            "epoch  0 , batch  2849  current loss =  0.0697529760424636\n",
            "epoch  0 , batch  2850  current loss =  0.06973229010397668\n",
            "epoch  0 , batch  2851  current loss =  0.06972856819923565\n",
            "epoch  0 , batch  2852  current loss =  0.0697080388154653\n",
            "epoch  0 , batch  2853  current loss =  0.06970429823087096\n",
            "epoch  0 , batch  2854  current loss =  0.06968372439192494\n",
            "epoch  0 , batch  2855  current loss =  0.069663050783412\n",
            "epoch  0 , batch  2856  current loss =  0.06965952357528278\n",
            "epoch  0 , batch  2857  current loss =  0.06965604815840659\n",
            "epoch  0 , batch  2858  current loss =  0.06965261832955898\n",
            "epoch  0 , batch  2859  current loss =  0.06963177356263298\n",
            "epoch  0 , batch  2860  current loss =  0.06962833475524657\n",
            "epoch  0 , batch  2861  current loss =  0.06960752261750489\n",
            "epoch  0 , batch  2862  current loss =  0.06960411245830245\n",
            "epoch  0 , batch  2863  current loss =  0.06960064477668347\n",
            "epoch  0 , batch  2864  current loss =  0.06959712888174292\n",
            "epoch  0 , batch  2865  current loss =  0.06957653920385215\n",
            "epoch  0 , batch  2866  current loss =  0.06955602393853652\n",
            "epoch  0 , batch  2867  current loss =  0.06953551084604608\n",
            "epoch  0 , batch  2868  current loss =  0.06951495892838626\n",
            "epoch  0 , batch  2869  current loss =  0.06951144284662833\n",
            "epoch  0 , batch  2870  current loss =  0.06950798633666362\n",
            "epoch  0 , batch  2871  current loss =  0.06950452818287521\n",
            "epoch  0 , batch  2872  current loss =  0.06948391201082854\n",
            "epoch  0 , batch  2873  current loss =  0.06948043843478524\n",
            "epoch  0 , batch  2874  current loss =  0.06945986243110636\n",
            "epoch  0 , batch  2875  current loss =  0.06943928789974337\n",
            "epoch  0 , batch  2876  current loss =  0.06943582968063183\n",
            "epoch  0 , batch  2877  current loss =  0.06941523082435255\n",
            "epoch  0 , batch  2878  current loss =  0.06941183423542571\n",
            "epoch  0 , batch  2879  current loss =  0.06939122258627321\n",
            "epoch  0 , batch  2880  current loss =  0.06938783514336998\n",
            "epoch  0 , batch  2881  current loss =  0.06936722584094628\n",
            "epoch  0 , batch  2882  current loss =  0.06934660718754641\n",
            "epoch  0 , batch  2883  current loss =  0.06932596274007025\n",
            "epoch  0 , batch  2884  current loss =  0.06930527857874409\n",
            "epoch  0 , batch  2885  current loss =  0.06928455054066812\n",
            "epoch  0 , batch  2886  current loss =  0.06928164100259604\n",
            "epoch  0 , batch  2887  current loss =  0.06927876711798538\n",
            "epoch  0 , batch  2888  current loss =  0.06925798465674127\n",
            "epoch  0 , batch  2889  current loss =  0.06923721767091885\n",
            "epoch  0 , batch  2890  current loss =  0.0692164515052023\n",
            "epoch  0 , batch  2891  current loss =  0.06921354117661581\n",
            "epoch  0 , batch  2892  current loss =  0.0691927861415218\n",
            "epoch  0 , batch  2893  current loss =  0.06918986349925914\n",
            "epoch  0 , batch  2894  current loss =  0.06916913976233344\n",
            "epoch  0 , batch  2895  current loss =  0.06914844251532386\n",
            "epoch  0 , batch  2896  current loss =  0.06914548198880566\n",
            "epoch  0 , batch  2897  current loss =  0.06912481359105231\n",
            "epoch  0 , batch  2898  current loss =  0.06910414755808285\n",
            "epoch  0 , batch  2899  current loss =  0.06910130885558138\n",
            "epoch  0 , batch  2900  current loss =  0.06908065611923545\n",
            "epoch  0 , batch  2901  current loss =  0.06907786508421346\n",
            "epoch  0 , batch  2902  current loss =  0.0690572096042584\n",
            "epoch  0 , batch  2903  current loss =  0.06905440066026436\n",
            "epoch  0 , batch  2904  current loss =  0.06903377314981413\n",
            "epoch  0 , batch  2905  current loss =  0.06901314599645893\n",
            "epoch  0 , batch  2906  current loss =  0.06901040275481546\n",
            "epoch  0 , batch  2907  current loss =  0.06898977797852504\n",
            "epoch  0 , batch  2908  current loss =  0.06898707243488719\n",
            "epoch  0 , batch  2909  current loss =  0.06898432264162094\n",
            "epoch  0 , batch  2910  current loss =  0.06896376871794709\n",
            "epoch  0 , batch  2911  current loss =  0.06896093565936118\n",
            "epoch  0 , batch  2912  current loss =  0.06895800711158018\n",
            "epoch  0 , batch  2913  current loss =  0.06893763595657626\n",
            "epoch  0 , batch  2914  current loss =  0.06893461785961333\n",
            "epoch  0 , batch  2915  current loss =  0.0689143584504601\n",
            "epoch  0 , batch  2916  current loss =  0.06889410841862684\n",
            "epoch  0 , batch  2917  current loss =  0.06889107156732592\n",
            "epoch  0 , batch  2918  current loss =  0.06887075811166364\n",
            "epoch  0 , batch  2919  current loss =  0.06886778899104883\n",
            "epoch  0 , batch  2920  current loss =  0.06884743947438828\n",
            "epoch  0 , batch  2921  current loss =  0.06882706259949098\n",
            "epoch  0 , batch  2922  current loss =  0.0688242871869321\n",
            "epoch  0 , batch  2923  current loss =  0.06880387600585207\n",
            "epoch  0 , batch  2924  current loss =  0.06878345020943218\n",
            "epoch  0 , batch  2925  current loss =  0.06878090817137524\n",
            "epoch  0 , batch  2926  current loss =  0.06876045642442923\n",
            "epoch  0 , batch  2927  current loss =  0.0687400040826175\n",
            "epoch  0 , batch  2928  current loss =  0.06873757885079024\n",
            "epoch  0 , batch  2929  current loss =  0.06873508901001549\n",
            "epoch  0 , batch  2930  current loss =  0.06873248526982198\n",
            "epoch  0 , batch  2931  current loss =  0.06872968934412847\n",
            "epoch  0 , batch  2932  current loss =  0.06872676578825077\n",
            "epoch  0 , batch  2933  current loss =  0.06870675940211321\n",
            "epoch  0 , batch  2934  current loss =  0.068703742868551\n",
            "epoch  0 , batch  2935  current loss =  0.06870068229445604\n",
            "epoch  0 , batch  2936  current loss =  0.06869757314081658\n",
            "epoch  0 , batch  2937  current loss =  0.06869440714951029\n",
            "epoch  0 , batch  2938  current loss =  0.06869118141758884\n",
            "epoch  0 , batch  2939  current loss =  0.06868789463627095\n",
            "epoch  0 , batch  2940  current loss =  0.06868454247246952\n",
            "epoch  0 , batch  2941  current loss =  0.06866604991397744\n",
            "epoch  0 , batch  2942  current loss =  0.06866264514241531\n",
            "epoch  0 , batch  2943  current loss =  0.0686592379538722\n",
            "epoch  0 , batch  2944  current loss =  0.06864057520123006\n",
            "epoch  0 , batch  2945  current loss =  0.06862167990276462\n",
            "epoch  0 , batch  2946  current loss =  0.06861839859838359\n",
            "epoch  0 , batch  2947  current loss =  0.06861524049349361\n",
            "epoch  0 , batch  2948  current loss =  0.06861216100687575\n",
            "epoch  0 , batch  2949  current loss =  0.06860912085337154\n",
            "epoch  0 , batch  2950  current loss =  0.06860603961458614\n",
            "epoch  0 , batch  2951  current loss =  0.06858666292972217\n",
            "epoch  0 , batch  2952  current loss =  0.06856728726704667\n",
            "epoch  0 , batch  2953  current loss =  0.0685478661921236\n",
            "epoch  0 , batch  2954  current loss =  0.06852837017817696\n",
            "epoch  0 , batch  2955  current loss =  0.06852561148313278\n",
            "epoch  0 , batch  2956  current loss =  0.06850596658329898\n",
            "epoch  0 , batch  2957  current loss =  0.06850333924312711\n",
            "epoch  0 , batch  2958  current loss =  0.06848362076337644\n",
            "epoch  0 , batch  2959  current loss =  0.06846387133952482\n",
            "epoch  0 , batch  2960  current loss =  0.06846133898314603\n",
            "epoch  0 , batch  2961  current loss =  0.06845872729839374\n",
            "epoch  0 , batch  2962  current loss =  0.0684559532550267\n",
            "epoch  0 , batch  2963  current loss =  0.06843624090305787\n",
            "epoch  0 , batch  2964  current loss =  0.06841658430101749\n",
            "epoch  0 , batch  2965  current loss =  0.06841370283041352\n",
            "epoch  0 , batch  2966  current loss =  0.06841082404420046\n",
            "epoch  0 , batch  2967  current loss =  0.06839136330779853\n",
            "epoch  0 , batch  2968  current loss =  0.068371926137281\n",
            "epoch  0 , batch  2969  current loss =  0.06836915615670107\n",
            "epoch  0 , batch  2970  current loss =  0.06836636717365732\n",
            "epoch  0 , batch  2971  current loss =  0.06836354857170265\n",
            "epoch  0 , batch  2972  current loss =  0.06834416457298696\n",
            "epoch  0 , batch  2973  current loss =  0.06832478244876002\n",
            "epoch  0 , batch  2974  current loss =  0.06830532887152263\n",
            "epoch  0 , batch  2975  current loss =  0.06828575909935108\n",
            "epoch  0 , batch  2976  current loss =  0.06828322887406889\n",
            "epoch  0 , batch  2977  current loss =  0.06828084175272915\n",
            "epoch  0 , batch  2978  current loss =  0.06826113802845114\n",
            "epoch  0 , batch  2979  current loss =  0.068258856080985\n",
            "epoch  0 , batch  2980  current loss =  0.06825655337650527\n",
            "epoch  0 , batch  2981  current loss =  0.06825412811504053\n",
            "epoch  0 , batch  2982  current loss =  0.06825155186511518\n",
            "epoch  0 , batch  2983  current loss =  0.06824878937328839\n",
            "epoch  0 , batch  2984  current loss =  0.06824584745238824\n",
            "epoch  0 , batch  2985  current loss =  0.0682268789853983\n",
            "epoch  0 , batch  2986  current loss =  0.06822381641218145\n",
            "epoch  0 , batch  2987  current loss =  0.06822070747506687\n",
            "epoch  0 , batch  2988  current loss =  0.06820228074042593\n",
            "epoch  0 , batch  2989  current loss =  0.06818381282080425\n",
            "epoch  0 , batch  2990  current loss =  0.06818067810312287\n",
            "epoch  0 , batch  2991  current loss =  0.06817757011233097\n",
            "epoch  0 , batch  2992  current loss =  0.06815877691816166\n",
            "epoch  0 , batch  2993  current loss =  0.06815575314909668\n",
            "epoch  0 , batch  2994  current loss =  0.06815277090349012\n",
            "epoch  0 , batch  2995  current loss =  0.06813384213631547\n",
            "epoch  0 , batch  2996  current loss =  0.06811487512500794\n",
            "epoch  0 , batch  2997  current loss =  0.06809583359464426\n",
            "epoch  0 , batch  2998  current loss =  0.06809325555197226\n",
            "epoch  0 , batch  2999  current loss =  0.06807408078946173\n",
            "epoch  0 , batch  3000  current loss =  0.06807176305570133\n",
            "epoch  0 , batch  3001  current loss =  0.0680694679086215\n",
            "epoch  0 , batch  3002  current loss =  0.06806711571013832\n",
            "epoch  0 , batch  3003  current loss =  0.06806465974151989\n",
            "epoch  0 , batch  3004  current loss =  0.06804551868552276\n",
            "epoch  0 , batch  3005  current loss =  0.06802643586479311\n",
            "epoch  0 , batch  3006  current loss =  0.06800736964280409\n",
            "epoch  0 , batch  3007  current loss =  0.06800471380522644\n",
            "epoch  0 , batch  3008  current loss =  0.06798563629974406\n",
            "epoch  0 , batch  3009  current loss =  0.06796654398859389\n",
            "epoch  0 , batch  3010  current loss =  0.0679639248939541\n",
            "epoch  0 , batch  3011  current loss =  0.06796135085296\n",
            "epoch  0 , batch  3012  current loss =  0.06795875907069152\n",
            "epoch  0 , batch  3013  current loss =  0.06795609552955827\n",
            "epoch  0 , batch  3014  current loss =  0.06795338849331659\n",
            "epoch  0 , batch  3015  current loss =  0.06793447105931637\n",
            "epoch  0 , batch  3016  current loss =  0.06791559949839523\n",
            "epoch  0 , batch  3017  current loss =  0.0679128358206626\n",
            "epoch  0 , batch  3018  current loss =  0.06789392737271317\n",
            "epoch  0 , batch  3019  current loss =  0.06787496072375863\n",
            "epoch  0 , batch  3020  current loss =  0.06785590253716094\n",
            "epoch  0 , batch  3021  current loss =  0.06783673844486968\n",
            "epoch  0 , batch  3022  current loss =  0.06783444408402513\n",
            "epoch  0 , batch  3023  current loss =  0.06783229740159143\n",
            "epoch  0 , batch  3024  current loss =  0.0678129789738123\n",
            "epoch  0 , batch  3025  current loss =  0.06781096912560995\n",
            "epoch  0 , batch  3026  current loss =  0.06780895448883927\n",
            "epoch  0 , batch  3027  current loss =  0.06778966518035319\n",
            "epoch  0 , batch  3028  current loss =  0.06777040514425944\n",
            "epoch  0 , batch  3029  current loss =  0.06775115583792772\n",
            "epoch  0 , batch  3030  current loss =  0.06774895944632897\n",
            "epoch  0 , batch  3031  current loss =  0.06772969968126728\n",
            "epoch  0 , batch  3032  current loss =  0.06772746437465962\n",
            "epoch  0 , batch  3033  current loss =  0.06772517182955723\n",
            "epoch  0 , batch  3034  current loss =  0.06772279940097542\n",
            "epoch  0 , batch  3035  current loss =  0.06772032122579262\n",
            "epoch  0 , batch  3036  current loss =  0.0677014244272618\n",
            "epoch  0 , batch  3037  current loss =  0.06768262287027953\n",
            "epoch  0 , batch  3038  current loss =  0.06766381848072704\n",
            "epoch  0 , batch  3039  current loss =  0.0676612695096992\n",
            "epoch  0 , batch  3040  current loss =  0.0676423558948175\n",
            "epoch  0 , batch  3041  current loss =  0.06763990079545655\n",
            "epoch  0 , batch  3042  current loss =  0.06762088104963764\n",
            "epoch  0 , batch  3043  current loss =  0.0676185397841844\n",
            "epoch  0 , batch  3044  current loss =  0.06761623756632772\n",
            "epoch  0 , batch  3045  current loss =  0.06759720819819418\n",
            "epoch  0 , batch  3046  current loss =  0.0675781716415026\n",
            "epoch  0 , batch  3047  current loss =  0.06757595041477099\n",
            "epoch  0 , batch  3048  current loss =  0.06757371984917039\n",
            "epoch  0 , batch  3049  current loss =  0.06755471783919169\n",
            "epoch  0 , batch  3050  current loss =  0.06755242925027391\n",
            "epoch  0 , batch  3051  current loss =  0.06755007605061061\n",
            "epoch  0 , batch  3052  current loss =  0.06753120732015072\n",
            "epoch  0 , batch  3053  current loss =  0.06751238148764371\n",
            "epoch  0 , batch  3054  current loss =  0.06749355648529949\n",
            "epoch  0 , batch  3055  current loss =  0.06747469495669865\n",
            "epoch  0 , batch  3056  current loss =  0.06745578445455179\n",
            "epoch  0 , batch  3057  current loss =  0.06743679704458895\n",
            "epoch  0 , batch  3058  current loss =  0.06741774263272647\n",
            "epoch  0 , batch  3059  current loss =  0.06741601654200577\n",
            "epoch  0 , batch  3060  current loss =  0.06741441565643959\n",
            "epoch  0 , batch  3061  current loss =  0.06741275973764024\n",
            "epoch  0 , batch  3062  current loss =  0.06739361837829809\n",
            "epoch  0 , batch  3063  current loss =  0.06737450618532732\n",
            "epoch  0 , batch  3064  current loss =  0.0673553968987885\n",
            "epoch  0 , batch  3065  current loss =  0.06733628538566588\n",
            "epoch  0 , batch  3066  current loss =  0.06731715986555559\n",
            "epoch  0 , batch  3067  current loss =  0.0673154685285059\n",
            "epoch  0 , batch  3068  current loss =  0.06731377527240327\n",
            "epoch  0 , batch  3069  current loss =  0.0673120060592817\n",
            "epoch  0 , batch  3070  current loss =  0.06729295100617665\n",
            "epoch  0 , batch  3071  current loss =  0.06727395772547122\n",
            "epoch  0 , batch  3072  current loss =  0.06727194875324786\n",
            "epoch  0 , batch  3073  current loss =  0.06726988174521746\n",
            "epoch  0 , batch  3074  current loss =  0.06726772730337169\n",
            "epoch  0 , batch  3075  current loss =  0.06726548242956758\n",
            "epoch  0 , batch  3076  current loss =  0.06726316577183772\n",
            "epoch  0 , batch  3077  current loss =  0.06724484583884574\n",
            "epoch  0 , batch  3078  current loss =  0.06724240294512157\n",
            "epoch  0 , batch  3079  current loss =  0.06722422623039259\n",
            "epoch  0 , batch  3080  current loss =  0.06720597536570015\n",
            "epoch  0 , batch  3081  current loss =  0.06720354860663018\n",
            "epoch  0 , batch  3082  current loss =  0.06720119079002797\n",
            "epoch  0 , batch  3083  current loss =  0.06718263096096364\n",
            "epoch  0 , batch  3084  current loss =  0.06718039131018437\n",
            "epoch  0 , batch  3085  current loss =  0.06716175691260245\n",
            "epoch  0 , batch  3086  current loss =  0.06714309468970384\n",
            "epoch  0 , batch  3087  current loss =  0.06712439759885361\n",
            "epoch  0 , batch  3088  current loss =  0.06710564732031794\n",
            "epoch  0 , batch  3089  current loss =  0.06708683308943335\n",
            "epoch  0 , batch  3090  current loss =  0.0670857632662878\n",
            "epoch  0 , batch  3091  current loss =  0.06706687162647128\n",
            "epoch  0 , batch  3092  current loss =  0.06706602842421439\n",
            "epoch  0 , batch  3093  current loss =  0.06706501656611051\n",
            "epoch  0 , batch  3094  current loss =  0.0670461705156116\n",
            "epoch  0 , batch  3095  current loss =  0.06704468839231503\n",
            "epoch  0 , batch  3096  current loss =  0.067042959875057\n",
            "epoch  0 , batch  3097  current loss =  0.06704097729130588\n",
            "epoch  0 , batch  3098  current loss =  0.06702249152384514\n",
            "epoch  0 , batch  3099  current loss =  0.06700414012817126\n",
            "epoch  0 , batch  3100  current loss =  0.06700188083161522\n",
            "epoch  0 , batch  3101  current loss =  0.06698371336611046\n",
            "epoch  0 , batch  3102  current loss =  0.06696573143318905\n",
            "epoch  0 , batch  3103  current loss =  0.0669634318901538\n",
            "epoch  0 , batch  3104  current loss =  0.06696115656037502\n",
            "epoch  0 , batch  3105  current loss =  0.06694299372240507\n",
            "epoch  0 , batch  3106  current loss =  0.06692475990350602\n",
            "epoch  0 , batch  3107  current loss =  0.06692262433236765\n",
            "epoch  0 , batch  3108  current loss =  0.06690423926125869\n",
            "epoch  0 , batch  3109  current loss =  0.06690230239781632\n",
            "epoch  0 , batch  3110  current loss =  0.06690040299425226\n",
            "epoch  0 , batch  3111  current loss =  0.06689845499520342\n",
            "epoch  0 , batch  3112  current loss =  0.06688006200857276\n",
            "epoch  0 , batch  3113  current loss =  0.06687816731331483\n",
            "epoch  0 , batch  3114  current loss =  0.06687619232902987\n",
            "epoch  0 , batch  3115  current loss =  0.06685791131490375\n",
            "epoch  0 , batch  3116  current loss =  0.06685580953897088\n",
            "epoch  0 , batch  3117  current loss =  0.06685363132096803\n",
            "epoch  0 , batch  3118  current loss =  0.06683556770391669\n",
            "epoch  0 , batch  3119  current loss =  0.06683331266618692\n",
            "epoch  0 , batch  3120  current loss =  0.06681537141236252\n",
            "epoch  0 , batch  3121  current loss =  0.06681310492797417\n",
            "epoch  0 , batch  3122  current loss =  0.06681083133035637\n",
            "epoch  0 , batch  3123  current loss =  0.06680850339004062\n",
            "epoch  0 , batch  3124  current loss =  0.06679073639810085\n",
            "epoch  0 , batch  3125  current loss =  0.06678841430908374\n",
            "epoch  0 , batch  3126  current loss =  0.06677068210542583\n",
            "epoch  0 , batch  3127  current loss =  0.06675289599361885\n",
            "epoch  0 , batch  3128  current loss =  0.06673499293650356\n",
            "epoch  0 , batch  3129  current loss =  0.06673296293624627\n",
            "epoch  0 , batch  3130  current loss =  0.0667148948034628\n",
            "epoch  0 , batch  3131  current loss =  0.06671312090608923\n",
            "epoch  0 , batch  3132  current loss =  0.06671142357080805\n",
            "epoch  0 , batch  3133  current loss =  0.06670970779361624\n",
            "epoch  0 , batch  3134  current loss =  0.06670790470340415\n",
            "epoch  0 , batch  3135  current loss =  0.06668987186662426\n",
            "epoch  0 , batch  3136  current loss =  0.06667189162276782\n",
            "epoch  0 , batch  3137  current loss =  0.06665391851319837\n",
            "epoch  0 , batch  3138  current loss =  0.06665194692317421\n",
            "epoch  0 , batch  3139  current loss =  0.0666339614327736\n",
            "epoch  0 , batch  3140  current loss =  0.06663203073160848\n",
            "epoch  0 , batch  3141  current loss =  0.06663006270822448\n",
            "epoch  0 , batch  3142  current loss =  0.06662806508706476\n",
            "epoch  0 , batch  3143  current loss =  0.06662600850757525\n",
            "epoch  0 , batch  3144  current loss =  0.06660824483571447\n",
            "epoch  0 , batch  3145  current loss =  0.06659052935763436\n",
            "epoch  0 , batch  3146  current loss =  0.06658839798835173\n",
            "epoch  0 , batch  3147  current loss =  0.06658625456899774\n",
            "epoch  0 , batch  3148  current loss =  0.06658409688108334\n",
            "epoch  0 , batch  3149  current loss =  0.06658189017000415\n",
            "epoch  0 , batch  3150  current loss =  0.06657963558311493\n",
            "epoch  0 , batch  3151  current loss =  0.06657732140153486\n",
            "epoch  0 , batch  3152  current loss =  0.06657495194838713\n",
            "epoch  0 , batch  3153  current loss =  0.06655789767324065\n",
            "epoch  0 , batch  3154  current loss =  0.06654086753596122\n",
            "epoch  0 , batch  3155  current loss =  0.06652373379404469\n",
            "epoch  0 , batch  3156  current loss =  0.06652140628197194\n",
            "epoch  0 , batch  3157  current loss =  0.06650401158624006\n",
            "epoch  0 , batch  3158  current loss =  0.06650192628019962\n",
            "epoch  0 , batch  3159  current loss =  0.06648438324108484\n",
            "epoch  0 , batch  3160  current loss =  0.0664667777480821\n",
            "epoch  0 , batch  3161  current loss =  0.06644908724951214\n",
            "epoch  0 , batch  3162  current loss =  0.0664312968792001\n",
            "epoch  0 , batch  3163  current loss =  0.06641340413155546\n",
            "epoch  0 , batch  3164  current loss =  0.0664127471193224\n",
            "epoch  0 , batch  3165  current loss =  0.0664122193070412\n",
            "epoch  0 , batch  3166  current loss =  0.06639417109879826\n",
            "epoch  0 , batch  3167  current loss =  0.06637611144223494\n",
            "epoch  0 , batch  3168  current loss =  0.06635803285029294\n",
            "epoch  0 , batch  3169  current loss =  0.06635741922234652\n",
            "epoch  0 , batch  3170  current loss =  0.06635663985297935\n",
            "epoch  0 , batch  3171  current loss =  0.0663556060369137\n",
            "epoch  0 , batch  3172  current loss =  0.06633761637893162\n",
            "epoch  0 , batch  3173  current loss =  0.06633610149760975\n",
            "epoch  0 , batch  3174  current loss =  0.06631826964947651\n",
            "epoch  0 , batch  3175  current loss =  0.06630053871014491\n",
            "epoch  0 , batch  3176  current loss =  0.06628284904798613\n",
            "epoch  0 , batch  3177  current loss =  0.06628110788761397\n",
            "epoch  0 , batch  3178  current loss =  0.06627935136645827\n",
            "epoch  0 , batch  3179  current loss =  0.06626171199634155\n",
            "epoch  0 , batch  3180  current loss =  0.06624405921244492\n",
            "epoch  0 , batch  3181  current loss =  0.06622634906676497\n",
            "epoch  0 , batch  3182  current loss =  0.06620853767179344\n",
            "epoch  0 , batch  3183  current loss =  0.0662070544446519\n",
            "epoch  0 , batch  3184  current loss =  0.06620570497391409\n",
            "epoch  0 , batch  3185  current loss =  0.06620441503590119\n"
          ]
        }
      ],
      "source": [
        "crit = 0.90\n",
        "dTrain = data[0:round(len(data)*crit)]\n",
        "dTest = data[round(len(data)*crit):-1]\n",
        "\n",
        "# model\n",
        "#model = models.VAE_LSTM(484, 10, 10, 10, 10, 484, 484)\n",
        "#model = VAE_LSTM(484, 10, 10, 10, 10, 484, 484) # works reasonably good. loss 0.04 \n",
        "#model = models.VAE_LSTM(484, 10, 5, 5, 10, 484, 484) # not as good\n",
        "model = AE_Transformer(4840,4840,4840, 3, 1, 1000, 2, 2, True, None)\n",
        "model = model.to(\"cuda\").to(torch.float32)\n",
        "#model\n",
        "\n",
        "\n",
        "res = trainLoop(dTrain, model, False,f\"{gdrive_path}aAETransformer.pth.tar\", 0.001, 0.01, -1, MSEpixelLoss, 5000, 1, None)\n",
        "\n",
        "#hiddenL, mlpSize, numLayersDateEncoder, sizeDateEncoder, lstmLayers, lstmHiddenSize, lstmInputSize\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}